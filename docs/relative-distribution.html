<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Manqing Lin, Tina Lasisi" />


<title>Estimating Differences in the Distribution of First-degree Relatives</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PODFRIDGE</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/lasisilab/PODFRIDGE">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Estimating Differences in the Distribution
of First-degree Relatives</h1>
<h4 class="author">Manqing Lin, Tina Lasisi</h4>
<h4 class="date">2024-12-16 14:04:39</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2024-12-16
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>PODFRIDGE/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges">
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted
changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges"
class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of
the R Markdown file created these results, you’ll want to first commit
it to the Git repo. If you’re still working on the analysis, you can
ignore this warning. When you’re finished, you can run
<code>wflow_publish</code> to commit the R Markdown file and build the
HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20230302code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20230302)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20230302code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20230302)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomlasisilabPODFRIDGEtree9e2e50ef47dc8f2941ae4ef1a368167cab84fa1btargetblank9e2e50ea">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/lasisilab/PODFRIDGE/tree/9e2e50ef47dc8f2941ae4ef1a368167cab84fa1b" target="_blank">9e2e50e</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomlasisilabPODFRIDGEtree9e2e50ef47dc8f2941ae4ef1a368167cab84fa1btargetblank9e2e50ea"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/lasisilab/PODFRIDGE/tree/9e2e50ef47dc8f2941ae4ef1a368167cab84fa1b" target="_blank">9e2e50e</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.Rhistory
    Ignored:    data/.DS_Store

Unstaged changes:
    Modified:   analysis/relative-distribution.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/relative-distribution.Rmd</code>)
and HTML (<code>docs/relative-distribution.html</code>) files. If you’ve
configured a remote Git repository (see <code>?wflow_git_remote</code>),
click on the hyperlinks in the table below to view the files as they
were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/231390a7e9b5261ed01047322fdbca2676183be9/analysis/relative-distribution.Rmd" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
<td>
update analysis
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/231390a7e9b5261ed01047322fdbca2676183be9/docs/relative-distribution.html" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
<td>
update analysis
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/analysis/relative-distribution.Rmd" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
<td>
update workflow page
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/800786411d6551c5050635b63803c9f8e4c12506/docs/relative-distribution.html" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
<td>
update workflow page
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/e553adcbb2285b77b2005e6b5bfcd9cd5d7a5425/analysis/relative-distribution.Rmd" target="_blank">e553adc</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/e76576b2722f0c7f4e6acfab618f728c675ab898/analysis/relative-distribution.Rmd" target="_blank">e76576b</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/21f0f4fa28354d3f047a99b91294fe40edc5d6d6/analysis/relative-distribution.Rmd" target="_blank">21f0f4f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-19
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/f5837985e03135176fbb94c819f8089d39510172/analysis/relative-distribution.Rmd" target="_blank">f583798</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-14
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/900b2e49b54e99e7dba6ec4c1e09d85c8f35b762/analysis/relative-distribution.Rmd" target="_blank">900b2e4</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-14
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/analysis/relative-distribution.Rmd" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
<td>
update the model fit analysis in children’s part
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/relative-distribution.html" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
<td>
update the model fit analysis in children’s part
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/06a8f9602d51a58fe87d4ac678eb63ef39cf2275/analysis/relative-distribution.Rmd" target="_blank">06a8f96</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
update sibling’s part
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/06a8f9602d51a58fe87d4ac678eb63ef39cf2275/docs/relative-distribution.html" target="_blank">06a8f96</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
update sibling’s part
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/1741cb1d69036bd588d6f00cdff2b95b37a1b106/analysis/relative-distribution.Rmd" target="_blank">1741cb1</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix test
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/4e68621bb2cf39f3713f32ebf0d1640cd0cf2edd/analysis/relative-distribution.Rmd" target="_blank">4e68621</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix chisq-test in cohort stability
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/4e68621bb2cf39f3713f32ebf0d1640cd0cf2edd/docs/relative-distribution.html" target="_blank">4e68621</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix chisq-test in cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/6fb5b405d09346d07e1d2be9e59158068a385b20/analysis/relative-distribution.Rmd" target="_blank">6fb5b40</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-29
</td>
<td>
update sibling’s distribution plot
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/570abb077e3ce782ed0ad4a4efadedacced84fbc/analysis/relative-distribution.Rmd" target="_blank">570abb0</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
update sibling part
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/2e09e084a0ab4c6710fc50bf2575a64d7115435e/analysis/relative-distribution.Rmd" target="_blank">2e09e08</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
workflow build
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/2e09e084a0ab4c6710fc50bf2575a64d7115435e/docs/relative-distribution.html" target="_blank">2e09e08</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
workflow build
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/bb2c61b7f74db6bd5d5499c3a5769fe950aa670e/analysis/relative-distribution.Rmd" target="_blank">bb2c61b</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-21
</td>
<td>
complete fertility shift analysis
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/842d935f1027fd858cabf2fd48684e824c1699b3/analysis/relative-distribution.Rmd" target="_blank">842d935</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-17
</td>
<td>
update fertility shift
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/2ae84609413327192cca951dc7e71dcc4000f910/analysis/relative-distribution.Rmd" target="_blank">2ae8460</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-16
</td>
<td>
fix the chisq-test
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/9632ae1f7420addbaec02a4b92ea9258b6e67e22/analysis/relative-distribution.Rmd" target="_blank">9632ae1</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-12
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/9852339ae0eb8c21fbeff0dd60f78482a2a51982/analysis/relative-distribution.Rmd" target="_blank">9852339</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-08
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/9852339ae0eb8c21fbeff0dd60f78482a2a51982/docs/relative-distribution.html" target="_blank">9852339</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-08
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/7ec169f19f763fa4ae4cc479e001d89c48eac353/analysis/relative-distribution.Rmd" target="_blank">7ec169f</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-03
</td>
<td>
update sibling distribution
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/27b986fd03c7db1db62f9a234ac2146626f39047/analysis/relative-distribution.Rmd" target="_blank">27b986f</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-01
</td>
<td>
update stability cohort analysis
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/57a97dbc76b451268df7314c0de6b4c5bc724680/analysis/relative-distribution.Rmd" target="_blank">57a97db</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-30
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/52aa7f848be819c985c7ec16b22558aaebebe01c/analysis/relative-distribution.Rmd" target="_blank">52aa7f8</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-27
</td>
<td>
improving code on Part1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/c54a746c06249bc02d4a778c9e3b16e887891fce/analysis/relative-distribution.Rmd" target="_blank">c54a746</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-26
</td>
<td>
update and fix step 2
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/94d00b35b4a3f33e6e96a1d8ec016a851774f05f/analysis/relative-distribution.Rmd" target="_blank">94d00b3</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-24
</td>
<td>
fix step1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/1225480d79d7a80647f573e73fa72cbe517bafc6/analysis/relative-distribution.Rmd" target="_blank">1225480</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-23
</td>
<td>
update on step1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/83174c03bbc21104de64adb0e1c6e15a206d48bc/analysis/relative-distribution.Rmd" target="_blank">83174c0</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-22
</td>
<td>
Instructions and layout for relative distribution
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/83174c03bbc21104de64adb0e1c6e15a206d48bc/docs/relative-distribution.html" target="_blank">83174c0</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-22
</td>
<td>
Instructions and layout for relative distribution
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/78c162184b484b2c22526171033ab3dc7235d2de/analysis/relative-distribution.Rmd" target="_blank">78c1621</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/f4c2830d4e6d627e954221b90ac013605f417de2/analysis/relative-distribution.Rmd" target="_blank">f4c2830</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/analysis/relative-distribution.Rmd" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
rename old analysis
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/28513857e94c801ed7d27e62bb34ff8098d08107/docs/relative-distribution.html" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
rename old analysis
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The relative genetic surveillance of a population is influenced by
the number of genetically detectable relatives individuals have.
First-degree relatives (parents, siblings, and children) are especially
relevant in forensic analyses using short tandem repeat (STR) loci,
where close familial searches are commonly employed. To explore
potential disparities in genetic detectability between African American
and European American populations, we examined U.S. Census data from
four census years (1960, 1970, 1980, and 1990) focusing on the number of
children born to women over the age of 40.</p>
</div>
<div id="data-sources" class="section level2">
<h2>Data Sources</h2>
<p>We used publicly available data from the Integrated Public Use
Microdata Series (IPUMS) for the U.S. Census years 1960, 1970, 1980, and
1990. The datasets include information on:</p>
<ul>
<li>AGE: Age of the respondent.</li>
<li>RACE: Self-identified race of the respondent.</li>
<li>chborn_num: Number of children ever born to the respondent.</li>
</ul>
<p>Data citation: Steven Ruggles, Sarah Flood, Matthew Sobek, Daniel
Backman, Annie Chen, Grace Cooper, Stephanie Richards, Renae Rogers, and
Megan Schouweiler. IPUMS USA: Version 14.0 [dataset]. Minneapolis, MN:
IPUMS, 2023. <a href="https://doi.org/10.18128/D010.V14.0"
class="uri">https://doi.org/10.18128/D010.V14.0</a></p>
</div>
<div id="data-preparation" class="section level2">
<h2>Data Preparation</h2>
<p>Filtering Criteria: We selected women aged 40 and above to ensure
that most had completed childbearing.</p>
<p>Due to the terms of agreement for using this data, we cannot share
the full dataset but our repo contains the subset that was used to
calculate the mean number of offspring and variance.</p>
<p>Race Classification: We categorized individuals into two groups:</p>
<ul>
<li>African American: Those who identified as “Black” or “African
American”.</li>
<li>European American: Those who identified as “White”.</li>
</ul>
<p>Calculating Number of Siblings: For each child of these women, the
number of siblings (n_sib) is one less than the number of children born
to the mother:</p>
<p><span class="math display">\[
n_{sib} = chborn_{num} - 1
\]</span></p>
<pre class="r"><code>path &lt;- file.path(&quot;.&quot;, &quot;data&quot;)
savepath &lt;- file.path(&quot;.&quot;, &quot;output&quot;)

prop_race_year &lt;- file.path(path, &quot;proportions_table_by_race_year.csv&quot;)
data_filter &lt;- file.path(path, &quot;data_filtered_recoded.csv&quot;)

children_data = read.csv(prop_race_year)
mother_data = read.csv(data_filter)</code></pre>
<pre class="r"><code>df &lt;- mother_data %&gt;%
  # Filter for women aged 40 and above
  filter(AGE &gt;= 40) %&gt;%
  mutate(
    # Create new age ranges
    AGE_RANGE = case_when(
      AGE &gt;= 70 ~ &quot;70+&quot;,
      AGE &gt;= 60 ~ &quot;60-69&quot;,
      AGE &gt;= 50 ~ &quot;50-59&quot;,
      AGE &gt;= 40 ~ &quot;40-49&quot;,
      TRUE ~ as.character(AGE_RANGE)  # This shouldn&#39;t occur due to the filter, but included for completeness
    ),
    # Convert CHBORN to ordered factor
    CHBORN = factor(case_when(
      chborn_num == 0 ~ &quot;No children&quot;,
      chborn_num == 1 ~ &quot;1 child&quot;,
      chborn_num == 2 ~ &quot;2 children&quot;,
      chborn_num == 3 ~ &quot;3 children&quot;,
      chborn_num == 4 ~ &quot;4 children&quot;,
      chborn_num == 5 ~ &quot;5 children&quot;,
      chborn_num == 6 ~ &quot;6 children&quot;,
      chborn_num == 7 ~ &quot;7 children&quot;,
      chborn_num == 8 ~ &quot;8 children&quot;,
      chborn_num == 9 ~ &quot;9 children&quot;,
      chborn_num == 10 ~ &quot;10 children&quot;,
      chborn_num == 11 ~ &quot;11 children&quot;,
      chborn_num &gt;= 12 ~ &quot;12+ children&quot;
    ), levels = c(&quot;No children&quot;, &quot;1 child&quot;, &quot;2 children&quot;, &quot;3 children&quot;, 
                  &quot;4 children&quot;, &quot;5 children&quot;, &quot;6 children&quot;, &quot;7 children&quot;, 
                  &quot;8 children&quot;, &quot;9 children&quot;, &quot;10 children&quot;, &quot;11 children&quot;, 
                  &quot;12+ children&quot;), ordered = TRUE),
    
    # Ensure RACE variable is correctly formatted and filtered
    RACE = factor(RACE, levels = c(&quot;White&quot;, &quot;Black/African American&quot;))
  ) %&gt;%
  # Filter for African American and European American women
  filter(RACE %in% c(&quot;Black/African American&quot;, &quot;White&quot;)) %&gt;%
  # Select and reorder columns
  dplyr::select(YEAR, SEX, AGE, BIRTHYR, RACE, CHBORN, AGE_RANGE, chborn_num)

# Display the first few rows of the processed data
head(df)</code></pre>
<pre><code>  YEAR    SEX AGE BIRTHYR  RACE      CHBORN AGE_RANGE chborn_num
1 1960 Female  65    1894 White No children     60-69          0
2 1960 Female  49    1911 White  2 children     40-49          2
3 1960 Female  54    1905 White No children     50-59          0
4 1960 Female  56    1903 White     1 child     50-59          1
5 1960 Female  54    1905 White     1 child     50-59          1
6 1960 Female  50    1910 White No children     50-59          0</code></pre>
<pre class="r"><code># Summary of the processed data
summary(df)</code></pre>
<pre><code>      YEAR          SEX                 AGE            BIRTHYR    
 Min.   :1960   Length:1917477     Min.   : 41.00   Min.   :1859  
 1st Qu.:1970   Class :character   1st Qu.: 49.00   1st Qu.:1905  
 Median :1970   Mode  :character   Median : 58.00   Median :1916  
 Mean   :1976                      Mean   : 59.24   Mean   :1916  
 3rd Qu.:1980                      3rd Qu.: 68.00   3rd Qu.:1926  
 Max.   :1990                      Max.   :100.00   Max.   :1949  
                                                                  
                     RACE                 CHBORN        AGE_RANGE        
 White                 :1740755   2 children :452594   Length:1917477    
 Black/African American: 176722   No children:343319   Class :character  
                                  3 children :335119   Mode  :character  
                                  1 child    :292001                     
                                  4 children :204983                     
                                  5 children :113593                     
                                  (Other)    :175868                     
   chborn_num   
 Min.   : 0.00  
 1st Qu.: 1.00  
 Median : 2.00  
 Mean   : 2.57  
 3rd Qu.: 4.00  
 Max.   :12.00  
                </code></pre>
<pre class="r"><code># Check the levels of the RACE factor
levels(df$RACE)</code></pre>
<pre><code>[1] &quot;White&quot;                  &quot;Black/African American&quot;</code></pre>
<pre class="r"><code># Count of observations by RACE
table(df$RACE)</code></pre>
<pre><code>
                 White Black/African American 
               1740755                 176722 </code></pre>
<pre class="r"><code># Count of observations by AGE_RANGE
table(df$AGE_RANGE)</code></pre>
<pre><code>
 40-49  50-59  60-69    70+ 
529160 517620 436829 433868 </code></pre>
</div>
<div id="distribution-of-number-of-children-across-census-years"
class="section level1">
<h1>Distribution of Number of Children Across Census Years</h1>
<p>First we visualize the general trends in the frequency of the number
of children for African American and European American mothers across
the Census years by age group.</p>
<pre class="r"><code># Calculate proportions within each group, ensuring proper normalization
df_proportions &lt;- df %&gt;%
  group_by(YEAR, RACE, AGE_RANGE, chborn_num) %&gt;%
  summarise(count = n(), .groups = &quot;drop&quot;) %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  mutate(proportion = count / sum(count)) %&gt;%
  ungroup()

# Reshape data for the mirror plot
df_mirror &lt;- df_proportions %&gt;%
  mutate(proportion = if_else(RACE == &quot;White&quot;, -proportion, proportion))

# Create color palette
my_colors &lt;- colorRampPalette(c(&quot;#FFB000&quot;, &quot;#F77A2E&quot;, &quot;#DE3A8A&quot;, &quot;#7253FF&quot;, &quot;#5E8BFF&quot;))(13)

# Create the plot
child_plot &lt;- ggplot(df_mirror, aes(x = chborn_num, y = proportion, fill = as.factor(chborn_num))) +
  geom_col(aes(alpha = RACE)) +
  geom_hline(yintercept = 0, color = &quot;black&quot;, size = 0.5) +
  facet_grid(AGE_RANGE ~ YEAR, scales = &quot;free_y&quot;) +
  coord_flip() +
  scale_y_continuous(
    labels = function(x) abs(x),
    limits = function(x) c(-max(abs(x)), max(abs(x)))
  ) +
  scale_x_continuous(breaks = 0:12, labels = c(0:11, &quot;12+&quot;)) +
  scale_fill_manual(values = my_colors) +
  scale_alpha_manual(values = c(&quot;White&quot; = 0.7, &quot;Black/African American&quot; = 1), guide = &quot;none&quot;) +
  labs(
    title = &quot;Distribution of Number of Children by Census Year, Race, and Age Range&quot;,
    x = &quot;Number of Children&quot;,
    y = &quot;Proportion&quot;,
    fill = &quot;Number of Children&quot;,
    caption = &quot;White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10),
    legend.position = &quot;none&quot;,
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )

print(child_plot)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-3-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Print summary to check age ranges and normalization
print(df_proportions %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  summarise(total_proportion = sum(proportion), .groups = &quot;drop&quot;) %&gt;%
  arrange(YEAR, RACE, AGE_RANGE))</code></pre>
<pre><code># A tibble: 32 × 4
    YEAR RACE                   AGE_RANGE total_proportion
   &lt;int&gt; &lt;fct&gt;                  &lt;chr&gt;                &lt;dbl&gt;
 1  1960 White                  40-49                    1
 2  1960 White                  50-59                    1
 3  1960 White                  60-69                    1
 4  1960 White                  70+                      1
 5  1960 Black/African American 40-49                    1
 6  1960 Black/African American 50-59                    1
 7  1960 Black/African American 60-69                    1
 8  1960 Black/African American 70+                      1
 9  1970 White                  40-49                    1
10  1970 White                  50-59                    1
# ℹ 22 more rows</code></pre>
<p>With this visualization of the distribution of the data, we can see
that there are differences between White and Black Americans.</p>
<p>We will now test for differences in 1) the mean and variance, and 2)
zero-inflation.</p>
<div id="instructions-for-manqing-model-fit-across-census-years"
class="section level2">
<h2>[instructions for Manqing] Model Fit Across Census Years</h2>
<p><strong>Question 1) What is the best model for the distribution of
the data in each of these subsets of data (by race, by census year, by
age range combined)?</strong></p>
<div id="step-1-fit-models-across-all-subsets" class="section level3">
<h3>Step 1: Fit Models Across All Subsets</h3>
<p>For each combination of race, census year, and age range, fit your
candidate models:</p>
<ul>
<li><strong>Poisson Model</strong></li>
<li><strong>Negative Binomial (NB) Model</strong></li>
<li><strong>Zero-Inflated Poisson (ZIP) Model</strong></li>
<li><strong>Zero-Inflated Negative Binomial (ZINB) Model</strong></li>
</ul>
<p>This should be done for each subset of the data (race × census year ×
age range).</p>
<p><strong>Understanding the Data:</strong></p>
<ul>
<li><strong>Data Type:</strong> Count data representing the number of
children per woman.</li>
<li><strong>Characteristics:</strong>
<ul>
<li>Potential overdispersion (variance greater than the mean).</li>
<li>Possible zero-inflation (excess zeros) in some subsets.</li>
<li>Different distributions across races, census years, and age
ranges.</li>
</ul></li>
</ul>
<p><strong>Candidate Models for Count Data:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Poisson Distribution:</strong>
<ul>
<li>Assumes mean equals variance.</li>
<li>Not suitable if overdispersion is present.</li>
</ul></li>
<li><strong>Negative Binomial Distribution:</strong>
<ul>
<li>Handles overdispersion by introducing a dispersion parameter.</li>
<li>Suitable when variance exceeds the mean.</li>
</ul></li>
<li><strong>Zero-Inflated Models:</strong>
<ul>
<li><strong>Zero-Inflated Poisson (ZIP):</strong>
<ul>
<li>Combines a Poisson distribution with a point mass at zero.</li>
<li>Suitable if there’s an excess of zeros.</li>
</ul></li>
<li><strong>Zero-Inflated Negative Binomial (ZINB):</strong>
<ul>
<li>Combines a negative binomial distribution with a point mass at
zero.</li>
<li>Handles both overdispersion and excess zeros.</li>
</ul></li>
</ul></li>
<li><strong>Hurdle Models: (optional)</strong>
<ul>
<li>Similar to zero-inflated models but model zeros and positive counts
separately.</li>
</ul></li>
</ol>
<p><strong>Recommended Approach:</strong></p>
<p><strong>1: Exploratory Data Analysis (EDA)</strong></p>
<ul>
<li><strong>Compute Mean and Variance:</strong>
<ul>
<li>For each subset (race, census year, age range), calculate the mean
and variance of the number of children.</li>
<li>Check for overdispersion: If variance &gt; mean, overdispersion is
present.</li>
</ul></li>
<li><strong>Check for Zero-Inflation:</strong>
<ul>
<li>Calculate the proportion of zeros in each subset.</li>
<li>If the proportion of zeros is significantly higher than expected
under a standard Poisson or negative binomial model, consider
zero-inflated models.</li>
</ul></li>
</ul>
<p><strong>2: Model Selection</strong></p>
<p><strong>Scenario 1: Overdispersion Without Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Negative Binomial Distribution</li>
<li><strong>Justification:</strong> Handles overdispersion
effectively.</li>
</ul>
<p><strong>Scenario 2: Overdispersion With Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Zero-Inflated Negative Binomial (ZINB)
Distribution</li>
<li><strong>Justification:</strong> Accounts for both overdispersion and
excess zeros.</li>
</ul>
<p><strong>Scenario 3: No Overdispersion, No Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Poisson Distribution</li>
<li><strong>Justification:</strong> Appropriate if mean equals variance
and no excess zeros.</li>
</ul>
<p><strong>3: Fit Models to Each Subset</strong></p>
<ul>
<li><strong>For Each Subset:</strong>
<ul>
<li>Fit a Poisson model.</li>
<li>Fit a Negative Binomial model.</li>
<li>If necessary, fit a Zero-Inflated Poisson (ZIP) and Zero-Inflated
Negative Binomial (ZINB) model.</li>
</ul></li>
<li><strong>Compare Models:</strong>
<ul>
<li>Use goodness-of-fit measures such as Akaike Information Criterion
(AIC) or Bayesian Information Criterion (BIC).</li>
<li>Lower AIC/BIC indicates a better-fitting model.</li>
<li>Perform likelihood ratio tests where appropriate.</li>
</ul></li>
</ul>
</div>
<div id="step-2-model-comparison-using-aic-or-bic"
class="section level3">
<h3>Step 2: Model Comparison Using AIC or BIC</h3>
<p>Once the models are fitted, compare them using goodness-of-fit
criteria like <strong>AIC</strong> or <strong>BIC</strong> for each
subset. The model with the <strong>lowest AIC/BIC</strong> is the best
fit for that subset.</p>
<ul>
<li><strong>Assess Model Fit:</strong>
<ul>
<li>Check residuals for patterns.</li>
<li>Use diagnostic plots.</li>
</ul></li>
<li><strong>Check Dispersion Parameter:</strong>
<ul>
<li>For negative binomial models, examine the estimated dispersion
parameter.</li>
</ul></li>
<li><strong>Vuong Test:</strong>
<ul>
<li>Compare zero-inflated models to standard models to assess if
zero-inflation significantly improves the fit.</li>
</ul></li>
</ul>
<pre class="r"><code>## Approach 1:
combinations &lt;- df %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  group_split()

# Initialize the data frame for storing results
EDA_df &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  Age_Range = character(),
  Overdispersion = logical(), 
  Zero_Inflation = logical(),
  stringsAsFactors = FALSE
)

# Initialize vectors for overdispersion and zero-inflation
overdispersion &lt;- logical(length(combinations))
zero_inflation &lt;- logical(length(combinations))

for (i in seq_along(combinations)) {
  subset_data &lt;- combinations[[i]]
  mean_chborn &lt;- mean(subset_data$chborn_num)
  var_chborn &lt;- var(subset_data$chborn_num)
  
  # Check for overdispersion (variance &gt; mean)
  overdispersion[i] &lt;- var_chborn &gt; mean_chborn
  
  # Check for zero-inflation
  prop_zero &lt;- sum(subset_data$chborn_num == 0) / nrow(subset_data)
  
  # Compare prop_zero to expected under Poisson
  exp_poisson &lt;- exp(-mean_chborn)

  # Compare prop_zero to expected under Negative Binomial
  standard_nb &lt;- glm.nb(chborn_num ~ 1, data = subset_data)
  theta_nb &lt;- standard_nb$theta
  exp_zero_nb &lt;- (theta_nb / (theta_nb + mean_chborn))^theta_nb
  
  zero_inflation[i] &lt;- prop_zero &gt; exp_poisson | prop_zero &gt; exp_zero_nb
  
  # Store the results in the EDA_df
  EDA_df &lt;- rbind(
    EDA_df,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      Age_Range = unique(subset_data$AGE_RANGE),
      Overdispersion = overdispersion[i], 
      Zero_Inflation = zero_inflation[i],
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<pre class="r"><code>EDA_df$model &lt;- NA  # Create an empty column for the model

for(i in 1:nrow(EDA_df)) {
  if(EDA_df$Overdispersion[i] &amp; EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Zero-Inflated Negative Binomial&quot;
  } else if(EDA_df$Overdispersion[i] &amp; !EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Negative Binomial&quot;
  } else if(!EDA_df$Overdispersion[i] &amp; !EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Poisson&quot;
  } else if(!EDA_df$Overdispersion[i] &amp; EDA_df$Zero_Inflation[i]){
    EDA_df$model[i] &lt;- &quot;Zero-Inflated Poisson&quot;  
  }
}

# View the final EDA_df
print(EDA_df)</code></pre>
<pre><code>                     Race Census_Year Age_Range Overdispersion Zero_Inflation
1                   White        1960     40-49           TRUE           TRUE
2                   White        1960     50-59           TRUE           TRUE
3                   White        1960     60-69           TRUE           TRUE
4                   White        1960       70+           TRUE           TRUE
5  Black/African American        1960     40-49           TRUE           TRUE
6  Black/African American        1960     50-59           TRUE           TRUE
7  Black/African American        1960     60-69           TRUE           TRUE
8  Black/African American        1960       70+           TRUE           TRUE
9                   White        1970     40-49           TRUE           TRUE
10                  White        1970     50-59           TRUE           TRUE
11                  White        1970     60-69           TRUE           TRUE
12                  White        1970       70+           TRUE           TRUE
13 Black/African American        1970     40-49           TRUE           TRUE
14 Black/African American        1970     50-59           TRUE           TRUE
15 Black/African American        1970     60-69           TRUE           TRUE
16 Black/African American        1970       70+           TRUE           TRUE
17                  White        1980     40-49           TRUE           TRUE
18                  White        1980     50-59           TRUE           TRUE
19                  White        1980     60-69           TRUE           TRUE
20                  White        1980       70+           TRUE           TRUE
21 Black/African American        1980     40-49           TRUE           TRUE
22 Black/African American        1980     50-59           TRUE           TRUE
23 Black/African American        1980     60-69           TRUE           TRUE
24 Black/African American        1980       70+           TRUE           TRUE
25                  White        1990     40-49          FALSE           TRUE
26                  White        1990     50-59           TRUE           TRUE
27                  White        1990     60-69           TRUE           TRUE
28                  White        1990       70+           TRUE           TRUE
29 Black/African American        1990     40-49           TRUE           TRUE
30 Black/African American        1990     50-59           TRUE           TRUE
31 Black/African American        1990     60-69           TRUE           TRUE
32 Black/African American        1990       70+           TRUE           TRUE
                             model
1  Zero-Inflated Negative Binomial
2  Zero-Inflated Negative Binomial
3  Zero-Inflated Negative Binomial
4  Zero-Inflated Negative Binomial
5  Zero-Inflated Negative Binomial
6  Zero-Inflated Negative Binomial
7  Zero-Inflated Negative Binomial
8  Zero-Inflated Negative Binomial
9  Zero-Inflated Negative Binomial
10 Zero-Inflated Negative Binomial
11 Zero-Inflated Negative Binomial
12 Zero-Inflated Negative Binomial
13 Zero-Inflated Negative Binomial
14 Zero-Inflated Negative Binomial
15 Zero-Inflated Negative Binomial
16 Zero-Inflated Negative Binomial
17 Zero-Inflated Negative Binomial
18 Zero-Inflated Negative Binomial
19 Zero-Inflated Negative Binomial
20 Zero-Inflated Negative Binomial
21 Zero-Inflated Negative Binomial
22 Zero-Inflated Negative Binomial
23 Zero-Inflated Negative Binomial
24 Zero-Inflated Negative Binomial
25           Zero-Inflated Poisson
26 Zero-Inflated Negative Binomial
27 Zero-Inflated Negative Binomial
28 Zero-Inflated Negative Binomial
29 Zero-Inflated Negative Binomial
30 Zero-Inflated Negative Binomial
31 Zero-Inflated Negative Binomial
32 Zero-Inflated Negative Binomial</code></pre>
<pre class="r"><code>## Approach 2
# Initialize the data frame to store results
best_models &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  Age_Range = character(),
  AIC_poisson = numeric(),
  AIC_nb = numeric(),
  AIC_zip = numeric(),
  AIC_zinb = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each subset of data
for (i in seq_along(combinations)) {
  subset_data &lt;- combinations[[i]]
  
  # Fit Poisson model
  poisson_model &lt;- glm(chborn_num ~ 1, family = poisson, data = subset_data)
  # Fit Negative Binomial model
  nb_model &lt;- glm.nb(chborn_num ~ 1, data = subset_data)

  # Fit Zero-Inflated Poisson model
  zip_model &lt;- zeroinfl(chborn_num ~ 1 | 1, data = subset_data, dist = &quot;poisson&quot;)

  # Fit Zero-Inflated Negative Binomial model
  zinb_model &lt;- zeroinfl(chborn_num ~ 1 | 1, data = subset_data, dist = &quot;negbin&quot;)
  
  # Append the result to the best_models data frame
  best_models &lt;- rbind(
    best_models,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      Age_Range = unique(subset_data$AGE_RANGE),
      AIC_poisson = AIC(poisson_model),
      AIC_nb = AIC(nb_model),
      AIC_zip = AIC(zip_model),
      AIC_zinb = AIC(zinb_model),
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<pre class="r"><code># Add a Best_Model column to store the best model based on minimum AIC
best_models$Best_Model &lt;- apply(best_models, 1, function(row) {
  # Get AIC values for Poisson, NB, ZIP, and ZINB models
  aic_values &lt;- c(Poisson = as.numeric(row[&#39;AIC_poisson&#39;]),
                  Negative_Binomial = as.numeric(row[&#39;AIC_nb&#39;]),
                  Zero_Inflated_Poisson = as.numeric(row[&#39;AIC_zip&#39;]),
                  Zero_Inflated_NB= as.numeric(row[&#39;AIC_zinb&#39;]))
  
  # Find the name of the model with the minimum AIC value
  best_model &lt;- names(which.min(aic_values))
  
  return(best_model)
})

best_models &lt;- best_models %&gt;% dplyr::select(Race, Census_Year, Age_Range, Best_Model)
# View the updated table with the Best_Model column
print(best_models)</code></pre>
<pre><code>                     Race Census_Year Age_Range            Best_Model
1                   White        1960     40-49      Zero_Inflated_NB
2                   White        1960     50-59      Zero_Inflated_NB
3                   White        1960     60-69      Zero_Inflated_NB
4                   White        1960       70+      Zero_Inflated_NB
5  Black/African American        1960     40-49      Zero_Inflated_NB
6  Black/African American        1960     50-59      Zero_Inflated_NB
7  Black/African American        1960     60-69      Zero_Inflated_NB
8  Black/African American        1960       70+      Zero_Inflated_NB
9                   White        1970     40-49      Zero_Inflated_NB
10                  White        1970     50-59      Zero_Inflated_NB
11                  White        1970     60-69      Zero_Inflated_NB
12                  White        1970       70+      Zero_Inflated_NB
13 Black/African American        1970     40-49      Zero_Inflated_NB
14 Black/African American        1970     50-59      Zero_Inflated_NB
15 Black/African American        1970     60-69      Zero_Inflated_NB
16 Black/African American        1970       70+      Zero_Inflated_NB
17                  White        1980     40-49 Zero_Inflated_Poisson
18                  White        1980     50-59      Zero_Inflated_NB
19                  White        1980     60-69      Zero_Inflated_NB
20                  White        1980       70+      Zero_Inflated_NB
21 Black/African American        1980     40-49      Zero_Inflated_NB
22 Black/African American        1980     50-59      Zero_Inflated_NB
23 Black/African American        1980     60-69      Zero_Inflated_NB
24 Black/African American        1980       70+      Zero_Inflated_NB
25                  White        1990     40-49 Zero_Inflated_Poisson
26                  White        1990     50-59 Zero_Inflated_Poisson
27                  White        1990     60-69      Zero_Inflated_NB
28                  White        1990       70+      Zero_Inflated_NB
29 Black/African American        1990     40-49      Zero_Inflated_NB
30 Black/African American        1990     50-59      Zero_Inflated_NB
31 Black/African American        1990     60-69      Zero_Inflated_NB
32 Black/African American        1990       70+      Zero_Inflated_NB</code></pre>
</div>
<div id="step-3-record-the-best-model-for-each-subset"
class="section level3">
<h3>Step 3: Record the Best Model for Each Subset</h3>
<p>Create a table or data frame where you store the best model for each
combination of race, census year, and age range based on AIC/BIC. For
example:</p>
<table>
<thead>
<tr class="header">
<th>Race</th>
<th>Census Year</th>
<th>Age Range</th>
<th>Best Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1990</td>
<td>40-49</td>
<td>Negative Binomial</td>
</tr>
<tr class="even">
<td>White</td>
<td>1990</td>
<td>40-49</td>
<td>Zero-Inflated NB</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1980</td>
<td>50-59</td>
<td>Poisson</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>(but obviously do this as a dataframe so we can analyze it)</p>
</div>
<div id="step-4-analyze-the-effect-of-race-census-year-and-age-range"
class="section level3">
<h3>Step 4: Analyze the Effect of Race, Census Year, and Age Range</h3>
<p>Once you’ve gathered the best model for each subset, you can analyze
which factor (race, census year, or age range) is most influential in
determining the best-fitting model.</p>
<p><strong>Options for statistical analysis:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Chi-Square Test of Independence</strong>: You can use a
chi-square test to determine whether there is a significant association
between race and the best-fitting model, or census year/age group and
the best-fitting model. This test will help you see if certain races or
age ranges are more likely to have a particular model as the best
fit.</li>
</ol>
<pre class="r"><code>#example
# Need large sample size, warning message &quot;Chi-squared approximation may be incorrect,&quot; usually occurs when some of the expected counts in the contingency table are too small (typically less than 5)
## Create a contingency table
#table_model_race &lt;- table(best_models$Race, best_models$Best_Model)

# Perform chi-square test
#chisq.test(table_model_race)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Logistic Regression</strong>: You could fit a logistic
regression model where the response variable is the best-fitting model
(binary or multinomial) and the predictor variables are race, census
year, and age range. This will allow you to quantify the effect of each
variable on the model choice.</p>
<p><strong>Example in R</strong> (assuming binary outcome: Poisson
vs. NB):</p></li>
</ol>
<pre class="r"><code># Recode Best_Model to a binary variable (e.g., &quot;Zero_Inflated_NB&quot; vs. &quot;Other&quot;)
best_models$Best_Model_Binary &lt;- ifelse(best_models$Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)

# Fit binary logistic regression
model_logistic &lt;- glm(Best_Model_Binary ~ Race + Census_Year + Age_Range, family = binomial(), data = best_models)

# Summary of the logistic regression model
summary(model_logistic)</code></pre>
<pre><code>
Call:
glm(formula = Best_Model_Binary ~ Race + Census_Year + Age_Range, 
    family = binomial(), data = best_models)

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)                 8.741e+03  7.710e+06   0.001    0.999
RaceBlack/African American  8.903e+01  8.227e+04   0.001    0.999
Census_Year                -4.426e+00  3.902e+03  -0.001    0.999
Age_Range50-59              4.390e+01  5.002e+04   0.001    0.999
Age_Range60-69              8.990e+01  1.045e+05   0.001    0.999
Age_Range70+                8.990e+01  1.045e+05   0.001    0.999

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1.9912e+01  on 31  degrees of freedom
Residual deviance: 2.4509e-09  on 26  degrees of freedom
AIC: 12

Number of Fisher Scoring iterations: 25</code></pre>
<p><strong><em>RESULT:</em></strong>The p-value for each variable is
larger than 0.05, indicating non-significant effects on best_model
fitting.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Multinomial Logistic Regression</strong> (if more than
two models): If you have multiple possible best-fitting models (Poisson,
NB, ZIP, ZINB), you can use multinomial logistic regression to assess
the impact of race, census year, and age range on model selection.</p>
<p><strong>Example in R using the <code>nnet</code>
package</strong>:</p></li>
</ol>
<pre class="r"><code>## Not appropriate since only 2 levels in best_model
# Fit multinomial logistic regression
#model_multinom &lt;- multinom(Best_Model ~ Race + Census_Year + Age_Range, data = best_model_data)

# Summary of results
#summary(model_multinom)</code></pre>
</div>
<div id="step-5-summarize-the-results" class="section level3">
<h3>Step 5: Summarize the Results</h3>
<ul>
<li><strong>Significance of Each Variable</strong>: From the regression
analysis (or chi-square tests), you can determine which variable (race,
census year, or age range) has the most significant impact on the model
choice.</li>
<li><strong>Effect Sizes</strong>: Logistic regression will provide
coefficients that describe how much each variable influences the
probability of choosing a particular model.</li>
<li><strong>Best Model by Race</strong>: You can summarize which model
tends to fit best for each race across years and age groups. For
example, you might find that the <strong>Negative Binomial</strong>
model consistently fits the best for a specific race or age group,
indicating more overdispersion in that subset.</li>
</ul>
</div>
<div id="visualize-the-results" class="section level3">
<h3>Visualize the Results</h3>
<p>Finally, visualize the distribution of the best-fitting models across
races, census years, and age groups.</p>
<ul>
<li><strong>Bar Plots</strong>: Show the proportion of each model for
different races or age groups.</li>
<li><strong>Heatmap</strong>: Use a heatmap to visualize how the best
model varies across race, census year, and age range.</li>
</ul>
<p><strong>Example of a simple bar plot in R</strong>:</p>
<pre class="r"><code>model_proportions &lt;- best_models %&gt;%
  group_by(Race, Age_Range, Best_Model) %&gt;%
  summarise(Count = n(), .groups = &quot;drop&quot;) %&gt;%
  group_by(Race, Age_Range) %&gt;%
  mutate(Proportion = Count / sum(Count))

                                                                    ggplot(model_proportions, aes(x = Age_Range, y = Proportion, fill = Best_Model)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;fill&quot;) +
  facet_wrap(~ Race) +
  labs(
    title = &quot;Proportion of Models by Race and Age Group&quot;,
    x = &quot;Age Range&quot;,
    y = &quot;Proportion&quot;,
    fill = &quot;Model&quot;
  ) +
  theme_minimal()</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-11-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-11-1">
Past versions of unnamed-chunk-11-1.png
</button>
</p>
<div id="fig-unnamed-chunk-11-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/docs/figure/relative-distribution.Rmd/unnamed-chunk-11-1.png" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-11-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/docs/figure/relative-distribution.Rmd/unnamed-chunk-11-1.png" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>ggplot(best_models, aes(x = Census_Year, y = Age_Range, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + 
  facet_wrap(~Race, nrow = 2) +  
  scale_fill_manual(values = c(&quot;Zero_Inflated_Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;)) + 
  labs(
    title = &quot;Best Model by Race, Census Year, and Age Range&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Age Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-12-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-12-1">
Past versions of unnamed-chunk-12-1.png
</button>
</p>
<div id="fig-unnamed-chunk-12-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-12-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/docs/figure/relative-distribution.Rmd/unnamed-chunk-12-1.png" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion:</h3>
<ul>
<li><strong>Best Model Analysis</strong>: The best-fitting model can be
assessed across different races, census years, and age ranges by
comparing models using AIC/BIC.</li>
<li><strong>Significance Testing</strong>: Use chi-square or logistic
regression to assess which variable most influences the model
selection.</li>
<li><strong>Summarizing Across Years</strong>: After analyzing the data,
you’ll be able to conclude which model fits each race best across
different years, and whether race, census year, or age group is the
dominant factor.</li>
</ul>
<p><strong><em>CONCLUSION:</em></strong> The logistics regression shows
that there isn’t a significant association between the predictors(races,
age ranges, and census year) and the best-fitting model. According to
the resulting visualization, the ZINB model is the best fit for the
black population across census year and age group. However, the ZINB
model perform the best among the white population only across year 1960
and 1970, and age group 60-69 and 70+.</p>
</div>
</div>
<div id="instructions-for-manqing-cohort-stability-analysis"
class="section level2">
<h2>[Instructions for Manqing] Cohort Stability Analysis</h2>
<p>For Question 2: <strong>Cohort Stability Analysis</strong>, the goal
is to determine if there is a significant change in <strong>zero
inflation</strong>, <strong>family size</strong>, or <strong>model
fit</strong> for the same cohort across different census years, given
race.</p>
<div id="step-1-add-a-birth-year-cohort-variable"
class="section level3">
<h3>Step 1: Add a Birth-Year “Cohort” Variable</h3>
<p>Using the existing table of model summaries, calculate the
<strong>birth-year cohort</strong> based on the <strong>Census
Year</strong> and <strong>Age Range</strong>. For example, if a woman is
in the 40-49 age range in the 1990 Census, her birth cohort would be
<strong>1941-1950</strong>.</p>
<ul>
<li><strong>Formula to Calculate Cohort:</strong> For each row in the
table, subtract the age range from the census year to get the cohort.
For example:
<ul>
<li>Census Year: 1990</li>
<li>Age Range: 40-49</li>
<li>Cohort: 1990 - (40 to 49) → <strong>Cohort: 1941-1950</strong></li>
</ul></li>
<li>Add a new column to the summary table called
<code>Cohort</code>.</li>
</ul>
<p><strong>Example Table:</strong></p>
<table>
<colgroup>
<col width="24%" />
<col width="16%" />
<col width="14%" />
<col width="24%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th>Race</th>
<th>Census Year</th>
<th>Age Range</th>
<th>Best Model</th>
<th>Cohort</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1990</td>
<td>40-49</td>
<td>Negative Binomial</td>
<td>1941-1950</td>
</tr>
<tr class="even">
<td>White</td>
<td>1990</td>
<td>40-49</td>
<td>Zero-Inflated NB</td>
<td>1941-1950</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1980</td>
<td>50-59</td>
<td>Poisson</td>
<td>1921-1930</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<pre class="r"><code>calculate_cohort &lt;- function(census_year, age_range) {
  age_limits &lt;- as.numeric(unlist(strsplit(age_range, &quot;-|\\+&quot;)))
  
  if (length(age_limits) == 1) {
    lower_age &lt;- age_limits
    upper_age &lt;- Inf  
  } else {
    lower_age &lt;- age_limits[1]
    upper_age &lt;- age_limits[2]
  }
  
  lower_cohort &lt;- census_year - upper_age
  upper_cohort &lt;- census_year - lower_age
  
  
  if (upper_age == Inf) {
    upper_cohort &lt;- census_year - 70
  }
  
  return(paste(lower_cohort, upper_cohort, sep = &quot;-&quot;))
}

best_models &lt;- best_models %&gt;%
  mutate(Cohort = mapply(calculate_cohort, Census_Year, Age_Range)) %&gt;% 
  dplyr::select(Race, Census_Year, Age_Range, Best_Model, Cohort)

print(best_models)</code></pre>
<pre><code>                     Race Census_Year Age_Range            Best_Model    Cohort
1                   White        1960     40-49      Zero_Inflated_NB 1911-1920
2                   White        1960     50-59      Zero_Inflated_NB 1901-1910
3                   White        1960     60-69      Zero_Inflated_NB 1891-1900
4                   White        1960       70+      Zero_Inflated_NB -Inf-1890
5  Black/African American        1960     40-49      Zero_Inflated_NB 1911-1920
6  Black/African American        1960     50-59      Zero_Inflated_NB 1901-1910
7  Black/African American        1960     60-69      Zero_Inflated_NB 1891-1900
8  Black/African American        1960       70+      Zero_Inflated_NB -Inf-1890
9                   White        1970     40-49      Zero_Inflated_NB 1921-1930
10                  White        1970     50-59      Zero_Inflated_NB 1911-1920
11                  White        1970     60-69      Zero_Inflated_NB 1901-1910
12                  White        1970       70+      Zero_Inflated_NB -Inf-1900
13 Black/African American        1970     40-49      Zero_Inflated_NB 1921-1930
14 Black/African American        1970     50-59      Zero_Inflated_NB 1911-1920
15 Black/African American        1970     60-69      Zero_Inflated_NB 1901-1910
16 Black/African American        1970       70+      Zero_Inflated_NB -Inf-1900
17                  White        1980     40-49 Zero_Inflated_Poisson 1931-1940
18                  White        1980     50-59      Zero_Inflated_NB 1921-1930
19                  White        1980     60-69      Zero_Inflated_NB 1911-1920
20                  White        1980       70+      Zero_Inflated_NB -Inf-1910
21 Black/African American        1980     40-49      Zero_Inflated_NB 1931-1940
22 Black/African American        1980     50-59      Zero_Inflated_NB 1921-1930
23 Black/African American        1980     60-69      Zero_Inflated_NB 1911-1920
24 Black/African American        1980       70+      Zero_Inflated_NB -Inf-1910
25                  White        1990     40-49 Zero_Inflated_Poisson 1941-1950
26                  White        1990     50-59 Zero_Inflated_Poisson 1931-1940
27                  White        1990     60-69      Zero_Inflated_NB 1921-1930
28                  White        1990       70+      Zero_Inflated_NB -Inf-1920
29 Black/African American        1990     40-49      Zero_Inflated_NB 1941-1950
30 Black/African American        1990     50-59      Zero_Inflated_NB 1931-1940
31 Black/African American        1990     60-69      Zero_Inflated_NB 1921-1930
32 Black/African American        1990       70+      Zero_Inflated_NB -Inf-1920</code></pre>
</div>
<div id="step-2-compute-summary-statistics-for-each-subset"
class="section level3">
<h3>Step 2: Compute Summary Statistics for Each Subset</h3>
<p>For each combination of <strong>Race</strong>,
<strong>Cohort</strong>, and <strong>Census Year</strong>, compute
additional summary statistics for family size distributions: -
<strong>Mean</strong>, <strong>Variance</strong>, <strong>Mode</strong>
of the number of children. - <strong>Probability</strong> of having 0,
1, 2, …, 12+ children (empirical or from the best-fitting model).</p>
<p>These statistics will help quantify family size changes over
time.</p>
<p><strong>Example Summary Table:</strong></p>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="11%" />
<col width="9%" />
<col width="14%" />
<col width="5%" />
<col width="7%" />
<col width="4%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="3%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Race</th>
<th>Cohort</th>
<th>Census Year</th>
<th>Best Model</th>
<th>Mean</th>
<th>Variance</th>
<th>Mode</th>
<th>Prob(0)</th>
<th>Prob(1)</th>
<th>Prob(2)</th>
<th>…</th>
<th>Prob(12+)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1941-1950</td>
<td>1990</td>
<td>Negative Binomial</td>
<td>2.5</td>
<td>1.2</td>
<td>2</td>
<td>0.20</td>
<td>0.30</td>
<td>0.25</td>
<td>…</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>White</td>
<td>1941-1950</td>
<td>1990</td>
<td>Zero-Inflated NB</td>
<td>2.1</td>
<td>1.0</td>
<td>2</td>
<td>0.35</td>
<td>0.28</td>
<td>0.20</td>
<td>…</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1921-1930</td>
<td>1980</td>
<td>Poisson</td>
<td>3.0</td>
<td>1.5</td>
<td>3</td>
<td>0.15</td>
<td>0.25</td>
<td>0.30</td>
<td>…</td>
<td>0.05</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<pre class="r"><code>df_merg &lt;- df %&gt;%
  rename(Census_Year = YEAR, Race = RACE, Age_Range = AGE_RANGE)

# Perform a left join to merge the data frames
merged_data &lt;- left_join(df_merg, best_models, by = c(&quot;Race&quot;, &quot;Census_Year&quot;, &quot;Age_Range&quot;))</code></pre>
<pre class="r"><code>calculate_mode &lt;- function(x) {
  ux &lt;- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_table &lt;- merged_data %&gt;% group_by(Race, Cohort, Census_Year) %&gt;%
  summarise(
    Mean = mean(chborn_num),
    Variance = var(chborn_num),
    Mode = calculate_mode(chborn_num),
    Prob_0 = mean(chborn_num == 0),
    Prob_1 = mean(chborn_num == 1),
    Prob_2 = mean(chborn_num == 2),
    Prob_3 = mean(chborn_num == 3),
    Prob_4 = mean(chborn_num == 4),
    Prob_5 = mean(chborn_num == 5),
    Prob_6 = mean(chborn_num == 6),
    Prob_7 = mean(chborn_num == 7),
    Prob_8 = mean(chborn_num == 8),
    Prob_9 = mean(chborn_num == 9),
    Prob_10 = mean(chborn_num == 10),
    Prob_11 = mean(chborn_num == 11),
    Prob_12plus = mean(chborn_num &gt;= 12)
    #Total_Prob = Prob_0 + Prob_1 + Prob_2 + Prob_3 + Prob_4 + Prob_5 + Prob_6 + 
                # Prob_7 + Prob_8 + Prob_9 + Prob_10 + Prob_11 + Prob_12plus
  ) %&gt;%
  ungroup() %&gt;% as.data.frame()</code></pre>
<pre><code>`summarise()` has grouped output by &#39;Race&#39;, &#39;Cohort&#39;. You can override using
the `.groups` argument.</code></pre>
<pre class="r"><code># View the summary table
print(summary_table)</code></pre>
<pre><code>                     Race    Cohort Census_Year     Mean  Variance Mode
1                   White -Inf-1890        1960 3.295149  8.035775    2
2                   White -Inf-1900        1970 2.619220  6.411794    0
3                   White -Inf-1910        1980 2.259255  4.905316    0
4                   White -Inf-1920        1990 2.310209  4.125397    2
5                   White 1891-1900        1960 2.749532  6.109824    2
6                   White 1901-1910        1960 2.357718  4.870047    2
7                   White 1901-1910        1970 2.198574  4.786569    0
8                   White 1911-1920        1960 2.383745  3.784971    2
9                   White 1911-1920        1970 2.290355  3.947823    2
10                  White 1911-1920        1980 2.299697  3.885418    2
11                  White 1921-1930        1970 2.697188  3.906783    2
12                  White 1921-1930        1980 2.728259  3.886124    2
13                  White 1921-1930        1990 2.796851  3.950610    2
14                  White 1931-1940        1980 2.901081  3.393930    2
15                  White 1931-1940        1990 2.894691  3.351678    2
16                  White 1941-1950        1990 2.204755  2.090623    2
17 Black/African American -Inf-1890        1960 3.902162 13.245048    0
18 Black/African American -Inf-1900        1970 3.087770 10.564482    0
19 Black/African American -Inf-1910        1980 2.613889  9.158011    0
20 Black/African American -Inf-1920        1990 2.856028  9.809749    0
21 Black/African American 1891-1900        1960 3.166572 10.973569    0
22 Black/African American 1901-1910        1960 2.741205  9.730068    0
23 Black/African American 1901-1910        1970 2.618036  9.023970    0
24 Black/African American 1911-1920        1960 2.820761  9.475099    0
25 Black/African American 1911-1920        1970 2.795064  9.124200    0
26 Black/African American 1911-1920        1980 2.817014  9.453284    0
27 Black/African American 1921-1930        1970 3.411675  9.564633    0
28 Black/African American 1921-1930        1980 3.400445  9.646242    0
29 Black/African American 1921-1930        1990 3.643816 10.234543    0
30 Black/African American 1931-1940        1980 3.721409  7.972764    3
31 Black/African American 1931-1940        1990 3.723892  7.741557    2
32 Black/African American 1941-1950        1990 2.690402  3.955388    2
      Prob_0     Prob_1    Prob_2     Prob_3     Prob_4     Prob_5     Prob_6
1  0.1601171 0.14383842 0.1735320 0.14095304 0.10820180 0.07719472 0.05585582
2  0.2337344 0.15563563 0.1907270 0.13766146 0.09400089 0.06100962 0.04147614
3  0.2425410 0.17905944 0.2217025 0.14213617 0.08185637 0.04957835 0.03016161
4  0.2003224 0.17086054 0.2495743 0.16517318 0.09503183 0.05020253 0.02764322
5  0.1790942 0.17183505 0.2064320 0.14997168 0.10013557 0.06473203 0.04249112
6  0.2000759 0.19774610 0.2351671 0.14591432 0.08571877 0.04872973 0.03009123
7  0.2484123 0.18579166 0.2226615 0.13859746 0.08031093 0.04560480 0.02848213
8  0.1548323 0.18555184 0.2691760 0.17613893 0.09801059 0.05041189 0.02763336
9  0.1967171 0.16973904 0.2562944 0.16982255 0.09505741 0.04905532 0.02524530
10 0.1926550 0.16842906 0.2583952 0.17291618 0.09513579 0.04901138 0.02691150
11 0.1351880 0.12673286 0.2507330 0.20721415 0.13102862 0.06863779 0.03679984
12 0.1318459 0.12042477 0.2503092 0.21324354 0.13229042 0.07044023 0.03706567
13 0.1234195 0.11569770 0.2477657 0.21626065 0.13752802 0.07369103 0.03953569
14 0.1037357 0.09351712 0.2399871 0.23964134 0.16043259 0.08265468 0.04216199
15 0.1031027 0.09122701 0.2441949 0.24135347 0.15966028 0.08278604 0.04035221
16 0.1389518 0.13595406 0.3532313 0.22043189 0.09474345 0.03452663 0.01315010
17 0.1979522 0.14761092 0.1242890 0.08902162 0.08447099 0.05830489 0.06058020
18 0.2601452 0.16502234 0.1285369 0.09959047 0.08460536 0.05835815 0.04579300
19 0.3019568 0.19414247 0.1310909 0.09464126 0.06778360 0.04744852 0.03824018
20 0.2758865 0.18308004 0.1298886 0.09979737 0.07163121 0.05420466 0.04346505
21 0.2480664 0.17732503 0.1284663 0.09677419 0.07508017 0.05715903 0.04584041
22 0.2864718 0.19580962 0.1319193 0.09169684 0.07281428 0.04837041 0.03879979
23 0.2998207 0.18659938 0.1367953 0.09436218 0.07231556 0.05491733 0.03625739
24 0.2685870 0.18750000 0.1383696 0.09891304 0.07510870 0.05206522 0.04413043
25 0.2644968 0.18741749 0.1396872 0.10373718 0.07936427 0.05255408 0.04305880
26 0.2708013 0.17914380 0.1436883 0.10406147 0.07178924 0.05433589 0.04368825
27 0.1825328 0.15683751 0.1417145 0.12075385 0.09643760 0.07621236 0.05796369
28 0.1890040 0.15089492 0.1437869 0.12280552 0.09454483 0.07185065 0.05917616
29 0.1674815 0.14605222 0.1425153 0.11640487 0.09497555 0.07968376 0.06407989
30 0.1190148 0.12667930 0.1436445 0.14424733 0.12435412 0.10032725 0.07543920
31 0.1110096 0.12261307 0.1537688 0.14536318 0.13001370 0.09821836 0.07747830
32 0.1258126 0.15923518 0.2409178 0.18860421 0.12466539 0.07319312 0.04221797
        Prob_7      Prob_8       Prob_9      Prob_10      Prob_11  Prob_12plus
1  0.041084387 0.034021662 0.0232983786 0.0170538963 0.0107017506 0.0141469822
2  0.027730366 0.021085755 0.0136685140 0.0098475111 0.0061248428 0.0072978345
3  0.018016649 0.012731042 0.0087478429 0.0054809686 0.0032668743 0.0047212303
4  0.015665041 0.009936348 0.0059849549 0.0041084566 0.0023807556 0.0031164752
5  0.028642035 0.019752536 0.0133514098 0.0101079439 0.0054400988 0.0080142781
6  0.019685606 0.013481499 0.0084292090 0.0063219068 0.0035732517 0.0050653787
7  0.016949039 0.011846964 0.0078935242 0.0056162892 0.0031186767 0.0047147446
8  0.015027420 0.008985590 0.0057688199 0.0033710799 0.0022909100 0.0028013199
9  0.014739040 0.009003132 0.0055114823 0.0034551148 0.0020929019 0.0032672234
10 0.013830609 0.009086128 0.0053711101 0.0032338559 0.0018127497 0.0032114763
11 0.018971640 0.010663352 0.0060738619 0.0036086503 0.0017938349 0.0025543789
12 0.019924245 0.010812430 0.0055849728 0.0036524562 0.0019035288 0.0025026089
13 0.019747920 0.011179196 0.0063567977 0.0038260350 0.0019827629 0.0030090171
14 0.019447458 0.009181204 0.0046502200 0.0023370336 0.0011565932 0.0010969750
15 0.019026010 0.009492189 0.0043714027 0.0021336608 0.0010720345 0.0012281560
16 0.005115379 0.002117610 0.0008191578 0.0004008645 0.0002875767 0.0002701478
17 0.047781570 0.044368601 0.0346985210 0.0315699659 0.0236063709 0.0557451650
18 0.037043931 0.029318690 0.0252233805 0.0209419211 0.0134028295 0.0320178704
19 0.034531270 0.023404527 0.0170098478 0.0170098478 0.0092083387 0.0235324210
20 0.037082067 0.029078014 0.0217831814 0.0163120567 0.0094224924 0.0283687943
21 0.039615167 0.034899076 0.0239577438 0.0260328240 0.0130164120 0.0337672137
22 0.029487843 0.028711847 0.0210812209 0.0165545784 0.0102172788 0.0280651837
23 0.029749651 0.023109104 0.0184607212 0.0138787436 0.0094959825 0.0242379972
24 0.035434783 0.026847826 0.0191304348 0.0186956522 0.0103260870 0.0248913043
25 0.031938662 0.028688941 0.0201076470 0.0160454961 0.0108662537 0.0220371687
26 0.031503842 0.025795829 0.0222832053 0.0171240395 0.0107574094 0.0250274424
27 0.049046196 0.036037692 0.0242702827 0.0204091014 0.0130085038 0.0247759136
28 0.047529331 0.036139419 0.0262053610 0.0196968399 0.0139590648 0.0244069538
29 0.052637054 0.039633829 0.0263185270 0.0241339852 0.0160199730 0.0300634557
30 0.057698932 0.040475370 0.0259214606 0.0170513262 0.0102480193 0.0148983810
31 0.055824577 0.039013248 0.0278666058 0.0152581087 0.0074920055 0.0160804020
32 0.020573614 0.012848948 0.0061185468 0.0022944551 0.0014531549 0.0020650096</code></pre>
</div>
<div
id="step-3-test-for-significant-changes-over-time-within-each-cohort"
class="section level3">
<h3>Step 3: Test for Significant Changes Over Time Within Each
Cohort</h3>
<p>Once the cohort information and summary statistics are available, the
goal is to determine if there is a <strong>significant change</strong>
in any of the following across census years for the same cohort:</p>
<ol style="list-style-type: decimal">
<li><strong>Zero Inflation</strong>: Check if the proportion of women
with zero children changes significantly over time for the same
cohort.</li>
<li><strong>Family Size</strong>: Test if the mean or variance in the
number of children changes for the same cohort over time.</li>
<li><strong>Model Fit</strong>: Analyze if the best-fitting model for
the cohort changes over time.</li>
</ol>
<div id="a.-zero-inflation-analysis" class="section level4">
<h4>a. <strong>Zero-Inflation Analysis</strong></h4>
<ul>
<li><p>Use a <strong>logistic regression</strong> model to assess if the
probability of having zero children changes significantly over time for
the same cohort.</p>
<p><strong>Example Code</strong>:</p></li>
</ul>
<pre class="r"><code>## divided the corhort by race
merged_df_black &lt;- merged_data %&gt;% filter(Race == &quot;Black/African American&quot;)
merged_df_white &lt;- merged_data %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code># Data frame to store proportions
proportions_df_b &lt;- data.frame(Cohort = character(), Census_Year = character(), 
                             Proportion_Zero_Children = numeric(), Race = character(), stringsAsFactors = FALSE)

# Filter cohorts with more than one census year
cohort_counts &lt;- merged_df_black %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test &lt;- cohort_counts$Cohort

# Initialize results data frame
results_black &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test) {
  cohort_data &lt;- merged_df_black %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$chborn_num == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_black &lt;- rbind(results_black, data.frame(
      RACE = &quot;Black/African American&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
    
    # proportion across year
    proportions &lt;- cohort_data %&gt;%
      group_by(Census_Year) %&gt;%
      summarise(Proportion_Zero_Children = mean(chborn_num == &quot;0&quot;))
    
    proportions$Cohort &lt;- cohort
    proportions$Race &lt;- &quot;Black&quot;
    
    # Combine into one data frame
    proportions_df_b &lt;- rbind(proportions_df_b, proportions)
  
    # Print proportions for review
    print(paste(&quot;Proportions for cohort:&quot;, cohort))
    print(proportions)
  }
}</code></pre>
<pre><code>[1] &quot;Proportions for cohort: 1901-1910&quot;
# A tibble: 2 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1960                    0.286 1901-1910 Black
2        1970                    0.300 1901-1910 Black
[1] &quot;Proportions for cohort: 1911-1920&quot;
# A tibble: 3 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1960                    0.269 1911-1920 Black
2        1970                    0.264 1911-1920 Black
3        1980                    0.271 1911-1920 Black
[1] &quot;Proportions for cohort: 1921-1930&quot;
# A tibble: 3 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1970                    0.183 1921-1930 Black
2        1980                    0.189 1921-1930 Black
3        1990                    0.167 1921-1930 Black
[1] &quot;Proportions for cohort: 1931-1940&quot;
# A tibble: 2 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1980                    0.119 1931-1940 Black
2        1990                    0.111 1931-1940 Black</code></pre>
<pre class="r"><code>results_black &lt;- results_black %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_black)</code></pre>
<pre><code>                             RACE    Cohort Chi_Square      p_value
X-squared  Black/African American 1901-1910   4.310851 0.0378700083
X-squared1 Black/African American 1911-1920   1.421550 0.4912633533
X-squared2 Black/African American 1921-1930  17.245995 0.0001799202
X-squared3 Black/African American 1931-1940   3.466056 0.0626405054
           Significance
X-squared           Yes
X-squared1           No
X-squared2          Yes
X-squared3           No</code></pre>
<pre class="r"><code># Function to determine the nature of change
determine_nature_of_change &lt;- function(proportions) {
  if (nrow(proportions) &gt; 1) {
    if (all(diff(proportions$Proportion_Zero_Children) &gt; 0)) {
      return(&quot;Increase&quot;)
    } else if (all(diff(proportions$Proportion_Zero_Children) &lt; 0)) {
      return(&quot;Decrease&quot;)
    } else {
      return(&quot;Mixed/No Change&quot;)
    }
  } else {
    return(&quot;Not Applicable&quot;)
  }
}

# Add the Nature_of_Change column
results_black$Nature_of_Change &lt;- NA  # Initialize the column

# Loop through each cohort in results_black
for (i in 1:nrow(results_black)) {
  cohort &lt;- results_black$Cohort[i]
  cohort_data &lt;- merged_df_black %&gt;% filter(Cohort == cohort)
  
  # Calculate proportions for the cohort
  proportions &lt;- cohort_data %&gt;%
    group_by(Census_Year) %&gt;%
    summarise(Proportion_Zero_Children = mean(chborn_num == &quot;0&quot;))
    
  # Determine nature of change
  results_black$Nature_of_Change[i] &lt;- determine_nature_of_change(proportions)
}

# View the updated results_black
print(results_black)</code></pre>
<pre><code>                             RACE    Cohort Chi_Square      p_value
X-squared  Black/African American 1901-1910   4.310851 0.0378700083
X-squared1 Black/African American 1911-1920   1.421550 0.4912633533
X-squared2 Black/African American 1921-1930  17.245995 0.0001799202
X-squared3 Black/African American 1931-1940   3.466056 0.0626405054
           Significance Nature_of_Change
X-squared           Yes         Increase
X-squared1           No  Mixed/No Change
X-squared2          Yes  Mixed/No Change
X-squared3           No         Decrease</code></pre>
<pre class="r"><code># Data frame to store proportions
proportions_df_w &lt;- data.frame(Cohort = character(), Census_Year = character(), 
                             Proportion_Zero_Children = numeric(), Race = character(), stringsAsFactors = FALSE)

# Filter cohorts with more than one census year
cohort_counts2 &lt;- merged_df_white %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test2 &lt;- cohort_counts2$Cohort

# Initialize results data frame
results_white &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test2) {
  cohort_data &lt;- merged_df_white %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$chborn_num == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_white &lt;- rbind(results_white, data.frame(
      RACE = &quot;White&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
    
    # proportion across year
    proportions &lt;- cohort_data %&gt;%
      group_by(Census_Year) %&gt;%
      summarise(Proportion_Zero_Children = mean(chborn_num == &quot;0&quot;))
    
    proportions$Cohort &lt;- cohort
    proportions$Race &lt;- &quot;White&quot;
    
    # Combine into one data frame
    proportions_df_w &lt;- rbind(proportions_df_w, proportions)
  
    # Print proportions for review
    print(paste(&quot;Proportions for cohort:&quot;, cohort))
    print(proportions)
  }
}</code></pre>
<pre><code>[1] &quot;Proportions for cohort: 1901-1910&quot;
# A tibble: 2 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1960                    0.200 1901-1910 White
2        1970                    0.248 1901-1910 White
[1] &quot;Proportions for cohort: 1911-1920&quot;
# A tibble: 3 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1960                    0.155 1911-1920 White
2        1970                    0.197 1911-1920 White
3        1980                    0.193 1911-1920 White
[1] &quot;Proportions for cohort: 1921-1930&quot;
# A tibble: 3 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1970                    0.135 1921-1930 White
2        1980                    0.132 1921-1930 White
3        1990                    0.123 1921-1930 White
[1] &quot;Proportions for cohort: 1931-1940&quot;
# A tibble: 2 × 4
  Census_Year Proportion_Zero_Children Cohort    Race 
        &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
1        1980                    0.104 1931-1940 White
2        1990                    0.103 1931-1940 White</code></pre>
<pre class="r"><code>results_white &lt;- results_white %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_white)</code></pre>
<pre><code>            RACE    Cohort  Chi_Square       p_value Significance
X-squared  White 1901-1910 662.9400598 3.427247e-146          Yes
X-squared1 White 1911-1920 711.8344845 2.673657e-155          Yes
X-squared2 White 1921-1930  80.1733778  3.895581e-18          Yes
X-squared3 White 1931-1940   0.1867867  6.656046e-01           No</code></pre>
<pre class="r"><code># Add the Nature_of_Change column
results_white$Nature_of_Change &lt;- NA  # Initialize the column

# Loop through each cohort in results_white
for (i in 1:nrow(results_white)) {
  cohort &lt;- results_white$Cohort[i]
  cohort_data &lt;- merged_df_white %&gt;% filter(Cohort == cohort)
  
  # Calculate proportions for the cohort
  proportions &lt;- cohort_data %&gt;%
    group_by(Census_Year) %&gt;%
    summarise(Proportion_Zero_Children = mean(chborn_num == &quot;0&quot;))
  
  # Determine nature of change
  results_white$Nature_of_Change[i] &lt;- determine_nature_of_change(proportions)
}

# View the updated results_white
print(results_white)</code></pre>
<pre><code>            RACE    Cohort  Chi_Square       p_value Significance
X-squared  White 1901-1910 662.9400598 3.427247e-146          Yes
X-squared1 White 1911-1920 711.8344845 2.673657e-155          Yes
X-squared2 White 1921-1930  80.1733778  3.895581e-18          Yes
X-squared3 White 1931-1940   0.1867867  6.656046e-01           No
           Nature_of_Change
X-squared          Increase
X-squared1  Mixed/No Change
X-squared2         Decrease
X-squared3         Decrease</code></pre>
<pre class="r"><code># Combine the two data frames
combined_result &lt;- rbind(results_black, results_white)

# Create the plot
ggplot(combined_result, aes(x = Cohort, y = p_value, color = RACE, shape = Significance)) +
  geom_point(size = 2) +
  geom_line(aes(group = RACE)) +
    annotate(&quot;text&quot;, x = Inf, y = 0.05, label = &quot;p = 0.05&quot;, hjust = 1.1, vjust = -0.5, color = &quot;red&quot;, size = 3) +
  geom_hline(yintercept = 0.05, linetype = &quot;dashed&quot;, color = &quot;red&quot;, size = 0.5) + 
  scale_y_log10() +  # Use log scale for better visualization if p-values vary widely
  labs(
    title = &quot;Change of p-values by Cohort&quot;,
    x = &quot;Cohort&quot;,
    y = &quot;p-value (log scale)&quot;,
    color = &quot;Race&quot;,
    shape = &quot;Significance&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-21-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-21-1">
Past versions of unnamed-chunk-21-1.png
</button>
</p>
<div id="fig-unnamed-chunk-21-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/231390a7e9b5261ed01047322fdbca2676183be9/docs/figure/relative-distribution.Rmd/unnamed-chunk-21-1.png" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-21-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/docs/figure/relative-distribution.Rmd/unnamed-chunk-21-1.png" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong><em>RESULT:</em></strong> The graph shows that there is a
discrepancy in the p-value within the cohorts like 1901-1910, 1911-1920
and 1921-1930 by race. However, in cohort 1931-1941, the p-value of each
race is pretty close to each other. The overall trend of the p-value for
black population is stable across cohort, while the trend for white
population fluctuate a lot.</p>
<pre class="r"><code>ggplot(combined_result, aes(x = Cohort, y = Chi_Square, color = RACE)) +
  geom_point(size = 3) +
  geom_line(aes(group = RACE)) +
  labs(
    title = &quot;Change of Test Statistics by Cohort&quot;,
    x = &quot;Cohort&quot;,
    y = &quot;Chi-Square&quot;,
    color = &quot;Race&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-22-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-22-1">
Past versions of unnamed-chunk-22-1.png
</button>
</p>
<div id="fig-unnamed-chunk-22-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-22-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/docs/figure/relative-distribution.Rmd/unnamed-chunk-22-1.png" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong><em>CONCLUSION:</em></strong> We observe that the proportion
of women with zero children change significantly across census year in
the following cohort by race: -black population:1901-1910, 1921-1930
-white population:1901-1910, 1911-1920, 1921-1930</p>
</div>
<div id="b.-family-size-analysis" class="section level4">
<h4>b. <strong>Family Size Analysis</strong></h4>
<ul>
<li><p>Use an <strong>ANOVA</strong> or <strong>linear
regression</strong> to test if the mean or variance in family size
changes over census years for the same cohort.</p>
<p><strong>Example Code</strong>:</p></li>
</ul>
<pre class="r"><code>  # Fit linear model to check for changes in family size over time
  #family_size_model &lt;- lm(Mean ~ Census_Year, data = summary_table)
  
  # ANOVA to check for significant differences in mean
  #anova(family_size_model)</code></pre>
<pre class="r"><code>merged_data2 &lt;- left_join(merged_data, summary_table, by = c(&quot;Race&quot;,&quot;Cohort&quot;,&quot;Census_Year&quot;)) %&gt;% dplyr::select(Race, Cohort, Census_Year, Mean, Variance)
merged_black = merged_data2 %&gt;% filter(Race == &quot;Black/African American&quot;)
merged_white = merged_data2 %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code>cohorts1 &lt;- unique(merged_black$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts1) {
  
  # Filter data for the specific cohort
  cohort_data_b &lt;- merged_black[merged_black$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_b$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_b)
  
  # Perform ANOVA for Variance
  anova_variance_result &lt;- aov(Variance ~ factor(Census_Year), data = cohort_data_b)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean Family Size:\n&quot;)
  print(summary(anova_mean_result))
}</code></pre>
<pre><code>
Cohort: 1891-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1911-1920
ANOVA for Mean Family Size:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     2  5.453   2.727 8.507e+23 &lt;2e-16 ***
Residuals           38001  0.000   0.000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1901-1910
ANOVA for Mean Family Size:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     1  77.51   77.51 7.094e+25 &lt;2e-16 ***
Residuals           22789   0.00    0.00                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1890 has only one Census Year. Skipping ANOVA.

Cohort: 1921-1930
ANOVA for Mean Family Size:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     2    417   208.5 4.477e+26 &lt;2e-16 ***
Residuals           43042      0     0.0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1931-1940
ANOVA for Mean Family Size:
                       Df  Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     1 0.03475 0.03475 1.223e+22 &lt;2e-16 ***
Residuals           22555 0.00000 0.00000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1910 has only one Census Year. Skipping ANOVA.

Cohort: 1941-1950 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1920 has only one Census Year. Skipping ANOVA.</code></pre>
<pre class="r"><code>cohorts2 &lt;- unique(merged_white$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts2) {
  
  # Filter data for the specific cohort
  cohort_data_w &lt;- merged_white[merged_white$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_w$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_w)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean Family Size:\n&quot;)
  print(summary(anova_mean_result))
}</code></pre>
<pre><code>
Cohort: 1891-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1911-1920
ANOVA for Mean Family Size:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      2  535.2   267.6 4.546e+24 &lt;2e-16 ***
Residuals           365210    0.0     0.0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1901-1910
ANOVA for Mean Family Size:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      1   1281    1281 9.604e+25 &lt;2e-16 ***
Residuals           226142      0       0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1890 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1921-1930
ANOVA for Mean Family Size:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      2  653.9     327 8.029e+23 &lt;2e-16 ***
Residuals           394507    0.0       0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1931-1940
ANOVA for Mean Family Size:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      1  1.829   1.829 8.533e+22 &lt;2e-16 ***
Residuals           179944  0.000   0.000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1910 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1920 has only one Census Year. Skipping ANOVA.

Cohort: 1941-1950 has only one Census Year. Skipping ANOVA.</code></pre>
<p><strong><em>RESULT:</em></strong> 1.In both racial group, the ANOVA
is not applicable for the following cohort since there is only one
census year available in the data for those cohorts:-Inf-1910,
1941-1950, -Inf-1920, -Inf-1890, -Inf-1900, and 1891-1900 2.By looking
at the ANOVA for mean family size in both racial group, the p-value of
the rest cohorts (1901-1910, 1911-1920, 1921-1930, 1931-1940) are
smaller than 0.05, indicating mean family size for these cohort has
significantly changed over different census years in both
population.</p>
</div>
<div id="c.-model-fit-analysis" class="section level4">
<h4>c. <strong>Model Fit Analysis</strong></h4>
<ul>
<li>If the best-fitting model changes for the same cohort over time,
this suggests that the distribution of family sizes has shifted. Use
<strong>multinomial logistic regression</strong> to test if the model
fit differs across census years for the same cohort.</li>
</ul>
<p><strong>Example Code</strong>:</p>
<pre class="r"><code># Test for white population
test_df_w &lt;- merged_data %&gt;%
  mutate(Best_Model_Binary = ifelse(Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)) %&gt;%
  select(Race, Cohort, Census_Year, Best_Model, Best_Model_Binary) %&gt;% 
  filter(Race == &quot;White&quot;)

unique_cohorts &lt;- unique(test_df_w$Cohort)

for (cohort in unique_cohorts) {
  cohort_data &lt;- test_df_w %&gt;% filter(Cohort == cohort)
  
  if (n_distinct(cohort_data$Census_Year) &gt; 1) {
    if (n_distinct(cohort_data$Best_Model_Binary) &gt; 1) {
      logistic_model &lt;- glm(Best_Model_Binary ~ as.factor(Census_Year), data = cohort_data, family = binomial)
      
      print(paste(&quot;Cohort:&quot;, cohort))
      print(summary(logistic_model))
    } else {
      print(paste(&quot;Warning for Cohort&quot;, cohort, &quot;: Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;))
    }
  } else {
    print(paste(&quot;Cohort:&quot;, cohort, &quot;- Not enough data variability across census years for logistic regression.&quot;))
  }
}</code></pre>
<pre><code>[1] &quot;Cohort: 1891-1900 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Warning for Cohort 1911-1920 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Warning for Cohort 1901-1910 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Cohort: -Inf-1890 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Cohort: -Inf-1900 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Warning for Cohort 1921-1930 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Warning for Cohort 1931-1940 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Cohort: -Inf-1910 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Cohort: -Inf-1920 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Cohort: 1941-1950 - Not enough data variability across census years for logistic regression.&quot;</code></pre>
<pre class="r"><code># Test for black population
test_df_b &lt;- merged_data %&gt;%
  mutate(Best_Model_Binary = ifelse(Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)) %&gt;%
  select(Race, Cohort, Census_Year, Best_Model, Best_Model_Binary) %&gt;% 
  filter(Race == &quot;Black/African American&quot;)

unique_cohorts &lt;- unique(test_df_b$Cohort)

for (cohort in unique_cohorts) {
  cohort_data &lt;- test_df_b %&gt;% filter(Cohort == cohort)
  
  if (n_distinct(cohort_data$Census_Year) &gt; 1) {
    if (n_distinct(cohort_data$Best_Model_Binary) &gt; 1) {
      logistic_model &lt;- glm(Best_Model_Binary ~ as.factor(Census_Year), data = cohort_data, family = binomial)
      
      print(paste(&quot;Cohort:&quot;, cohort))
      print(summary(logistic_model))
    } else {
      print(paste(&quot;Warning for Cohort&quot;, cohort, &quot;: Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;))
    }
  } else {
    print(paste(&quot;Cohort:&quot;, cohort, &quot;- Not enough data variability across census years for logistic regression.&quot;))
  }
}</code></pre>
<pre><code>[1] &quot;Cohort: 1891-1900 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Warning for Cohort 1911-1920 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Warning for Cohort 1901-1910 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Cohort: -Inf-1890 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Warning for Cohort 1921-1930 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Cohort: -Inf-1900 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Warning for Cohort 1931-1940 : Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;
[1] &quot;Cohort: -Inf-1910 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Cohort: 1941-1950 - Not enough data variability across census years for logistic regression.&quot;
[1] &quot;Cohort: -Inf-1920 - Not enough data variability across census years for logistic regression.&quot;</code></pre>
<pre class="r"><code># Due to the problem indicated above, I use an alternative method:visualization

ggplot(best_models, aes(x = Census_Year, y = Cohort, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + # Create the tiles
  facet_wrap(~Race, nrow = 2) + # Facet by Race
  scale_fill_manual(values = c(&quot;Zero_Inflated_Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;)) + 
  labs(
    title = &quot;Best Model by Race, Census Year, and Cohort(Birth Range)&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Birth Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-29-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-29-1">
Past versions of unnamed-chunk-29-1.png
</button>
</p>
<div id="fig-unnamed-chunk-29-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/docs/figure/relative-distribution.Rmd/unnamed-chunk-29-1.png" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong><em>RESULT:</em></strong> Based on the heatmap created, we
can see that the model fit for each cohort(cohort with 2+ corresponding
census year) across year does not change.</p>
</div>
</div>
<div id="step-4-interpret-the-results" class="section level3">
<h3>Step 4: Interpret the Results</h3>
<p>For each cohort, you will assess whether: -
<strong>Zero-inflation</strong> changes significantly over time (i.e.,
whether the probability of having no children decreases or increases
across census years). - <strong>Family size</strong> (mean, variance,
mode) changes significantly over time. - The <strong>best-fitting
model</strong> changes over time, indicating a shift in family size
distributions.</p>
<p>If significant changes are detected for a cohort (e.g., the same
cohort switches from a zero-inflated model to a non-zero-inflated model,
or family sizes decrease), this indicates a shift in the demographic
pattern for that group.</p>
</div>
<div id="conclusion-1" class="section level3">
<h3>Conclusion</h3>
<p>This analysis will allow you to evaluate <strong>cohort
stability</strong> by testing whether demographic patterns (e.g.,
zero-inflation, family size) are consistent over time for the same
cohort or if there are notable shifts. If the patterns change
significantly, you will be able to identify when and how the demographic
trends for each cohort begin to deviate from their earlier
distribution.</p>
</div>
</div>
<div
id="instructions-for-manqing-question-3-analyzing-and-visualizing-significant-fertility-shifts"
class="section level2">
<h2>[Instructions for Manqing] Question 3: Analyzing and Visualizing
Significant Fertility Shifts</h2>
<p>For Question 3: <strong>Significant Fertility shifts</strong>, the
goal is to summarize the information in the top 2 questions and create a
comprehensive analysis and visualization that illustrates significant
fertility shifts in cohorts, compares fertility patterns of 40-49
year-olds to 50-59 year-olds in the 1990 census so we can pick the set
of fertility distributions we want to use to visualize the sibling
distribution and do the math on the genetic surveillance.</p>
<div id="objective" class="section level3">
<h3>Objective</h3>
<p>Create a comprehensive analysis and visualization that:</p>
<ol style="list-style-type: decimal">
<li><strong>Illustrates significant fertility shifts in cohorts</strong>
based on the stability analysis from Question 2.</li>
<li><strong>Compares fertility patterns of 40-49 year-olds to 50-59
year-olds in the 1990 census</strong>, highlighting any significant
differences.</li>
<li><strong>Synthesizes the findings</strong> to discuss overall trends
and their implications.</li>
</ol>
<p>The steps below are suggestions: use critical thinking and your
judgement to complete this task and answer the question</p>
</div>
<div id="step-1-prepare-the-data" class="section level3">
<h3>Step 1: Prepare the Data</h3>
<div id="use-results-from-stability-analysis-question-2"
class="section level4">
<h4>1.1 Use Results from Stability Analysis (Question 2)</h4>
<ul>
<li><strong>Identify Cohorts with Significant Shifts</strong>:
<ul>
<li>Review the results from your stability analysis in Question 2.</li>
<li>List the cohorts where significant shifts in fertility distributions
were observed for 40-49 year-olds.</li>
<li>Note the nature of these shifts for each cohort, such as changes in
mean number of children, variance, or zero inflation (proportion of
women with zero children).</li>
</ul>
-change in prob_0 children(black):1901-1910, 1921-1930 -change in prob_0
children(white):1901-1910, 1911-1920, 1921-1930 -change in mean &amp;
variance(both racial groups):1901-1910, 1911-1920, 1921-1930, 1931-1940
-change in best model fit: none</li>
</ul>
</div>
<div id="extract-data-for-age-groups-in-1990-census"
class="section level4">
<h4>1.2 Extract Data for Age Groups in 1990 Census</h4>
<ul>
<li><strong>Filter Data for 1990 Census</strong>:
<ul>
<li>Use your existing dataset to extract data specifically from the 1990
census year.</li>
</ul></li>
<li><strong>Select Age Groups</strong>:
<ul>
<li>Focus on women in the age ranges of <strong>40-49</strong> and
<strong>50-59</strong>.</li>
<li>Ensure the data includes necessary variables:
<ul>
<li>Number of children (<code>chborn_num</code>)</li>
<li>Age range (<code>AGE_RANGE</code>)</li>
<li>Race (<code>RACE</code>)</li>
<li>Any other relevant variables used in previous analyses</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="step-2-create-visualizations" class="section level3">
<h3>Step 2: Create Visualizations</h3>
<p>Design visualizations that effectively communicate your findings.</p>
<div id="panel-a-fertility-distribution-shifts-across-cohorts"
class="section level4">
<h4>2.1 Panel A: Fertility Distribution Shifts Across Cohorts</h4>
<ul>
<li><strong>Use Existing Fertility Distribution Plots</strong>:
<ul>
<li>Leverage the fertility distribution plots you created in Question
1.</li>
</ul></li>
<li><strong>Highlight Significant Cohorts</strong>:
<ul>
<li>Emphasize the cohorts identified in Step 1.1 where significant
shifts occurred.
<ul>
<li>This could be done by using distinct colors, markers, or
annotations.</li>
</ul></li>
</ul></li>
<li><strong>Annotate the Plots</strong>:
<ul>
<li>Include text or labels that describe the nature of the significant
shifts for each highlighted cohort.
<ul>
<li>For example, indicate if there was a decrease in mean number of
children or an increase in childlessness.</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>part1&lt;- child_plot +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1960 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;60-69&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1990 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 0.45, ymin = -0.3, ymax = 0.3), 
            fill = &quot;blue&quot;, alpha = 0.03)</code></pre>
<pre class="r"><code>part2&lt;- part1 +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1960 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 0.45, ymin = -0.3, ymax = 0), 
            fill = &quot;blue&quot;, alpha = 0.03) + 
  labs(title = &quot;Fertility Distribution Shifts&quot;,
       subtitle = &quot;Highlighted significant shifts in Number of zero Children&quot;,
       caption = &quot;Annotations indicate key shifts in number of zero children across census years. White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;) +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5), 
    plot.caption = element_text(size = 9, hjust = 0.5),  
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10)
  )
part2</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-31-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-31-1">
Past versions of unnamed-chunk-31-1.png
</button>
</p>
<div id="fig-unnamed-chunk-31-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/231390a7e9b5261ed01047322fdbca2676183be9/docs/figure/relative-distribution.Rmd/unnamed-chunk-31-1.png" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/docs/figure/relative-distribution.Rmd/unnamed-chunk-31-1.png" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-31-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>child_plot +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1960 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1960 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;60-69&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;60-69&quot;)|
                                        (YEAR == 1990 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1990 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 13, ymin = -0.3, ymax = 0.3), 
            fill = &quot;blue&quot;, alpha = 0.01) + 
  labs(title = &quot;Fertility Distribution Shifts&quot;,
       subtitle = &quot;Highlighted significant shifts in Mean Family Size&quot;,
       caption = &quot;Annotations indicate key shifts in Mean Family Size across census years. White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;) +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5), 
    plot.caption = element_text(size = 9, hjust = 0.5),  
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10)
  )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-32-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Additional Visualization: Nature of significant Change for cohorts By
Race</p>
<pre class="r"><code>## Balck population
filter_prop_b &lt;- proportions_df_b %&gt;% 
  filter(Cohort %in% c(&quot;1901-1910&quot;, &quot;1921-1930&quot;))

# Create the plot
ggplot(filter_prop_b, aes(x = Census_Year, y = Proportion_Zero_Children)) +
  geom_line(size = 1, color = &quot;#F07857&quot;) +  
  geom_point(size = 2, color = &quot;#F07857&quot;) + 
  facet_wrap(~ Cohort, scales = &quot;free_x&quot;) +  
  labs(
    title = &quot;Cohorts (Black) with Significant Change in Probability of Zero Children&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Proportion with Zero Children&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-33-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-33-1">
Past versions of unnamed-chunk-33-1.png
</button>
</p>
<div id="fig-unnamed-chunk-33-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/docs/figure/relative-distribution.Rmd/unnamed-chunk-33-1.png" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/776920fb4e25a0632758115092f6ce91ffdf69fd/docs/figure/relative-distribution.Rmd/unnamed-chunk-33-1.png" target="_blank">776920f</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-12
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>## White population
filter_prop_w &lt;- proportions_df_w %&gt;% 
  filter(Cohort %in% c(&quot;1901-1910&quot;, &quot;1911-1920&quot;, &quot;1921-1930&quot;))

# Create the plot
ggplot(filter_prop_w, aes(x = Census_Year, y = Proportion_Zero_Children)) +
  geom_line(size = 1, color = &quot;#43A5BE&quot;) + 
  geom_point(size = 2, color = &quot;#43A5BE&quot;) + 
  facet_wrap(~ Cohort, scales = &quot;free_x&quot;) + 
  labs(
    title = &quot;Cohorts (White) with Significant Change in Probability of Zero Children&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Proportion with Zero Children&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-34-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="panel-b-comparison-of-40-49-and-50-59-age-groups-in-1990"
class="section level4">
<h4>2.2 Panel B: Comparison of 40-49 and 50-59 Age Groups in 1990</h4>
<ul>
<li><strong>Create Comparative Distribution Plots</strong>:
<ul>
<li>Generate side-by-side or overlaid histograms or density plots for
the 40-49 and 50-59 age groups within each racial group.</li>
</ul></li>
<li><strong>Include Summary Statistics</strong>:
<ul>
<li>On each plot or in accompanying tables, provide:
<ul>
<li>Mean number of children</li>
<li>Variance</li>
<li>Proportion of women with zero children (zero inflation)</li>
</ul></li>
</ul></li>
<li><strong>Ensure Clarity in Visuals</strong>:
<ul>
<li>Properly label axes, legends, and titles.</li>
<li>Use consistent color schemes for easy comparison between
groups.</li>
</ul></li>
</ul>
<pre class="r"><code>filter_df &lt;- df_proportions %&gt;% 
  filter(YEAR == &quot;1990&quot;, AGE_RANGE %in% c(&quot;40-49&quot;, &quot;50-59&quot;)) </code></pre>
<pre class="r"><code>ggplot(filter_df, aes(x = chborn_num, y = proportion, fill = AGE_RANGE)) +
  geom_col(position = &quot;identity&quot;, alpha = 0.5) +  
  facet_wrap(~ RACE) +  
  labs(
    title = &quot;Distribution of Number of Children for Women in 40-49 and 50-59 Age Groups in 1990&quot;,
    x = &quot;Number of Children&quot;,
    y = &quot;Proportion&quot;,
    fill = &quot;Age Range&quot;
  ) </code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-36-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary_stats &lt;- filter_df %&gt;%
  group_by(AGE_RANGE, RACE) %&gt;%
  summarise(
    mean_children = weighted.mean(chborn_num, count),  # Mean number of children
    variance_children = sum(count * (chborn_num - weighted.mean(chborn_num, count))^2) / sum(count),  # Variance
    zero_inflation = sum(count[chborn_num == 0]) / sum(count)  # Proportion of women with 0 children
  )</code></pre>
<pre><code>`summarise()` has grouped output by &#39;AGE_RANGE&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code># Print summary statistics table
summary_stats</code></pre>
<pre><code># A tibble: 4 × 5
# Groups:   AGE_RANGE [2]
  AGE_RANGE RACE                  mean_children variance_children zero_inflation
  &lt;chr&gt;     &lt;fct&gt;                         &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;
1 40-49     White                          2.20              2.09          0.139
2 40-49     Black/African Americ…          2.69              3.96          0.126
3 50-59     White                          2.89              3.35          0.103
4 50-59     Black/African Americ…          3.72              7.74          0.111</code></pre>
</div>
</div>
<div id="step-3-perform-statistical-comparisons" class="section level3">
<h3>Step 3: Perform Statistical Comparisons</h3>
<p>Conduct statistical tests to determine if observed differences are
significant.</p>
<div id="t-test-for-difference-in-means" class="section level4">
<h4>3.1 T-Test for Difference in Means</h4>
<ul>
<li><strong>Compare Means Between Age Groups</strong>:
<ul>
<li>For each racial group, perform a t-test to compare the mean number
of children between the 40-49 and 50-59 age groups.</li>
</ul></li>
<li><strong>Check Assumptions</strong>:
<ul>
<li>Ensure that the data meets the assumptions of the t-test (normality,
equal variances).</li>
<li>If assumptions are violated, consider using a non-parametric test
like the Mann-Whitney U test.</li>
</ul></li>
</ul>
<pre class="r"><code>## Check the normality assumption for black population
# Subset data for the 40-49 and 50-59 age groups
data_40_49_b &lt;- df %&gt;% filter(AGE_RANGE == &quot;40-49&quot;, RACE == &quot;Black/African American&quot;)
data_50_59_b &lt;- df %&gt;% filter(AGE_RANGE == &quot;50-59&quot;, RACE == &quot;Black/African American&quot;)

qqnorm(data_40_49_b$chborn_num, main = &quot;QQ Plot: 40-49 Age Group (Black/African American)&quot;)
qqline(data_40_49_b$chborn_num)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-38-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code># QQ plot for the 50-59 age group
qqnorm(data_50_59_b$chborn_num, main = &quot;QQ Plot: 50-59 Age Group (Black/African American)&quot;)
qqline(data_50_59_b$chborn_num)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-38-2.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Check equal variance for black population
df_b &lt;- df %&gt;% filter(RACE == &quot;Black/African American&quot;)

# Levene&#39;s test for equal variances
levene_test_result &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_b)

levene_test_result</code></pre>
<pre><code>Levene&#39;s Test for Homogeneity of Variance (center = median)
          Df F value    Pr(&gt;F)    
group      3  93.887 &lt; 2.2e-16 ***
      176718                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>## Check the normality assumption for white population
data_40_49_w &lt;- df %&gt;% filter(AGE_RANGE == &quot;40-49&quot;, RACE == &quot;White&quot;)
data_50_59_w &lt;- df %&gt;% filter(AGE_RANGE == &quot;50-59&quot;, RACE == &quot;White&quot;)

qqnorm(data_40_49_w$chborn_num, main = &quot;QQ Plot: 40-49 Age Group (White)&quot;)
qqline(data_40_49_w$chborn_num)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-40-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code># QQ plot for the 50-59 age group
qqnorm(data_50_59_w$chborn_num, main = &quot;QQ Plot: 50-59 Age Group (White)&quot;)
qqline(data_50_59_w$chborn_num)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-40-2.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Check equal variance for white population
df_w &lt;- df %&gt;% filter(RACE == &quot;White&quot;)

# Levene&#39;s test for equal variances
levene_test_result2 &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_w)

levene_test_result2</code></pre>
<pre><code>Levene&#39;s Test for Homogeneity of Variance (center = median)
           Df F value    Pr(&gt;F)    
group       3  4205.8 &lt; 2.2e-16 ***
      1740751                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Since the data for black population and white population violate both
assumption, we perform a Mann-Whitney U test for both racial groups in
the follwoing:</p>
<pre class="r"><code>wilcox_test_result &lt;- wilcox.test(data_40_49_b$chborn_num, data_50_59_b$chborn_num)$p.value
wilcox_test_result2 &lt;- wilcox.test(data_40_49_w$chborn_num, data_50_59_w$chborn_num)$p.value
print(c(wilcox_test_result, wilcox_test_result2))</code></pre>
<pre><code>[1]  1.012022e-31 3.463246e-126</code></pre>
<p><strong><em>RESULT:</em></strong> These p-values are both extremely
small (close to zero), meaning there is a very strong statistical
difference between the two age groups (40-49 and 50-59) in terms of the
number of children within each racial group.</p>
</div>
<div id="f-test-for-difference-in-variances" class="section level4">
<h4>3.2 F-Test for Difference in Variances</h4>
<ul>
<li><strong>Assess Variance Differences</strong>:
<ul>
<li>Perform an F-test or Levene’s test to compare the variances of the
number of children between the two age groups within each racial
group.</li>
</ul></li>
</ul>
<pre class="r"><code>## Apply Levene&#39;s test since non-normality

# Levene&#39;s test for Black group
levene_test_b &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_b)

# Levene&#39;s test for White group
levene_test_w &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_w)

# Print results
print(levene_test_b)</code></pre>
<pre><code>Levene&#39;s Test for Homogeneity of Variance (center = median)
          Df F value    Pr(&gt;F)    
group      3  93.887 &lt; 2.2e-16 ***
      176718                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>print(levene_test_w)</code></pre>
<pre><code>Levene&#39;s Test for Homogeneity of Variance (center = median)
           Df F value    Pr(&gt;F)    
group       3  4205.8 &lt; 2.2e-16 ***
      1740751                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong><em>RESULT:</em></strong> Since the p values are smaller than
0.05 for both racial group, we have enough evidence to reject the null
hypothesis, indicating that the variances of the number of children
between the two age groups within each racial group are significantly
different.</p>
</div>
<div id="chi-square-test-for-difference-in-zero-inflation"
class="section level4">
<h4>3.3 Chi-Square Test for Difference in Zero Inflation</h4>
<ul>
<li><strong>Analyze Zero Inflation</strong>:
<ul>
<li>Create contingency tables showing the counts of women with zero
children and those with one or more children for each age group.</li>
<li>Perform a chi-square test to determine if the proportion of
childlessness differs significantly between the age groups within each
racial group.</li>
</ul></li>
</ul>
<pre class="r"><code>ZI_table &lt;- df %&gt;% 
  mutate(childlessness = ifelse(chborn_num == 0, &quot;0 Children&quot;, &quot;1+ Children&quot;)) %&gt;%       group_by(RACE, AGE_RANGE, childlessness) %&gt;%
  summarise(count = n())</code></pre>
<pre><code>`summarise()` has grouped output by &#39;RACE&#39;, &#39;AGE_RANGE&#39;. You can override using
the `.groups` argument.</code></pre>
<pre class="r"><code>ZI_table</code></pre>
<pre><code># A tibble: 16 × 4
# Groups:   RACE, AGE_RANGE [8]
   RACE                   AGE_RANGE childlessness  count
   &lt;fct&gt;                  &lt;chr&gt;     &lt;chr&gt;          &lt;int&gt;
 1 White                  40-49     0 Children     63463
 2 White                  40-49     1+ Children   410055
 3 White                  50-59     0 Children     76528
 4 White                  50-59     1+ Children   391044
 5 White                  60-69     0 Children     77238
 6 White                  60-69     1+ Children   320508
 7 White                  70+       0 Children     87293
 8 White                  70+       1+ Children   314626
 9 Black/African American 40-49     0 Children      9469
10 Black/African American 40-49     1+ Children    46173
11 Black/African American 50-59     0 Children     10846
12 Black/African American 50-59     1+ Children    39202
13 Black/African American 60-69     0 Children      9907
14 Black/African American 60-69     1+ Children    29176
15 Black/African American 70+       0 Children      8575
16 Black/African American 70+       1+ Children    23374</code></pre>
<pre class="r"><code>ZI_table_b &lt;- ZI_table %&gt;%
  filter(RACE == &quot;Black/African American&quot;)

cont_table_b &lt;- xtabs(count ~ AGE_RANGE + childlessness, data = ZI_table_b)
chi_test_b &lt;- chisq.test(cont_table_b)
chi_test_b</code></pre>
<pre><code>
    Pearson&#39;s Chi-squared test

data:  cont_table_b
X-squared = 1501.6, df = 3, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>ZI_table_w &lt;- ZI_table %&gt;%
  filter(RACE == &quot;White&quot;)

cont_table_w &lt;- xtabs(count ~ AGE_RANGE + childlessness, data = ZI_table_w)
chi_test_w &lt;- chisq.test(cont_table_w)
chi_test_w</code></pre>
<pre><code>
    Pearson&#39;s Chi-squared test

data:  cont_table_w
X-squared = 11896, df = 3, p-value &lt; 2.2e-16</code></pre>
<p><strong><em>RESULT:</em></strong> The p-values for both tests are
extremely low, suggests that there is a significant difference in the
proportion of women with 0 children across different age ranges for both
the Black/African American and White racial groups. The results imply
that childlessness is not uniformly distributed across age groups.</p>
</div>
</div>
<div id="step-4-summarize-findings" class="section level3">
<h3>Step 4: Summarize Findings</h3>
<p>Write a clear and concise summary addressing the following
points.</p>
<div id="significant-fertility-shifts-across-cohorts"
class="section level4">
<h4>4.1 Significant Fertility Shifts Across Cohorts</h4>
<ul>
<li><strong>Identify Timing of Shifts</strong>:
<ul>
<li>Specify when significant fertility shifts occurred for each racial
group based on your analysis in Question 2.</li>
</ul></li>
<li><strong>Describe Nature of Shifts</strong>:
<ul>
<li>Detail the characteristics of the shifts, such as:
<ul>
<li>Decrease in mean number of children</li>
<li>Increase in childlessness (zero inflation)</li>
<li>Changes in variance or distribution shape</li>
</ul></li>
</ul></li>
<li><strong>Highlight Differences Between Racial Groups</strong>:
<ul>
<li>Compare the timing and nature of shifts between African American and
European American women.</li>
<li>Discuss any patterns or discrepancies observed.</li>
</ul></li>
</ul>
</div>
<div id="comparison-of-40-49-and-50-59-age-groups-in-1990"
class="section level4">
<h4>4.2 Comparison of 40-49 and 50-59 Age Groups in 1990</h4>
<ul>
<li><strong>Summarize Key Differences</strong>:
<ul>
<li>Present the differences in fertility patterns between the two age
groups for each racial group.</li>
<li>Include comparisons of:
<ul>
<li>Distribution shapes</li>
<li>Mean number of children</li>
<li>Variance</li>
<li>Zero inflation</li>
</ul></li>
</ul></li>
<li><strong>Report Statistical Test Results</strong>:
<ul>
<li>Provide the results of the t-tests, F-tests, and chi-square
tests.</li>
<li>Interpret the significance of these results in the context of your
analysis.</li>
</ul></li>
<li><strong>Discuss Implications</strong>:
<ul>
<li>Consider what these differences suggest about fertility trends and
behaviors.</li>
<li>Reflect on whether the older age group represents completed
fertility patterns.</li>
</ul></li>
</ul>
</div>
<div id="synthesis-and-implications" class="section level4">
<h4>4.3 Synthesis and Implications</h4>
<ul>
<li><strong>Integrate Findings</strong>:
<ul>
<li>Connect the insights from the cohort analysis with the age group
comparison.</li>
<li>Discuss how the patterns observed in the 1990 census relate to the
shifts identified across cohorts.</li>
</ul></li>
<li><strong>Consider Contributing Factors</strong>:
<ul>
<li>Explore potential social, economic, or policy factors that may have
contributed to the observed fertility shifts.
<ul>
<li>For example, changes in access to education, employment
opportunities, or family planning resources.</li>
</ul></li>
</ul></li>
<li><strong>Reflect on Broader Implications</strong>:
<ul>
<li>Discuss how these fertility trends might impact your broader
research topic, such as genetic surveillance disparities.</li>
<li>Consider the implications for future demographic research or policy
development.</li>
</ul></li>
</ul>
</div>
</div>
<div id="additional-considerations" class="section level3">
<h3>Additional Considerations</h3>
<ul>
<li><strong>Visual Clarity</strong>:
<ul>
<li>Ensure all visualizations are easy to interpret.</li>
<li>Use clear labels, legends, and annotations.</li>
</ul></li>
<li><strong>Contextualize Statistical Significance</strong>:
<ul>
<li>Explain not just whether results are statistically significant, but
also what they mean in practical terms.</li>
</ul></li>
<li><strong>Acknowledge Data Limitations</strong>:
<ul>
<li>Discuss any limitations or biases in the data that could affect your
findings.
<ul>
<li>For instance, sample size constraints or missing data.</li>
</ul></li>
</ul></li>
<li><strong>Ethical Considerations</strong>:
<ul>
<li>Approach discussions of race and fertility sensitively and
responsibly.</li>
<li>Avoid drawing causal conclusions without robust evidence.</li>
</ul></li>
</ul>
</div>
<div id="integration-with-previous-work" class="section level3">
<h3>Integration with Previous Work</h3>
<ul>
<li><strong>Leverage Previous Analyses</strong>:
<ul>
<li>Use the visualizations and statistical summaries from Questions 1
and 2 as foundations for this analysis.</li>
</ul></li>
<li><strong>Create a Cohesive Narrative</strong>:
<ul>
<li>Ensure that your findings from all questions are connected and build
upon each other.</li>
<li>Tell a comprehensive story about fertility trends across cohorts and
racial groups.</li>
</ul></li>
</ul>
</div>
<div id="final-deliverables" class="section level3">
<h3>Final Deliverables</h3>
<ul>
<li><strong>Multi-Panel Visualization</strong>:
<ul>
<li>Panel A: Fertility distribution shifts across cohorts with
highlighted significant shifts.</li>
<li>Panel B: Comparative distribution plots for 40-49 and 50-59 age
groups in 1990, including summary statistics.</li>
</ul></li>
<li><strong>Written Summary</strong>:
<ul>
<li>A concise report that addresses the points outlined in Step 4.</li>
<li>Include interpretations of statistical analyses and discuss broader
implications.</li>
</ul></li>
<li><strong>Statistical Analysis Documentation</strong>:
<ul>
<li>Provide details of the statistical tests conducted, including test
assumptions, results, and interpretations.</li>
</ul></li>
<li><strong>Annotated Code (if applicable)</strong>:
<ul>
<li>While not the focus, include any new code used for this analysis
with appropriate comments.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="distribution-of-number-of-siblings-across-census-years"
class="section level1">
<h1>Distribution of Number of Siblings Across Census Years</h1>
<p>Having analyzed the distribution of the number of children, we now
turn our attention to the distribution of the number of siblings. We
will explore the trends in the frequency of the number of siblings for
African American and European American mothers across the Census years
by age group.</p>
<p>Frequency of siblings is calculated as follows.</p>
<p><span class="math display">\[
\text{freq}_{n_{\text{sib}}} = \text{freq}_{\text{mother}} \cdot
\text{chborn}_{\text{num}}
\]</span></p>
<p>For example, suppose 10 mothers (generation 0) have 7 children, then
there will be 70 children (generation 1) in total who each have 6
siblings.</p>
<p>We take our original data and calculate the frequency of siblings for
each mother based on the number of children they have. We then aggregate
this data to get the frequency of siblings for each generation along
with details on the birthyears of the relevant children to visualize the
distribution of the number of siblings across generations.</p>
<div id="instructions-for-manqing-plot-across-census-years-for-children"
class="section level2">
<h2>[Instructions for Manqing] Plot Across Census Years for
Children</h2>
<div id="objective-1" class="section level3">
<h3>Objective</h3>
<p>Create a mirror plot for the distribution of siblings across census
years, races, and birth ranges, similar to the one created for the
number of children.</p>
</div>
<div id="step-1-calculate-sibling-frequencies" class="section level3">
<h3>Step 1: Calculate Sibling Frequencies</h3>
<ol style="list-style-type: decimal">
<li>Start with your dataframe that includes the <code>AGE_RANGE</code>
column.</li>
</ol>
<pre class="r"><code>df2 &lt;- df %&gt;% 
  dplyr::select(RACE, YEAR, AGE_RANGE, chborn_num)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Create a new column for the number of siblings:</li>
</ol>
<pre class="r"><code>df2 &lt;- df2 %&gt;%
 mutate(n_siblings = chborn_num - 1)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Calculate the frequency of siblings:</li>
</ol>
<pre class="r"><code>df2 &lt;- df2 %&gt;%
mutate(sibling_freq = ifelse(chborn_num != 1, n_siblings * 1, 1))  # Assuming each mother represents 1 in frequency</code></pre>
</div>
<div id="step-2-aggregate-sibling-data" class="section level3">
<h3>Step 2: Aggregate Sibling Data</h3>
<ol style="list-style-type: decimal">
<li>Group the data and calculate sibling frequencies:</li>
</ol>
<pre class="r"><code>df_siblings &lt;- df2 %&gt;%
 group_by(YEAR, RACE, AGE_RANGE, n_siblings) %&gt;%
 summarise(
   sibling_count = sum(sibling_freq),
   .groups = &quot;drop&quot;
 )</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate proportions within each group:</li>
</ol>
<pre class="r"><code>df_sibling_proportions &lt;- df_siblings %&gt;%
 group_by(YEAR, RACE, AGE_RANGE) %&gt;%
 mutate(proportion = sibling_count / sum(sibling_count)) %&gt;%
 ungroup()</code></pre>
</div>
<div id="step-3-check-normalization" class="section level3">
<h3>Step 3: Check Normalization</h3>
<p>Before creating the plot, verify that the proportions are correctly
normalized:</p>
<pre class="r"><code>normalization_check &lt;- df_sibling_proportions %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  summarise(total_proportion = sum(proportion), .groups = &quot;drop&quot;) %&gt;%
  arrange(YEAR, RACE, AGE_RANGE)

print(normalization_check)</code></pre>
<pre><code># A tibble: 32 × 4
    YEAR RACE                   AGE_RANGE total_proportion
   &lt;int&gt; &lt;fct&gt;                  &lt;chr&gt;                &lt;dbl&gt;
 1  1960 White                  40-49                    1
 2  1960 White                  50-59                    1
 3  1960 White                  60-69                    1
 4  1960 White                  70+                      1
 5  1960 Black/African American 40-49                    1
 6  1960 Black/African American 50-59                    1
 7  1960 Black/African American 60-69                    1
 8  1960 Black/African American 70+                      1
 9  1970 White                  40-49                    1
10  1970 White                  50-59                    1
# ℹ 22 more rows</code></pre>
<p>Ensure that the <code>total_proportion</code> for each group is very
close to 1.0. If not, revisit your calculations in Step 2.</p>
</div>
<div id="step-4-prepare-data-for-mirror-plot" class="section level3">
<h3>Step 4: Prepare Data for Mirror Plot</h3>
<p>Reshape data for the mirror plot:</p>
<pre class="r"><code>df_sibling_mirror &lt;- df_sibling_proportions %&gt;%
  mutate(proportion = if_else(RACE == &quot;White&quot;, -proportion, proportion))</code></pre>
</div>
<div id="step-5-create-the-mirror-plot" class="section level3">
<h3>Step 5: Create the Mirror Plot</h3>
<ol style="list-style-type: decimal">
<li>Create the color palette:</li>
</ol>
<pre class="r"><code>my_colors &lt;- colorRampPalette(c(&quot;#FFB000&quot;, &quot;#F77A2E&quot;, &quot;#DE3A8A&quot;, &quot;#7253FF&quot;, &quot;#5E8BFF&quot;))(13)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Create the plot:</li>
</ol>
<pre class="r"><code>ggplot(data = df_sibling_mirror %&gt;% filter(n_siblings != &quot;-1&quot;), aes(x = n_siblings, y = proportion, fill = as.factor(n_siblings))) +
 geom_col(aes(alpha = RACE)) +
 geom_hline(yintercept = 0, color = &quot;black&quot;, size = 0.5) +
 facet_grid(AGE_RANGE ~ YEAR, scales = &quot;free_y&quot;) +
 coord_flip() +
 scale_y_continuous(
   labels = function(x) abs(x),
   limits = function(x) c(-max(abs(x)), max(abs(x)))
 ) +
 scale_x_continuous(breaks = 0:11, labels = c(0:10, &quot;11+&quot;)) +
 scale_fill_manual(values = my_colors) +
 scale_alpha_manual(values = c(&quot;White&quot; = 0.7, &quot;Black/African American&quot; = 1)) +
 labs(
   title = &quot;Distribution of Number of Siblings by Census Year, Race, and Age Range&quot;,
   x = &quot;Number of Siblings&quot;,
   y = &quot;Proportion&quot;,
   fill = &quot;Number of Siblings&quot;,
   caption = &quot;White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;11+&#39; includes individuals with 11 or more siblings.&quot;
 ) +
 theme_minimal() +
 theme(
   plot.title = element_text(size = 14, hjust = 0.5),
   axis.text.y = element_text(size = 8),
   strip.text = element_text(size = 10),
   legend.position = &quot;none&quot;,
   panel.grid.major.y = element_blank(),
   panel.grid.minor.y = element_blank()
 )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-55-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="step-6-interpret-the-plot" class="section level3">
<h3>Step 6: Interpret the Plot</h3>
<p>After creating the plot, examine it carefully:</p>
<ol style="list-style-type: decimal">
<li>Look for patterns in sibling distribution across different census
years and age ranges.</li>
</ol>
<p><strong><em>RESULT:</em></strong></p>
<p><strong><em>-By Census Year:</em></strong> In 1960 and 1970,
individuals are more likely to have higher number of siblings,
especially in the 5-10 range. This trend diminishes over time.</p>
<p>By 1980 and 1990, the distribution shifts toward smaller family
sizes, with a growing proportion of individuals having fewer
siblings.</p>
<p><strong><em>-By age range:</em></strong></p>
<p>40-49 Age Group: For this group, the number of individuals with 0-2
siblings increases across census years, especially in 1980 and 1990,
while the proportion of individuals with larger sibling counts
decreases.</p>
<p>50-59 and 60-69 Age Groups: These groups show a similar shift toward
smaller family sizes, but the trend is slightly more gradual compared to
the younger age group.</p>
<p>70+ Age Group: The shift to fewer siblings is noticeable, although
the trend is less pronounced. The distribution remains relatively stable
across the census years, with a significant portion of individuals still
coming from large families in 1960 and 1970.</p>
<ol start="2" style="list-style-type: decimal">
<li>Compare the distributions between White and Black/African American
populations.</li>
</ol>
<p><strong><em>RESULT:</em></strong> -Black/African American Populations
(right side of each pair) consistently show a higher proportion of
individuals with larger sibling counts (5-10 siblings) compared to White
populations. However, similar to the White population, the number of
individuals with fewer siblings increases over time.</p>
<ol start="3" style="list-style-type: decimal">
<li>Note any significant changes or trends in the number of siblings
over time.</li>
</ol>
<p><strong><em>RESULT:</em></strong> -White Populations: (left side of
each pair) have a more marked shift toward smaller families by 1990,
with a larger proportion of individuals having 0-2 siblings compared to
the Black/African American population. The decline in larger family
sizes (5+ siblings) is more pronounced among Whites, particularly by
1980 and 1990.</p>
<ol start="4" style="list-style-type: decimal">
<li>Consider how these sibling distributions might differ from the
children distributions you analyzed earlier, and think about potential
reasons for these differences.</li>
</ol>
<p><strong><em>RESULT:</em></strong> While both distributions show a
trend toward smaller families, the sibling distribution is more spread
out across different sibling counts, suggesting potential difference in
the distribution.</p>
</div>
</div>
<div id="instructions-for-manqing-model-fit-across-census-years-1"
class="section level2">
<h2>[Instructions for Manqing] Model Fit Across Census Years</h2>
<div id="objective-2" class="section level3">
<h3>Objective</h3>
<p>Repeat the model fitting process we performed for the children
distribution, this time using the sibling distribution data.</p>
</div>
<div id="steps" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Prepare the Sibling Data Use the sibling distribution data you
calculated earlier (<code>df_sibling_proportions</code>).</p></li>
<li><p>Fit Models For each combination of RACE, YEAR, and AGE_RANGE, fit
the following distributions:</p>
<ul>
<li>Poisson</li>
<li>Negative Binomial</li>
<li>Zero-Inflated Poisson</li>
<li>Zero-Inflated Negative Binomial</li>
</ul>
<p>Use the same R functions and packages as in the children distribution
analysis.</p></li>
<li><p>Compare Model Fits Use AIC (Akaike Information Criterion) to
compare the fits of different models for each group.</p></li>
</ol>
<pre class="r"><code>combinations2 &lt;- df2 %&gt;%
  # treat number of sib = -1 as NA
  filter(n_siblings != -1) %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  group_split()

# Initialize the data frame to store results
best_models_sib &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  AGE_RANGE = character(),
  AIC_poisson = numeric(),
  AIC_nb = numeric(),
  AIC_zip = numeric(),
  AIC_zinb = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each subset of data
for (i in seq_along(combinations2)) {
  subset_data &lt;- combinations2[[i]]
  
  # Fit Poisson model
  poisson_model &lt;- glm(n_siblings ~ 1, family = poisson, data = subset_data)
  # Fit Negative Binomial model
  nb_model &lt;- glm.nb(n_siblings ~ 1, data = subset_data)

  # Fit Zero-Inflated Poisson model
  zip_model &lt;- zeroinfl(n_siblings ~ 1 | 1, data = subset_data, dist = &quot;poisson&quot;,control = zeroinfl.control(maxit = 100))
  
  # Fit Zero-Inflated Negative Binomial model with increased max iterations
  zinb_model &lt;- zeroinfl(n_siblings ~ 1 | 1, data = subset_data, dist = &quot;negbin&quot;,control = zeroinfl.control(maxit = 100))
  
  # Append the result to the best_models data frame
  best_models_sib &lt;- rbind(
    best_models_sib,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      AGE_RANGE = unique(subset_data$AGE_RANGE),
      AIC_poisson = AIC(poisson_model),
      AIC_nb = AIC(nb_model),
      AIC_zip = AIC(zip_model),
      AIC_zinb = AIC(zinb_model),
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Identify Best-Fitting Models Determine which model fits best for
each combination of RACE, YEAR, and AGE_RANGE.</li>
</ol>
<pre class="r"><code># Add a Best_Model column to store the best model based on minimum AIC
best_models_sib$Best_Model &lt;- apply(best_models_sib, 1, function(row) {
  # Get AIC values for Poisson, NB, ZIP, and ZINB models
  aic_values &lt;- c(Poisson = as.numeric(row[&#39;AIC_poisson&#39;]),
                  Negative_Binomial = as.numeric(row[&#39;AIC_nb&#39;]),
                  Zero_Inflated_Poisson = as.numeric(row[&#39;AIC_zip&#39;]),
                  Zero_Inflated_NB= as.numeric(row[&#39;AIC_zinb&#39;]))
  
  # Find the name of the model with the minimum AIC value
  best_models_sib &lt;- names(which.min(aic_values))
  
  return(best_models_sib)
})

best_models_sib &lt;- best_models_sib %&gt;% dplyr::select(Race, Census_Year, AGE_RANGE, Best_Model)
# View the updated table with the Best_Model column
print(best_models_sib)</code></pre>
<pre><code>                     Race Census_Year AGE_RANGE        Best_Model
1                   White        1960     40-49 Negative_Binomial
2                   White        1960     50-59 Negative_Binomial
3                   White        1960     60-69 Negative_Binomial
4                   White        1960       70+ Negative_Binomial
5  Black/African American        1960     40-49  Zero_Inflated_NB
6  Black/African American        1960     50-59  Zero_Inflated_NB
7  Black/African American        1960     60-69  Zero_Inflated_NB
8  Black/African American        1960       70+  Zero_Inflated_NB
9                   White        1970     40-49 Negative_Binomial
10                  White        1970     50-59 Negative_Binomial
11                  White        1970     60-69 Negative_Binomial
12                  White        1970       70+ Negative_Binomial
13 Black/African American        1970     40-49  Zero_Inflated_NB
14 Black/African American        1970     50-59  Zero_Inflated_NB
15 Black/African American        1970     60-69  Zero_Inflated_NB
16 Black/African American        1970       70+  Zero_Inflated_NB
17                  White        1980     40-49 Negative_Binomial
18                  White        1980     50-59 Negative_Binomial
19                  White        1980     60-69 Negative_Binomial
20                  White        1980       70+ Negative_Binomial
21 Black/African American        1980     40-49  Zero_Inflated_NB
22 Black/African American        1980     50-59  Zero_Inflated_NB
23 Black/African American        1980     60-69  Zero_Inflated_NB
24 Black/African American        1980       70+  Zero_Inflated_NB
25                  White        1990     40-49           Poisson
26                  White        1990     50-59 Negative_Binomial
27                  White        1990     60-69 Negative_Binomial
28                  White        1990       70+ Negative_Binomial
29 Black/African American        1990     40-49 Negative_Binomial
30 Black/African American        1990     50-59  Zero_Inflated_NB
31 Black/African American        1990     60-69  Zero_Inflated_NB
32 Black/African American        1990       70+  Zero_Inflated_NB</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Analyze Patterns
<ul>
<li>Examine how the best-fitting model changes across years and birth
ranges for each race.</li>
<li>Compare these patterns to those observed in the children
distribution analysis.</li>
</ul></li>
<li>Visualize Results Create a summary plot showing the best-fitting
models across years and birth ranges for each race, similar to the one
created for the children distribution.</li>
</ol>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = Race, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Race&quot;, x = &quot;Race&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-58-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-58-1">
Past versions of unnamed-chunk-58-1.png
</button>
</p>
<div id="fig-unnamed-chunk-58-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/800786411d6551c5050635b63803c9f8e4c12506/docs/figure/relative-distribution.Rmd/unnamed-chunk-58-1.png" target="_blank">8007864</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-03
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = Census_Year, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Census Year&quot;, x = &quot;Census Year&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-59-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = AGE_RANGE, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Birth Range)&quot;, x = &quot;Age Range&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-60-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-60-1">
Past versions of unnamed-chunk-60-1.png
</button>
</p>
<div id="fig-unnamed-chunk-60-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/231390a7e9b5261ed01047322fdbca2676183be9/docs/figure/relative-distribution.Rmd/unnamed-chunk-60-1.png" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>ggplot(best_models_sib, aes(x = Census_Year, y = AGE_RANGE, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + # Create the tiles
  facet_wrap(~Race, nrow = 2) + # Facet by Race
  scale_fill_manual(values = c(&quot;Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;, &quot;Negative_Binomial&quot; = &quot;grey&quot;)) + 
  labs(
    title = &quot;Best Model(siblings) by Race, Census Year, and Birth Range&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Age Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels for readability
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-61-1.png" width="864" style="display: block; margin: auto;" /></p>
<ol start="7" style="list-style-type: decimal">
<li>Interpret Findings
<ul>
<li>Discuss any differences in the best-fitting models between the
sibling and children distributions.</li>
</ul></li>
</ol>
<p><strong><em>RESULT:</em></strong> By comparing the pattern of
best-fitting models between the sibling and children distributions, we
observe that the best model for black population has the same best
model(zero-inlfated NB) across year and age range except on one
subset(age 40-49 in 1990) in siblings distribution. However, there is a
large difference in best model for white population. A large portion of
best model in children distribution for white population is
zero-inlfated NB, while negative-binomial is the best model fitted for
siblings distribution except for one subset(age 40-49 in 1990).</p>
<ul>
<li>Consider the implications of these differences for understanding
family structures and fertility patterns.</li>
</ul>
</div>
</div>
<div id="instructions-for-manqing-cohort-stability-analysis-siblings"
class="section level2">
<h2>[Instructions for Manqing] Cohort Stability Analysis Siblings</h2>
<div id="objective-3" class="section level3">
<h3>Objective</h3>
<p>Analyze the stability of sibling distributions across cohorts,
similar to the analysis performed for children.</p>
</div>
<div id="steps-1" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Use the sibling distribution data
(<code>df_sibling_proportions</code>).</p></li>
<li><p>For each combination of RACE and birth_range:</p>
<ul>
<li>Compare the sibling distributions across different census
years.</li>
<li>Use statistical tests (e.g., Kolmogorov-Smirnov test) to assess if
distributions are significantly different.</li>
</ul></li>
</ol>
<pre class="r"><code> df_sibling_proportions &lt;- df_sibling_proportions %&gt;%
  mutate(Cohort = mapply(calculate_cohort, YEAR, AGE_RANGE))</code></pre>
<pre class="r"><code>df_sibling_proportions %&gt;%
  filter(n_siblings &gt;= 0, sibling_count &gt;= 0, proportion &gt;= 0) %&gt;% group_by(RACE, Cohort) %&gt;%
  ggplot(aes(x = n_siblings, y = proportion, color = as.factor(YEAR))) +
  geom_line() +
  labs(
    title = &quot;Sibling Distribution by Census Year&quot;,
    x = &quot;Number of Siblings&quot;,
    y = &quot;Proportion&quot;,
    color = &quot;Census Year&quot;
  ) +
  facet_grid(RACE ~ Cohort) +
  theme_minimal()</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-63-1.png" width="864" style="display: block; margin: auto;" /></p>
<pre class="r"><code>df_sibling_b &lt;- df_sibling_proportions %&gt;% filter(RACE == &quot;Black/African American&quot;, n_siblings &gt;= 0, sibling_count &gt;= 0, proportion &gt;= 0)

results_sib_b &lt;- list()

cohort_counts2 &lt;- df_sibling_b %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(YEAR)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

for (cohort in cohort_counts2$Cohort) {
  cohort_data &lt;- df_sibling_b %&gt;% filter(Cohort == cohort)
  
  test_result &lt;- kruskal.test(sibling_count ~ YEAR, data = cohort_data)
  
  results_sib_b[[cohort]] &lt;- test_result
}
results_sib_b</code></pre>
<pre><code>$`1901-1910`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 13.23, df = 1, p-value = 0.0002755


$`1911-1920`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 22.761, df = 2, p-value = 1.141e-05


$`1921-1930`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 18.893, df = 2, p-value = 7.895e-05


$`1931-1940`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 0.21333, df = 1, p-value = 0.6442</code></pre>
<pre class="r"><code>df_sibling_w &lt;- df_sibling_proportions %&gt;% filter(RACE == &quot;White&quot;, n_siblings &gt;= 0, sibling_count &gt;= 0, proportion &gt;= 0)

results_sib_w &lt;- list()

cohort_counts2 &lt;- df_sibling_w %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(YEAR)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

for (cohort in cohort_counts2$Cohort) {
  cohort_data &lt;- df_sibling_w %&gt;% filter(Cohort == cohort)
  
  test_result &lt;- kruskal.test(sibling_count ~ YEAR, data = cohort_data)
  
  results_sib_w[[cohort]] &lt;- test_result
}
results_sib_w</code></pre>
<pre><code>$`1901-1910`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 3.8533, df = 1, p-value = 0.04965


$`1911-1920`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 4.9189, df = 2, p-value = 0.08548


$`1921-1930`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 2.7072, df = 2, p-value = 0.2583


$`1931-1940`

    Kruskal-Wallis rank sum test

data:  sibling_count by YEAR
Kruskal-Wallis chi-squared = 0.21333, df = 1, p-value = 0.6442</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Create a summary table showing:
<ul>
<li>RACE</li>
<li>birth_range</li>
<li>Whether the distribution is stable across census years</li>
<li>Any significant changes observed</li>
</ul></li>
</ol>
<pre class="r"><code>results_summary &lt;- data.frame(
  RACE = character(),
  Cohort = character(),
  Stable_Distribution = character(),
  Significant_Changes = character(),
  stringsAsFactors = FALSE
)

summarize_results &lt;- function(test_results, race) {
  summary_list &lt;- list()
  
  for (birth_range in names(test_results)) {
    test_result &lt;- test_results[[birth_range]]
    
    stable &lt;- ifelse(test_result$p.value &gt;= 0.05, &quot;Yes&quot;, &quot;No&quot;)
    significant_changes &lt;- ifelse(test_result$p.value &lt; 0.05, &quot;Yes&quot;, &quot;No&quot;)
    
    summary_list[[birth_range]] &lt;- data.frame(
      RACE = race,
      Cohort = birth_range,
      Stable_Distribution = stable,
      Significant_Changes = significant_changes
    )
  }
  
  do.call(rbind, summary_list)
}

results_summary_black &lt;- summarize_results(results_sib_b, &quot;Black/African American&quot;)

results_summary_white &lt;- summarize_results(results_sib_w, &quot;White&quot;)

results_summary &lt;- rbind(results_summary, results_summary_black, results_summary_white)

rownames(results_summary) &lt;- NULL 

results_summary</code></pre>
<pre><code>                    RACE    Cohort Stable_Distribution Significant_Changes
1 Black/African American 1901-1910                  No                 Yes
2 Black/African American 1911-1920                  No                 Yes
3 Black/African American 1921-1930                  No                 Yes
4 Black/African American 1931-1940                 Yes                  No
5                  White 1901-1910                  No                 Yes
6                  White 1911-1920                 Yes                  No
7                  White 1921-1930                 Yes                  No
8                  White 1931-1940                 Yes                  No</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Visualize stability:
<ul>
<li>Create a heatmap or similar plot showing stability/changes across
cohorts and races.</li>
</ul></li>
</ol>
<pre class="r"><code>ggplot(results_summary, aes(x = Cohort, y = RACE, fill = Significant_Changes)) +
  geom_tile(color = &quot;white&quot;) +
  scale_fill_manual(values = c(&quot;Yes&quot; = &quot;#e93e3a&quot;, &quot;No&quot; = &quot;#fdc70c&quot;)) +
  labs(title = &quot;Significant Changes in Sibling Count Distribution Across Years by Race and Birth Range&quot;,
       x = &quot;Birth Range&quot;,
       y = &quot;Race&quot;,
       fill = &quot;Significant Changes&quot;) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-67-1.png" width="864" style="display: block; margin: auto;" /></p>
<ol start="5" style="list-style-type: decimal">
<li>Interpret results:
<ul>
<li>Identify which cohorts show stable sibling distributions.</li>
<li>Compare stability patterns to those observed in the children
distribution analysis.</li>
<li>Discuss implications of stability or lack thereof for understanding
family structure changes over time.</li>
</ul></li>
</ol>
<p><strong><em>RESULT:</em></strong> From the plot above, we can see the
distribution of sibling is stable in the following cohorts by race:
-black population:1901-1919, 1911-1920, 1921-1930 -white
population:1901-1910</p>
</div>
</div>
<div id="apply-similar-analysis-performed-in-the-childrens-part"
class="section level2">
<h2>Apply similar analysis performed in the children’s part:</h2>
<ol style="list-style-type: decimal">
<li>Zero Inflation: Check if the proportion of individuals with zero
siblings changes significantly over time for the same cohort.</li>
</ol>
<pre class="r"><code>best_models_sib &lt;- best_models_sib %&gt;%
  mutate(Cohort = mapply(calculate_cohort, Census_Year, AGE_RANGE)) %&gt;% 
  dplyr::select(Race, Census_Year, AGE_RANGE, Best_Model, Cohort)

df_merg2 &lt;- df2 %&gt;%
  rename(Census_Year = YEAR, Race = RACE)

# Perform a left join to merge the data frames
merged_data_sib &lt;- left_join(df_merg2, best_models_sib, by = c(&quot;Race&quot;, &quot;Census_Year&quot;, &quot;AGE_RANGE&quot;))</code></pre>
<pre class="r"><code>## divided the corhort by race
merged_df_black2 &lt;- merged_data_sib %&gt;% filter(Race == &quot;Black/African American&quot;)
merged_df_white2 &lt;- merged_data_sib %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code># Filter cohorts with more than one census year
cohort_counts &lt;- merged_df_black2 %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test &lt;- cohort_counts$Cohort

# Initialize results data frame
results_black2 &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test) {
  cohort_data &lt;- merged_df_black2 %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$n_siblings == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_black2 &lt;- rbind(results_black2, data.frame(
      RACE = &quot;Black/African American&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
  }
}

results_black2 &lt;- results_black2 %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_black2)</code></pre>
<pre><code>                             RACE    Cohort Chi_Square    p_value Significance
X-squared  Black/African American 1901-1910  2.7595148 0.09667755           No
X-squared1 Black/African American 1911-1920  3.1588986 0.20608856           No
X-squared2 Black/African American 1921-1930  6.4474388 0.03980673          Yes
X-squared3 Black/African American 1931-1940  0.8166152 0.36617166           No</code></pre>
<p><strong><em>RESULT:</em></strong> The table shows that only the
cohort 1921-1930 has significant change in probability of individuals
with zero siblings in black population.</p>
<pre class="r"><code># Filter cohorts with more than one census year
cohort_counts &lt;- merged_df_white2 %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test &lt;- cohort_counts$Cohort

# Initialize results data frame
results_white2 &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test) {
  cohort_data &lt;- merged_df_white2 %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$n_siblings == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_white2 &lt;- rbind(results_white2, data.frame(
      RACE = &quot;White&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
  }
}

results_white2 &lt;- results_white2 %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_white2)</code></pre>
<pre><code>            RACE    Cohort Chi_Square      p_value Significance
X-squared  White 1901-1910  46.930953 7.353216e-12          Yes
X-squared1 White 1911-1920 120.015145 8.690450e-27          Yes
X-squared2 White 1921-1930  79.061388 6.792628e-18          Yes
X-squared3 White 1931-1940   2.776021 9.568561e-02           No</code></pre>
<p><strong><em>RESULT:</em></strong> The table shows that cohorts
1901-1910, 1911-1920, 1921-1930 have significant change in probability
of individuals with zero siblings in white population.</p>
<ol start="2" style="list-style-type: decimal">
<li>Family Size: Test if the mean or variance in the number of siblings
changes for the same cohort over time.</li>
</ol>
<pre class="r"><code>sum_table_sib &lt;- merged_data_sib %&gt;% group_by(Race, Cohort, Census_Year) %&gt;%
  summarise(
    Mean = mean(chborn_num),
    Variance = var(chborn_num))</code></pre>
<pre><code>`summarise()` has grouped output by &#39;Race&#39;, &#39;Cohort&#39;. You can override using
the `.groups` argument.</code></pre>
<pre class="r"><code>merged_sib &lt;- left_join(merged_data_sib, sum_table_sib, by = c(&quot;Race&quot;,&quot;Cohort&quot;,&quot;Census_Year&quot;)) %&gt;% dplyr::select(Race, Cohort, Census_Year, Mean, Variance)

sum_table_black = merged_sib %&gt;% filter(Race == &quot;Black/African American&quot;)
sum_table_white = merged_sib %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code>##Test for Black population
cohorts1 &lt;- unique(sum_table_black$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts1) {
  
  # Filter data for the specific cohort
  cohort_data_b &lt;- sum_table_black[sum_table_black$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_b$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_b)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean number of Siblings:\n&quot;)
  print(summary(anova_mean_result))
}</code></pre>
<pre><code>
Cohort: 1891-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1911-1920
ANOVA for Mean number of Siblings:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     2  5.453   2.727 8.507e+23 &lt;2e-16 ***
Residuals           38001  0.000   0.000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1901-1910
ANOVA for Mean number of Siblings:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     1  77.51   77.51 7.094e+25 &lt;2e-16 ***
Residuals           22789   0.00    0.00                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1890 has only one Census Year. Skipping ANOVA.

Cohort: 1921-1930
ANOVA for Mean number of Siblings:
                       Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     2    417   208.5 4.477e+26 &lt;2e-16 ***
Residuals           43042      0     0.0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1931-1940
ANOVA for Mean number of Siblings:
                       Df  Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)     1 0.03475 0.03475 1.223e+22 &lt;2e-16 ***
Residuals           22555 0.00000 0.00000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1910 has only one Census Year. Skipping ANOVA.

Cohort: 1941-1950 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1920 has only one Census Year. Skipping ANOVA.</code></pre>
<p><strong><em>RESULT:</em></strong> The mean number of siblings change
significantly in cohorts 1901-1910, 1911-1920, 1921-1930, 1931-1940 in
black population.</p>
<pre class="r"><code>##Test for White population
cohorts2 &lt;- unique(sum_table_white$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts2) {
  
  # Filter data for the specific cohort
  cohort_data_w &lt;- sum_table_white[sum_table_white$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_w$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_w)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean number of Siblings:\n&quot;)
  print(summary(anova_mean_result))
  
}</code></pre>
<pre><code>
Cohort: 1891-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1911-1920
ANOVA for Mean number of Siblings:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      2  535.2   267.6 4.546e+24 &lt;2e-16 ***
Residuals           365210    0.0     0.0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1901-1910
ANOVA for Mean number of Siblings:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      1   1281    1281 9.604e+25 &lt;2e-16 ***
Residuals           226142      0       0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1890 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1900 has only one Census Year. Skipping ANOVA.

Cohort: 1921-1930
ANOVA for Mean number of Siblings:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      2  653.9     327 8.029e+23 &lt;2e-16 ***
Residuals           394507    0.0       0                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: 1931-1940
ANOVA for Mean number of Siblings:
                        Df Sum Sq Mean Sq   F value Pr(&gt;F)    
factor(Census_Year)      1  1.829   1.829 8.533e+22 &lt;2e-16 ***
Residuals           179944  0.000   0.000                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Cohort: -Inf-1910 has only one Census Year. Skipping ANOVA.

Cohort: -Inf-1920 has only one Census Year. Skipping ANOVA.

Cohort: 1941-1950 has only one Census Year. Skipping ANOVA.</code></pre>
<p><strong><em>RESULT:</em></strong> The mean number of siblings change
significantly in cohorts 1901-1910, 1911-1920, 1921-1930, 1931-1940 in
white population.</p>
<ol start="3" style="list-style-type: decimal">
<li>Model Fit: Analyze if the best-fitting model for the cohort changes
over time.</li>
</ol>
<pre class="r"><code>ggplot(best_models_sib, aes(x = Census_Year, y = Cohort, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + # Create the tiles
  facet_wrap(~Race, nrow = 2) + # Facet by Race
  scale_fill_manual(values = c(&quot;Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;, &quot;Negative_Binomial&quot; = &quot;grey&quot;)) + 
  labs(
    title = &quot;Best Model(siblings) by Race, Census Year, and Cohort(Birth Range)&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Birth Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-75-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-75-1">
Past versions of unnamed-chunk-75-1.png
</button>
</p>
<div id="fig-unnamed-chunk-75-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/231390a7e9b5261ed01047322fdbca2676183be9/docs/figure/relative-distribution.Rmd/unnamed-chunk-75-1.png" target="_blank">231390a</a>
</td>
<td>
linmatch
</td>
<td>
2024-12-11
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong><em>RESULT:</em></strong> The best model for each
cohort(those with 1+ corresponding census year) is stable over time.</p>
</div>
<div id="instructions-for-manqing-plot-across-census-years-siblings"
class="section level2">
<h2>[Instructions for Manqing] Plot Across Census Years Siblings</h2>
<div id="objective-4" class="section level3">
<h3>Objective</h3>
<p>Create a visualization showing how sibling distributions change
across census years for different races and birth ranges.</p>
</div>
<div id="steps-2" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Use the sibling distribution data
(<code>df_sibling_proportions</code>).</p></li>
<li><p>Create a multi-panel plot:</p>
<ul>
<li>X-axis: Number of siblings (0 to 12+)</li>
<li>Y-axis: Proportion</li>
<li>Color: Census Year</li>
<li>Facet by: RACE and AGE_RANGE</li>
</ul></li>
<li><p>Use <code>ggplot2</code> to create the plot:</p></li>
</ol>
<pre class="r"><code>df_sibling_proportions %&gt;%
  filter(n_siblings &gt;= 0, sibling_count &gt;= 0, proportion &gt;= 0) %&gt;% ggplot(aes(x = n_siblings, y = proportion, color = factor(YEAR))) +
 geom_line() +
 facet_grid(RACE ~ AGE_RANGE) +
 labs(title = &quot;Sibling Distribution Across Census Years&quot;,
      x = &quot;Number of Siblings&quot;, y = &quot;Proportion&quot;, color = &quot;Census Year&quot;) +
 theme_minimal() +
 theme(axis.text.x = element_text(hjust = 1))</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-76-1.png" width="864" style="display: block; margin: auto;" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Analyze the plot:
<ul>
<li>Identify trends in sibling distribution changes over time.</li>
<li>Compare patterns between races and across birth ranges.</li>
<li>Note any significant shifts or stable periods.</li>
</ul></li>
<li>Compare with children distribution plot:
<ul>
<li>Highlight similarities and differences in trends.</li>
<li>Discuss what these comparisons reveal about changing family
structures.</li>
</ul></li>
</ol>
<p>Remember to reference your findings from the children distribution
analysis when discussing the results, highlighting any notable
similarities or differences between the two analyses.</p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.2 (2023-10-31)
Platform: x86_64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.5

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Detroit
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] rstatix_0.7.2     car_3.1-3         carData_3.0-5     nnet_7.3-19      
 [5] pscl_1.5.9        MASS_7.3-60       gridExtra_2.3     ggnewscale_0.5.0 
 [9] patchwork_1.2.0   rempsyc_0.1.8     scales_1.3.0      knitr_1.45       
[13] viridis_0.6.5     viridisLite_0.4.2 lubridate_1.9.3   forcats_1.0.0    
[17] stringr_1.5.1     purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      
[21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0   dplyr_1.1.4      
[25] workflowr_1.7.1  

loaded via a namespace (and not attached):
 [1] gtable_0.3.4      xfun_0.41         bslib_0.6.1       processx_3.8.3   
 [5] callr_3.7.3       tzdb_0.4.0        vctrs_0.6.5       tools_4.3.2      
 [9] ps_1.7.6          generics_0.1.3    fansi_1.0.6       highr_0.10       
[13] pkgconfig_2.0.3   lifecycle_1.0.4   farver_2.1.1      compiler_4.3.2   
[17] git2r_0.33.0      munsell_0.5.0     getPass_0.2-4     httpuv_1.6.14    
[21] htmltools_0.5.7   sass_0.4.8        yaml_2.3.8        Formula_1.2-5    
[25] later_1.3.2       pillar_1.9.0      jquerylib_0.1.4   whisker_0.4.1    
[29] cachem_1.0.8      abind_1.4-8       tidyselect_1.2.1  digest_0.6.34    
[33] stringi_1.8.3     labeling_0.4.3    rprojroot_2.0.4   fastmap_1.1.1    
[37] grid_4.3.2        colorspace_2.1-0  cli_3.6.2         magrittr_2.0.3   
[41] utf8_1.2.4        broom_1.0.6       withr_3.0.0       backports_1.5.0  
[45] promises_1.2.1    timechange_0.3.0  rmarkdown_2.25    httr_1.4.7       
[49] hms_1.1.3         evaluate_0.23     rlang_1.1.3       Rcpp_1.0.12      
[53] glue_1.7.0        rstudioapi_0.15.0 jsonlite_1.8.9    R6_2.5.1         
[57] fs_1.6.3         </code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
