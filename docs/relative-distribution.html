<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Manqing Lin, Tina Lasisi" />


<title>Estimating Differences in the Distribution of First-degree Relatives</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">PODFRIDGE</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/lasisilab/PODFRIDGE">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Estimating Differences in the Distribution
of First-degree Relatives</h1>
<h4 class="author">Manqing Lin, Tina Lasisi</h4>
<h4 class="date">2024-11-12 14:27:51</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2024-11-12
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>PODFRIDGE/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges">
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted
changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges"
class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of
the R Markdown file created these results, you’ll want to first commit
it to the Git repo. If you’re still working on the analysis, you can
ignore this warning. When you’re finished, you can run
<code>wflow_publish</code> to commit the R Markdown file and build the
HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20230302code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20230302)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20230302code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20230302)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomlasisilabPODFRIDGEtree3069ce172ec5df7154ecfbde0113f102c173e68btargetblank3069ce1a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/lasisilab/PODFRIDGE/tree/3069ce172ec5df7154ecfbde0113f102c173e68b" target="_blank">3069ce1</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomlasisilabPODFRIDGEtree3069ce172ec5df7154ecfbde0113f102c173e68btargetblank3069ce1a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/lasisilab/PODFRIDGE/tree/3069ce172ec5df7154ecfbde0113f102c173e68b" target="_blank">3069ce1</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.Rhistory
    Ignored:    analysis/figure/
    Ignored:    data/.DS_Store

Unstaged changes:
    Modified:   analysis/relative-distribution.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/relative-distribution.Rmd</code>)
and HTML (<code>docs/relative-distribution.html</code>) files. If you’ve
configured a remote Git repository (see <code>?wflow_git_remote</code>),
click on the hyperlinks in the table below to view the files as they
were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/06a8f9602d51a58fe87d4ac678eb63ef39cf2275/analysis/relative-distribution.Rmd" target="_blank">06a8f96</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
update sibling’s part
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/06a8f9602d51a58fe87d4ac678eb63ef39cf2275/docs/relative-distribution.html" target="_blank">06a8f96</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
update sibling’s part
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/1741cb1d69036bd588d6f00cdff2b95b37a1b106/analysis/relative-distribution.Rmd" target="_blank">1741cb1</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix test
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/4e68621bb2cf39f3713f32ebf0d1640cd0cf2edd/analysis/relative-distribution.Rmd" target="_blank">4e68621</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix chisq-test in cohort stability
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/4e68621bb2cf39f3713f32ebf0d1640cd0cf2edd/docs/relative-distribution.html" target="_blank">4e68621</a>
</td>
<td>
linmatch
</td>
<td>
2024-11-05
</td>
<td>
fix chisq-test in cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/6fb5b405d09346d07e1d2be9e59158068a385b20/analysis/relative-distribution.Rmd" target="_blank">6fb5b40</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-29
</td>
<td>
update sibling’s distribution plot
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/570abb077e3ce782ed0ad4a4efadedacced84fbc/analysis/relative-distribution.Rmd" target="_blank">570abb0</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
update sibling part
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/2e09e084a0ab4c6710fc50bf2575a64d7115435e/analysis/relative-distribution.Rmd" target="_blank">2e09e08</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
workflow build
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/2e09e084a0ab4c6710fc50bf2575a64d7115435e/docs/relative-distribution.html" target="_blank">2e09e08</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-22
</td>
<td>
workflow build
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/bb2c61b7f74db6bd5d5499c3a5769fe950aa670e/analysis/relative-distribution.Rmd" target="_blank">bb2c61b</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-21
</td>
<td>
complete fertility shift analysis
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/842d935f1027fd858cabf2fd48684e824c1699b3/analysis/relative-distribution.Rmd" target="_blank">842d935</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-17
</td>
<td>
update fertility shift
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/2ae84609413327192cca951dc7e71dcc4000f910/analysis/relative-distribution.Rmd" target="_blank">2ae8460</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-16
</td>
<td>
fix the chisq-test
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/9632ae1f7420addbaec02a4b92ea9258b6e67e22/analysis/relative-distribution.Rmd" target="_blank">9632ae1</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-12
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/9852339ae0eb8c21fbeff0dd60f78482a2a51982/analysis/relative-distribution.Rmd" target="_blank">9852339</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-08
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/9852339ae0eb8c21fbeff0dd60f78482a2a51982/docs/relative-distribution.html" target="_blank">9852339</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-08
</td>
<td>
update cohort stability
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/7ec169f19f763fa4ae4cc479e001d89c48eac353/analysis/relative-distribution.Rmd" target="_blank">7ec169f</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-03
</td>
<td>
update sibling distribution
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/27b986fd03c7db1db62f9a234ac2146626f39047/analysis/relative-distribution.Rmd" target="_blank">27b986f</a>
</td>
<td>
linmatch
</td>
<td>
2024-10-01
</td>
<td>
update stability cohort analysis
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/57a97dbc76b451268df7314c0de6b4c5bc724680/analysis/relative-distribution.Rmd" target="_blank">57a97db</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-30
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/52aa7f848be819c985c7ec16b22558aaebebe01c/analysis/relative-distribution.Rmd" target="_blank">52aa7f8</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-27
</td>
<td>
improving code on Part1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/c54a746c06249bc02d4a778c9e3b16e887891fce/analysis/relative-distribution.Rmd" target="_blank">c54a746</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-26
</td>
<td>
update and fix step 2
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/94d00b35b4a3f33e6e96a1d8ec016a851774f05f/analysis/relative-distribution.Rmd" target="_blank">94d00b3</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-24
</td>
<td>
fix step1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/1225480d79d7a80647f573e73fa72cbe517bafc6/analysis/relative-distribution.Rmd" target="_blank">1225480</a>
</td>
<td>
linmatch
</td>
<td>
2024-09-23
</td>
<td>
update on step1
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/83174c03bbc21104de64adb0e1c6e15a206d48bc/analysis/relative-distribution.Rmd" target="_blank">83174c0</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-22
</td>
<td>
Instructions and layout for relative distribution
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/83174c03bbc21104de64adb0e1c6e15a206d48bc/docs/relative-distribution.html" target="_blank">83174c0</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-22
</td>
<td>
Instructions and layout for relative distribution
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/78c162184b484b2c22526171033ab3dc7235d2de/analysis/relative-distribution.Rmd" target="_blank">78c1621</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/f4c2830d4e6d627e954221b90ac013605f417de2/analysis/relative-distribution.Rmd" target="_blank">f4c2830</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
Update relative-distribution.Rmd
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/analysis/relative-distribution.Rmd" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
rename old analysis
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/lasisilab/PODFRIDGE/28513857e94c801ed7d27e62bb34ff8098d08107/docs/relative-distribution.html" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
<td>
rename old analysis
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The relative genetic surveillance of a population is influenced by
the number of genetically detectable relatives individuals have.
First-degree relatives (parents, siblings, and children) are especially
relevant in forensic analyses using short tandem repeat (STR) loci,
where close familial searches are commonly employed. To explore
potential disparities in genetic detectability between African American
and European American populations, we examined U.S. Census data from
four census years (1960, 1970, 1980, and 1990) focusing on the number of
children born to women over the age of 40.</p>
</div>
<div id="data-sources" class="section level2">
<h2>Data Sources</h2>
<p>We used publicly available data from the Integrated Public Use
Microdata Series (IPUMS) for the U.S. Census years 1960, 1970, 1980, and
1990. The datasets include information on:</p>
<ul>
<li>AGE: Age of the respondent.</li>
<li>RACE: Self-identified race of the respondent.</li>
<li>chborn_num: Number of children ever born to the respondent.</li>
</ul>
<p>Data citation: Steven Ruggles, Sarah Flood, Matthew Sobek, Daniel
Backman, Annie Chen, Grace Cooper, Stephanie Richards, Renae Rogers, and
Megan Schouweiler. IPUMS USA: Version 14.0 [dataset]. Minneapolis, MN:
IPUMS, 2023. <a href="https://doi.org/10.18128/D010.V14.0"
class="uri">https://doi.org/10.18128/D010.V14.0</a></p>
</div>
<div id="data-preparation" class="section level2">
<h2>Data Preparation</h2>
<p>Filtering Criteria: We selected women aged 40 and above to ensure
that most had completed childbearing.</p>
<p>Due to the terms of agreement for using this data, we cannot share
the full dataset but our repo contains the subset that was used to
calculate the mean number of offspring and variance.</p>
<p>Race Classification: We categorized individuals into two groups:</p>
<ul>
<li>African American: Those who identified as “Black” or “African
American”.</li>
<li>European American: Those who identified as “White”.</li>
</ul>
<p>Calculating Number of Siblings: For each child of these women, the
number of siblings (n_sib) is one less than the number of children born
to the mother:</p>
<p><span class="math display">\[
n_{sib} = chborn_{num} - 1
\]</span></p>
<pre class="r"><code>path &lt;- file.path(&quot;.&quot;, &quot;data&quot;)
savepath &lt;- file.path(&quot;.&quot;, &quot;output&quot;)

prop_race_year &lt;- file.path(path, &quot;proportions_table_by_race_year.csv&quot;)
data_filter &lt;- file.path(path, &quot;data_filtered_recoded.csv&quot;)

children_data = read.csv(prop_race_year)
mother_data = read.csv(data_filter)</code></pre>
<pre class="r"><code>df &lt;- mother_data %&gt;%
  # Filter for women aged 40 and above
  filter(AGE &gt;= 40) %&gt;%
  mutate(
    # Create new age ranges
    AGE_RANGE = case_when(
      AGE &gt;= 70 ~ &quot;70+&quot;,
      AGE &gt;= 60 ~ &quot;60-69&quot;,
      AGE &gt;= 50 ~ &quot;50-59&quot;,
      AGE &gt;= 40 ~ &quot;40-49&quot;,
      TRUE ~ as.character(AGE_RANGE)  # This shouldn&#39;t occur due to the filter, but included for completeness
    ),
    # Convert CHBORN to ordered factor
    CHBORN = factor(case_when(
      chborn_num == 0 ~ &quot;No children&quot;,
      chborn_num == 1 ~ &quot;1 child&quot;,
      chborn_num == 2 ~ &quot;2 children&quot;,
      chborn_num == 3 ~ &quot;3 children&quot;,
      chborn_num == 4 ~ &quot;4 children&quot;,
      chborn_num == 5 ~ &quot;5 children&quot;,
      chborn_num == 6 ~ &quot;6 children&quot;,
      chborn_num == 7 ~ &quot;7 children&quot;,
      chborn_num == 8 ~ &quot;8 children&quot;,
      chborn_num == 9 ~ &quot;9 children&quot;,
      chborn_num == 10 ~ &quot;10 children&quot;,
      chborn_num == 11 ~ &quot;11 children&quot;,
      chborn_num &gt;= 12 ~ &quot;12+ children&quot;
    ), levels = c(&quot;No children&quot;, &quot;1 child&quot;, &quot;2 children&quot;, &quot;3 children&quot;, 
                  &quot;4 children&quot;, &quot;5 children&quot;, &quot;6 children&quot;, &quot;7 children&quot;, 
                  &quot;8 children&quot;, &quot;9 children&quot;, &quot;10 children&quot;, &quot;11 children&quot;, 
                  &quot;12+ children&quot;), ordered = TRUE),
    
    # Ensure RACE variable is correctly formatted and filtered
    RACE = factor(RACE, levels = c(&quot;White&quot;, &quot;Black/African American&quot;))
  ) %&gt;%
  # Filter for African American and European American women
  filter(RACE %in% c(&quot;Black/African American&quot;, &quot;White&quot;)) %&gt;%
  # Select and reorder columns
  dplyr::select(YEAR, SEX, AGE, BIRTHYR, RACE, CHBORN, AGE_RANGE, chborn_num)

# Display the first few rows of the processed data
head(df)</code></pre>
<pre><code>  YEAR    SEX AGE BIRTHYR  RACE      CHBORN AGE_RANGE chborn_num
1 1960 Female  65    1894 White No children     60-69          0
2 1960 Female  49    1911 White  2 children     40-49          2
3 1960 Female  54    1905 White No children     50-59          0
4 1960 Female  56    1903 White     1 child     50-59          1
5 1960 Female  54    1905 White     1 child     50-59          1
6 1960 Female  50    1910 White No children     50-59          0</code></pre>
<pre class="r"><code># Summary of the processed data
summary(df)</code></pre>
<pre><code>      YEAR          SEX                 AGE            BIRTHYR    
 Min.   :1960   Length:1917477     Min.   : 41.00   Min.   :1859  
 1st Qu.:1970   Class :character   1st Qu.: 49.00   1st Qu.:1905  
 Median :1970   Mode  :character   Median : 58.00   Median :1916  
 Mean   :1976                      Mean   : 59.24   Mean   :1916  
 3rd Qu.:1980                      3rd Qu.: 68.00   3rd Qu.:1926  
 Max.   :1990                      Max.   :100.00   Max.   :1949  
                                                                  
                     RACE                 CHBORN        AGE_RANGE        
 White                 :1740755   2 children :452594   Length:1917477    
 Black/African American: 176722   No children:343319   Class :character  
                                  3 children :335119   Mode  :character  
                                  1 child    :292001                     
                                  4 children :204983                     
                                  5 children :113593                     
                                  (Other)    :175868                     
   chborn_num   
 Min.   : 0.00  
 1st Qu.: 1.00  
 Median : 2.00  
 Mean   : 2.57  
 3rd Qu.: 4.00  
 Max.   :12.00  
                </code></pre>
<pre class="r"><code># Check the levels of the RACE factor
levels(df$RACE)</code></pre>
<pre><code>[1] &quot;White&quot;                  &quot;Black/African American&quot;</code></pre>
<pre class="r"><code># Count of observations by RACE
table(df$RACE)</code></pre>
<pre><code>
                 White Black/African American 
               1740755                 176722 </code></pre>
<pre class="r"><code># Count of observations by AGE_RANGE
table(df$AGE_RANGE)</code></pre>
<pre><code>
 40-49  50-59  60-69    70+ 
529160 517620 436829 433868 </code></pre>
</div>
<div id="distribution-of-number-of-children-across-census-years"
class="section level1">
<h1>Distribution of Number of Children Across Census Years</h1>
<p>First we visualize the general trends in the frequency of the number
of children for African American and European American mothers across
the Census years by age group.</p>
<pre class="r"><code># Calculate proportions within each group, ensuring proper normalization
df_proportions &lt;- df %&gt;%
  group_by(YEAR, RACE, AGE_RANGE, chborn_num) %&gt;%
  summarise(count = n(), .groups = &quot;drop&quot;) %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  mutate(proportion = count / sum(count)) %&gt;%
  ungroup()

# Reshape data for the mirror plot
df_mirror &lt;- df_proportions %&gt;%
  mutate(proportion = if_else(RACE == &quot;White&quot;, -proportion, proportion))

# Create color palette
my_colors &lt;- colorRampPalette(c(&quot;#FFB000&quot;, &quot;#F77A2E&quot;, &quot;#DE3A8A&quot;, &quot;#7253FF&quot;, &quot;#5E8BFF&quot;))(13)

# Create the plot
child_plot &lt;- ggplot(df_mirror, aes(x = chborn_num, y = proportion, fill = as.factor(chborn_num))) +
  geom_col(aes(alpha = RACE)) +
  geom_hline(yintercept = 0, color = &quot;black&quot;, size = 0.5) +
  facet_grid(AGE_RANGE ~ YEAR, scales = &quot;free_y&quot;) +
  coord_flip() +
  scale_y_continuous(
    labels = function(x) abs(x),
    limits = function(x) c(-max(abs(x)), max(abs(x)))
  ) +
  scale_x_continuous(breaks = 0:12, labels = c(0:11, &quot;12+&quot;)) +
  scale_fill_manual(values = my_colors) +
  scale_alpha_manual(values = c(&quot;White&quot; = 0.7, &quot;Black/African American&quot; = 1), guide = &quot;none&quot;) +
  labs(
    title = &quot;Distribution of Number of Children by Census Year, Race, and Age Range&quot;,
    x = &quot;Number of Children&quot;,
    y = &quot;Proportion&quot;,
    fill = &quot;Number of Children&quot;,
    caption = &quot;White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10),
    legend.position = &quot;none&quot;,
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )

print(child_plot)</code></pre>
<p><img src="figure/relative-distribution.Rmd/unnamed-chunk-2-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-2-1">
Past versions of unnamed-chunk-2-1.png
</button>
</p>
<div id="fig-unnamed-chunk-2-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/83174c03bbc21104de64adb0e1c6e15a206d48bc/docs/figure/relative-distribution.Rmd/unnamed-chunk-2-1.png" target="_blank">83174c0</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-22
</td>
</tr>
<tr>
<td>
<a href="https://github.com/lasisilab/PODFRIDGE/blob/28513857e94c801ed7d27e62bb34ff8098d08107/docs/figure/relative-distribution.Rmd/unnamed-chunk-2-1.png" target="_blank">2851385</a>
</td>
<td>
Tina Lasisi
</td>
<td>
2024-09-21
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code># Print summary to check age ranges and normalization
print(df_proportions %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  summarise(total_proportion = sum(proportion), .groups = &quot;drop&quot;) %&gt;%
  arrange(YEAR, RACE, AGE_RANGE))</code></pre>
<pre><code># A tibble: 32 × 4
    YEAR RACE                   AGE_RANGE total_proportion
   &lt;int&gt; &lt;fct&gt;                  &lt;chr&gt;                &lt;dbl&gt;
 1  1960 White                  40-49                    1
 2  1960 White                  50-59                    1
 3  1960 White                  60-69                    1
 4  1960 White                  70+                      1
 5  1960 Black/African American 40-49                    1
 6  1960 Black/African American 50-59                    1
 7  1960 Black/African American 60-69                    1
 8  1960 Black/African American 70+                      1
 9  1970 White                  40-49                    1
10  1970 White                  50-59                    1
# ℹ 22 more rows</code></pre>
<p>With this visualization of the distribution of the data, we can see
that there are differences between White and Black Americans.</p>
<p>We will now test for differences in 1) the mean and variance, and 2)
zero-inflation.</p>
<div id="instructions-for-manqing-model-fit-across-census-years"
class="section level2">
<h2>[instructions for Manqing] Model Fit Across Census Years</h2>
<p><strong>Question 1) What is the best model for the distribution of
the data in each of these subsets of data (by race, by census year, by
age range combined)?</strong></p>
<div id="step-1-fit-models-across-all-subsets" class="section level3">
<h3>Step 1: Fit Models Across All Subsets</h3>
<p>For each combination of race, census year, and age range, fit your
candidate models:</p>
<ul>
<li><strong>Poisson Model</strong></li>
<li><strong>Negative Binomial (NB) Model</strong></li>
<li><strong>Zero-Inflated Poisson (ZIP) Model</strong></li>
<li><strong>Zero-Inflated Negative Binomial (ZINB) Model</strong></li>
</ul>
<p>This should be done for each subset of the data (race × census year ×
age range).</p>
<p><strong>Understanding the Data:</strong></p>
<ul>
<li><strong>Data Type:</strong> Count data representing the number of
children per woman.</li>
<li><strong>Characteristics:</strong>
<ul>
<li>Potential overdispersion (variance greater than the mean).</li>
<li>Possible zero-inflation (excess zeros) in some subsets.</li>
<li>Different distributions across races, census years, and age
ranges.</li>
</ul></li>
</ul>
<p><strong>Candidate Models for Count Data:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Poisson Distribution:</strong>
<ul>
<li>Assumes mean equals variance.</li>
<li>Not suitable if overdispersion is present.</li>
</ul></li>
<li><strong>Negative Binomial Distribution:</strong>
<ul>
<li>Handles overdispersion by introducing a dispersion parameter.</li>
<li>Suitable when variance exceeds the mean.</li>
</ul></li>
<li><strong>Zero-Inflated Models:</strong>
<ul>
<li><strong>Zero-Inflated Poisson (ZIP):</strong>
<ul>
<li>Combines a Poisson distribution with a point mass at zero.</li>
<li>Suitable if there’s an excess of zeros.</li>
</ul></li>
<li><strong>Zero-Inflated Negative Binomial (ZINB):</strong>
<ul>
<li>Combines a negative binomial distribution with a point mass at
zero.</li>
<li>Handles both overdispersion and excess zeros.</li>
</ul></li>
</ul></li>
<li><strong>Hurdle Models: (optional)</strong>
<ul>
<li>Similar to zero-inflated models but model zeros and positive counts
separately.</li>
</ul></li>
</ol>
<p><strong>Recommended Approach:</strong></p>
<p><strong>1: Exploratory Data Analysis (EDA)</strong></p>
<ul>
<li><strong>Compute Mean and Variance:</strong>
<ul>
<li>For each subset (race, census year, age range), calculate the mean
and variance of the number of children.</li>
<li>Check for overdispersion: If variance &gt; mean, overdispersion is
present.</li>
</ul></li>
<li><strong>Check for Zero-Inflation:</strong>
<ul>
<li>Calculate the proportion of zeros in each subset.</li>
<li>If the proportion of zeros is significantly higher than expected
under a standard Poisson or negative binomial model, consider
zero-inflated models.</li>
</ul></li>
</ul>
<p><strong>2: Model Selection</strong></p>
<p><strong>Scenario 1: Overdispersion Without Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Negative Binomial Distribution</li>
<li><strong>Justification:</strong> Handles overdispersion
effectively.</li>
</ul>
<p><strong>Scenario 2: Overdispersion With Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Zero-Inflated Negative Binomial (ZINB)
Distribution</li>
<li><strong>Justification:</strong> Accounts for both overdispersion and
excess zeros.</li>
</ul>
<p><strong>Scenario 3: No Overdispersion, No Excess Zeros</strong></p>
<ul>
<li><strong>Model:</strong> Poisson Distribution</li>
<li><strong>Justification:</strong> Appropriate if mean equals variance
and no excess zeros.</li>
</ul>
<p><strong>3: Fit Models to Each Subset</strong></p>
<ul>
<li><strong>For Each Subset:</strong>
<ul>
<li>Fit a Poisson model.</li>
<li>Fit a Negative Binomial model.</li>
<li>If necessary, fit a Zero-Inflated Poisson (ZIP) and Zero-Inflated
Negative Binomial (ZINB) model.</li>
</ul></li>
<li><strong>Compare Models:</strong>
<ul>
<li>Use goodness-of-fit measures such as Akaike Information Criterion
(AIC) or Bayesian Information Criterion (BIC).</li>
<li>Lower AIC/BIC indicates a better-fitting model.</li>
<li>Perform likelihood ratio tests where appropriate.</li>
</ul></li>
</ul>
</div>
<div id="step-2-model-comparison-using-aic-or-bic"
class="section level3">
<h3>Step 2: Model Comparison Using AIC or BIC</h3>
<p>Once the models are fitted, compare them using goodness-of-fit
criteria like <strong>AIC</strong> or <strong>BIC</strong> for each
subset. The model with the <strong>lowest AIC/BIC</strong> is the best
fit for that subset.</p>
<ul>
<li><strong>Assess Model Fit:</strong>
<ul>
<li>Check residuals for patterns.</li>
<li>Use diagnostic plots.</li>
</ul></li>
<li><strong>Check Dispersion Parameter:</strong>
<ul>
<li>For negative binomial models, examine the estimated dispersion
parameter.</li>
</ul></li>
<li><strong>Vuong Test:</strong>
<ul>
<li>Compare zero-inflated models to standard models to assess if
zero-inflation significantly improves the fit.</li>
</ul></li>
</ul>
<pre class="r"><code>## Approach 1:
combinations &lt;- df %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  group_split()

# Initialize the data frame for storing results
EDA_df &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  Age_Range = character(),
  Overdispersion = logical(), 
  Zero_Inflation = logical(),
  stringsAsFactors = FALSE
)

# Initialize vectors for overdispersion and zero-inflation
overdispersion &lt;- logical(length(combinations))
zero_inflation &lt;- logical(length(combinations))

for (i in seq_along(combinations)) {
  subset_data &lt;- combinations[[i]]
  mean_chborn &lt;- mean(subset_data$chborn_num)
  var_chborn &lt;- var(subset_data$chborn_num)
  
  # Check for overdispersion (variance &gt; mean)
  overdispersion[i] &lt;- var_chborn &gt; mean_chborn
  
  # Check for zero-inflation
  prop_zero &lt;- sum(subset_data$chborn_num == 0) / nrow(subset_data)
  
  # Compare prop_zero to expected under Poisson
  exp_poisson &lt;- exp(-mean_chborn)

  # Compare prop_zero to expected under Negative Binomial
  standard_nb &lt;- glm.nb(chborn_num ~ 1, data = subset_data)
  theta_nb &lt;- standard_nb$theta
  exp_zero_nb &lt;- (theta_nb / (theta_nb + mean_chborn))^theta_nb
  
  zero_inflation[i] &lt;- prop_zero &gt; exp_poisson | prop_zero &gt; exp_zero_nb
  
  # Store the results in the EDA_df
  EDA_df &lt;- rbind(
    EDA_df,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      Age_Range = unique(subset_data$AGE_RANGE),
      Overdispersion = overdispersion[i], 
      Zero_Inflation = zero_inflation[i],
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<pre class="r"><code>EDA_df$model &lt;- NA  # Create an empty column for the model

for(i in 1:nrow(EDA_df)) {
  if(EDA_df$Overdispersion[i] &amp; EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Zero-Inflated Negative Binomial&quot;
  } else if(EDA_df$Overdispersion[i] &amp; !EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Negative Binomial&quot;
  } else if(!EDA_df$Overdispersion[i] &amp; !EDA_df$Zero_Inflation[i]) {
    EDA_df$model[i] &lt;- &quot;Poisson&quot;
  } else if(!EDA_df$Overdispersion[i] &amp; EDA_df$Zero_Inflation[i]){
    EDA_df$model[i] &lt;- &quot;Zero-Inflated Poisson&quot;  
  }
}

# View the final EDA_df
print(EDA_df)</code></pre>
<pre class="r"><code>## Approach 2
# Initialize the data frame to store results
best_models &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  Age_Range = character(),
  AIC_poisson = numeric(),
  AIC_nb = numeric(),
  AIC_zip = numeric(),
  AIC_zinb = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each subset of data
for (i in seq_along(combinations)) {
  subset_data &lt;- combinations[[i]]
  
  # Fit Poisson model
  poisson_model &lt;- glm(chborn_num ~ 1, family = poisson, data = subset_data)
  # Fit Negative Binomial model
  nb_model &lt;- glm.nb(chborn_num ~ 1, data = subset_data)

  # Fit Zero-Inflated Poisson model
  zip_model &lt;- zeroinfl(chborn_num ~ 1 | 1, data = subset_data, dist = &quot;poisson&quot;)

  # Fit Zero-Inflated Negative Binomial model
  zinb_model &lt;- zeroinfl(chborn_num ~ 1 | 1, data = subset_data, dist = &quot;negbin&quot;)
  
  # Append the result to the best_models data frame
  best_models &lt;- rbind(
    best_models,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      Age_Range = unique(subset_data$AGE_RANGE),
      AIC_poisson = AIC(poisson_model),
      AIC_nb = AIC(nb_model),
      AIC_zip = AIC(zip_model),
      AIC_zinb = AIC(zinb_model),
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<pre class="r"><code># Add a Best_Model column to store the best model based on minimum AIC
best_models$Best_Model &lt;- apply(best_models, 1, function(row) {
  # Get AIC values for Poisson, NB, ZIP, and ZINB models
  aic_values &lt;- c(Poisson = as.numeric(row[&#39;AIC_poisson&#39;]),
                  Negative_Binomial = as.numeric(row[&#39;AIC_nb&#39;]),
                  Zero_Inflated_Poisson = as.numeric(row[&#39;AIC_zip&#39;]),
                  Zero_Inflated_NB= as.numeric(row[&#39;AIC_zinb&#39;]))
  
  # Find the name of the model with the minimum AIC value
  best_model &lt;- names(which.min(aic_values))
  
  return(best_model)
})

best_models &lt;- best_models %&gt;% dplyr::select(Race, Census_Year, Age_Range, Best_Model)
# View the updated table with the Best_Model column
print(best_models)</code></pre>
</div>
<div id="step-3-record-the-best-model-for-each-subset"
class="section level3">
<h3>Step 3: Record the Best Model for Each Subset</h3>
<p>Create a table or data frame where you store the best model for each
combination of race, census year, and age range based on AIC/BIC. For
example:</p>
<table>
<thead>
<tr class="header">
<th>Race</th>
<th>Census Year</th>
<th>Age Range</th>
<th>Best Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1990</td>
<td>40-49</td>
<td>Negative Binomial</td>
</tr>
<tr class="even">
<td>White</td>
<td>1990</td>
<td>40-49</td>
<td>Zero-Inflated NB</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1980</td>
<td>50-59</td>
<td>Poisson</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>(but obviously do this as a dataframe so we can analyze it)</p>
</div>
<div id="step-4-analyze-the-effect-of-race-census-year-and-age-range"
class="section level3">
<h3>Step 4: Analyze the Effect of Race, Census Year, and Age Range</h3>
<p>Once you’ve gathered the best model for each subset, you can analyze
which factor (race, census year, or age range) is most influential in
determining the best-fitting model.</p>
<p><strong>Options for statistical analysis:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Chi-Square Test of Independence</strong>: You can use a
chi-square test to determine whether there is a significant association
between race and the best-fitting model, or census year/age group and
the best-fitting model. This test will help you see if certain races or
age ranges are more likely to have a particular model as the best
fit.</li>
</ol>
<pre class="r"><code>#example
# Need large sample size, warning message &quot;Chi-squared approximation may be incorrect,&quot; usually occurs when some of the expected counts in the contingency table are too small (typically less than 5)
## Create a contingency table
#table_model_race &lt;- table(best_models$Race, best_models$Best_Model)

# Perform chi-square test
#chisq.test(table_model_race)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Logistic Regression</strong>: You could fit a logistic
regression model where the response variable is the best-fitting model
(binary or multinomial) and the predictor variables are race, census
year, and age range. This will allow you to quantify the effect of each
variable on the model choice.</p>
<p><strong>Example in R</strong> (assuming binary outcome: Poisson
vs. NB):</p></li>
</ol>
<pre class="r"><code># Recode Best_Model to a binary variable (e.g., &quot;Zero_Inflated_NB&quot; vs. &quot;Other&quot;)
best_models$Best_Model_Binary &lt;- ifelse(best_models$Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)

# Fit binary logistic regression
model_logistic &lt;- glm(Best_Model_Binary ~ Race + Census_Year + Age_Range, family = binomial(), data = best_models)

# Summary of the logistic regression model
summary(model_logistic)</code></pre>
<p><strong><em>RESULT:</em></strong>The p-value for each variable is
smaller than 0.05, indicating non-significant effects on best_model
fitting.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Multinomial Logistic Regression</strong> (if more than
two models): If you have multiple possible best-fitting models (Poisson,
NB, ZIP, ZINB), you can use multinomial logistic regression to assess
the impact of race, census year, and age range on model selection.</p>
<p><strong>Example in R using the <code>nnet</code>
package</strong>:</p></li>
</ol>
<pre class="r"><code>## Not appropriate since only 2 levels in best_model
# Fit multinomial logistic regression
#model_multinom &lt;- multinom(Best_Model ~ Race + Census_Year + Age_Range, data = best_model_data)

# Summary of results
#summary(model_multinom)</code></pre>
</div>
<div id="step-5-summarize-the-results" class="section level3">
<h3>Step 5: Summarize the Results</h3>
<ul>
<li><strong>Significance of Each Variable</strong>: From the regression
analysis (or chi-square tests), you can determine which variable (race,
census year, or age range) has the most significant impact on the model
choice.</li>
<li><strong>Effect Sizes</strong>: Logistic regression will provide
coefficients that describe how much each variable influences the
probability of choosing a particular model.</li>
<li><strong>Best Model by Race</strong>: You can summarize which model
tends to fit best for each race across years and age groups. For
example, you might find that the <strong>Negative Binomial</strong>
model consistently fits the best for a specific race or age group,
indicating more overdispersion in that subset.</li>
</ul>
</div>
<div id="visualize-the-results" class="section level3">
<h3>Visualize the Results</h3>
<p>Finally, visualize the distribution of the best-fitting models across
races, census years, and age groups.</p>
<ul>
<li><strong>Bar Plots</strong>: Show the proportion of each model for
different races or age groups.</li>
<li><strong>Heatmap</strong>: Use a heatmap to visualize how the best
model varies across race, census year, and age range.</li>
</ul>
<p><strong>Example of a simple bar plot in R</strong>:</p>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models, aes(x = Race, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models by Race&quot;, x = &quot;Race&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models, aes(x = Census_Year, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models by Census Year&quot;, x = &quot;Census Year&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models, aes(x = Age_Range, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models by Age Range&quot;, x = &quot;Age Range&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code>ggplot(best_models, aes(x = Census_Year, y = Age_Range, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + # Create the tiles
  facet_wrap(~Race, nrow = 2) + # Facet by Race
  scale_fill_manual(values = c(&quot;Zero_Inflated_Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;)) + 
  labs(
    title = &quot;Best Model by Race, Census Year, and Age Range&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Age Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion:</h3>
<ul>
<li><strong>Best Model Analysis</strong>: The best-fitting model can be
assessed across different races, census years, and age ranges by
comparing models using AIC/BIC.</li>
<li><strong>Significance Testing</strong>: Use chi-square or logistic
regression to assess which variable most influences the model
selection.</li>
<li><strong>Summarizing Across Years</strong>: After analyzing the data,
you’ll be able to conclude which model fits each race best across
different years, and whether race, census year, or age group is the
dominant factor.</li>
</ul>
<p><strong><em>CONCLUSION:</em></strong> Both the logistics regression
and the result visualization shows that there isn’t a significant
association between the predictor and the best-fitting model, ie. no
certain races, age ranges, or census year are more likely to have a
particular model as the best fit.</p>
</div>
</div>
<div id="instructions-for-manqing-cohort-stability-analysis"
class="section level2">
<h2>[Instructions for Manqing] Cohort Stability Analysis</h2>
<p>For Question 2: <strong>Cohort Stability Analysis</strong>, the goal
is to determine if there is a significant change in <strong>zero
inflation</strong>, <strong>family size</strong>, or <strong>model
fit</strong> for the same cohort across different census years, given
race.</p>
<div id="step-1-add-a-birth-year-cohort-variable"
class="section level3">
<h3>Step 1: Add a Birth-Year “Cohort” Variable</h3>
<p>Using the existing table of model summaries, calculate the
<strong>birth-year cohort</strong> based on the <strong>Census
Year</strong> and <strong>Age Range</strong>. For example, if a woman is
in the 40-49 age range in the 1990 Census, her birth cohort would be
<strong>1941-1950</strong>.</p>
<ul>
<li><strong>Formula to Calculate Cohort:</strong> For each row in the
table, subtract the age range from the census year to get the cohort.
For example:
<ul>
<li>Census Year: 1990</li>
<li>Age Range: 40-49</li>
<li>Cohort: 1990 - (40 to 49) → <strong>Cohort: 1941-1950</strong></li>
</ul></li>
<li>Add a new column to the summary table called
<code>Cohort</code>.</li>
</ul>
<p><strong>Example Table:</strong></p>
<table>
<colgroup>
<col width="24%" />
<col width="16%" />
<col width="14%" />
<col width="24%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th>Race</th>
<th>Census Year</th>
<th>Age Range</th>
<th>Best Model</th>
<th>Cohort</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1990</td>
<td>40-49</td>
<td>Negative Binomial</td>
<td>1941-1950</td>
</tr>
<tr class="even">
<td>White</td>
<td>1990</td>
<td>40-49</td>
<td>Zero-Inflated NB</td>
<td>1941-1950</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1980</td>
<td>50-59</td>
<td>Poisson</td>
<td>1921-1930</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<pre class="r"><code>calculate_cohort &lt;- function(census_year, age_range) {
  # Extract the lower and upper age limits from the Age_Range
  age_limits &lt;- as.numeric(unlist(strsplit(age_range, &quot;-|\\+&quot;)))
  
  # If the age range is &quot;70+&quot;, treat the upper bound as 70+ (i.e., infinity)
  if (length(age_limits) == 1) {
    lower_age &lt;- age_limits
    upper_age &lt;- Inf  # For ages 70+, we assume no upper bound
  } else {
    lower_age &lt;- age_limits[1]
    upper_age &lt;- age_limits[2]
  }
  
  # Calculate birth cohort bounds
  lower_cohort &lt;- census_year - upper_age
  upper_cohort &lt;- census_year - lower_age
  
  # If it&#39;s the 70+ age range, we&#39;ll assume the lower bound goes back to a reasonable limit
  if (upper_age == Inf) {
    upper_cohort &lt;- census_year - 70
  }
  
  # Return the birth cohort as a string (e.g., &quot;1941-1950&quot;)
  return(paste(lower_cohort, upper_cohort, sep = &quot;-&quot;))
}

# Apply this function to your best_models table to create a new &#39;Cohort&#39; column
best_models &lt;- best_models %&gt;%
  mutate(Cohort = mapply(calculate_cohort, Census_Year, Age_Range)) %&gt;% 
  dplyr::select(Race, Census_Year, Age_Range, Best_Model, Cohort)

# View the updated table
print(best_models)</code></pre>
</div>
<div id="step-2-compute-summary-statistics-for-each-subset"
class="section level3">
<h3>Step 2: Compute Summary Statistics for Each Subset</h3>
<p>For each combination of <strong>Race</strong>,
<strong>Cohort</strong>, and <strong>Census Year</strong>, compute
additional summary statistics for family size distributions: -
<strong>Mean</strong>, <strong>Variance</strong>, <strong>Mode</strong>
of the number of children. - <strong>Probability</strong> of having 0,
1, 2, …, 12+ children (empirical or from the best-fitting model).</p>
<p>These statistics will help quantify family size changes over
time.</p>
<p><strong>Example Summary Table:</strong></p>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="11%" />
<col width="9%" />
<col width="14%" />
<col width="5%" />
<col width="7%" />
<col width="4%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="3%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Race</th>
<th>Cohort</th>
<th>Census Year</th>
<th>Best Model</th>
<th>Mean</th>
<th>Variance</th>
<th>Mode</th>
<th>Prob(0)</th>
<th>Prob(1)</th>
<th>Prob(2)</th>
<th>…</th>
<th>Prob(12+)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Black/African Am.</td>
<td>1941-1950</td>
<td>1990</td>
<td>Negative Binomial</td>
<td>2.5</td>
<td>1.2</td>
<td>2</td>
<td>0.20</td>
<td>0.30</td>
<td>0.25</td>
<td>…</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>White</td>
<td>1941-1950</td>
<td>1990</td>
<td>Zero-Inflated NB</td>
<td>2.1</td>
<td>1.0</td>
<td>2</td>
<td>0.35</td>
<td>0.28</td>
<td>0.20</td>
<td>…</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>White</td>
<td>1921-1930</td>
<td>1980</td>
<td>Poisson</td>
<td>3.0</td>
<td>1.5</td>
<td>3</td>
<td>0.15</td>
<td>0.25</td>
<td>0.30</td>
<td>…</td>
<td>0.05</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<pre class="r"><code>df_merg &lt;- df %&gt;%
  rename(Census_Year = YEAR, Race = RACE, Age_Range = AGE_RANGE)

# Perform a left join to merge the data frames
merged_data &lt;- left_join(df_merg, best_models, by = c(&quot;Race&quot;, &quot;Census_Year&quot;, &quot;Age_Range&quot;))</code></pre>
<pre class="r"><code>calculate_mode &lt;- function(x) {
  ux &lt;- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_table &lt;- merged_data %&gt;% group_by(Race, Cohort, Census_Year) %&gt;%
  summarise(
    Mean = mean(chborn_num),
    Variance = var(chborn_num),
    Mode = calculate_mode(chborn_num),
    Prob_0 = mean(chborn_num == 0),
    Prob_1 = mean(chborn_num == 1),
    Prob_2 = mean(chborn_num == 2),
    Prob_3 = mean(chborn_num == 3),
    Prob_4 = mean(chborn_num == 4),
    Prob_5 = mean(chborn_num == 5),
    Prob_6 = mean(chborn_num == 6),
    Prob_7 = mean(chborn_num == 7),
    Prob_8 = mean(chborn_num == 8),
    Prob_9 = mean(chborn_num == 9),
    Prob_10 = mean(chborn_num == 10),
    Prob_11 = mean(chborn_num == 11),
    Prob_12plus = mean(chborn_num &gt;= 12)
    #Total_Prob = Prob_0 + Prob_1 + Prob_2 + Prob_3 + Prob_4 + Prob_5 + Prob_6 + 
                # Prob_7 + Prob_8 + Prob_9 + Prob_10 + Prob_11 + Prob_12plus
  ) %&gt;%
  ungroup() %&gt;% as.data.frame()

# View the summary table
print(summary_table)</code></pre>
<pre class="r"><code>merged_data %&gt;% 
  group_by(Race) %&gt;%
  count()

white_prop &lt;-304522 / 1740755
black_prop &lt;- 38797 /176722</code></pre>
<pre class="r"><code>merged_data %&gt;% filter(Race == &quot;White&quot;) %&gt;% summarise(Mean = mean(chborn_num))</code></pre>
</div>
<div
id="step-3-test-for-significant-changes-over-time-within-each-cohort"
class="section level3">
<h3>Step 3: Test for Significant Changes Over Time Within Each
Cohort</h3>
<p>Once the cohort information and summary statistics are available, the
goal is to determine if there is a <strong>significant change</strong>
in any of the following across census years for the same cohort:</p>
<ol style="list-style-type: decimal">
<li><strong>Zero Inflation</strong>: Check if the proportion of women
with zero children changes significantly over time for the same
cohort.</li>
<li><strong>Family Size</strong>: Test if the mean or variance in the
number of children changes for the same cohort over time.</li>
<li><strong>Model Fit</strong>: Analyze if the best-fitting model for
the cohort changes over time.</li>
</ol>
<div id="a.-zero-inflation-analysis" class="section level4">
<h4>a. <strong>Zero-Inflation Analysis</strong></h4>
<ul>
<li><p>Use a <strong>logistic regression</strong> model to assess if the
probability of having zero children changes significantly over time for
the same cohort.</p>
<p><strong>Example Code</strong>:</p></li>
</ul>
<pre class="r"><code>## divided the corhort by race
merged_df_black &lt;- merged_data %&gt;% filter(Race == &quot;Black/African American&quot;)
merged_df_white &lt;- merged_data %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code># Filter cohorts with more than one census year
cohort_counts &lt;- merged_df_black %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test &lt;- cohort_counts$Cohort

# Initialize results data frame
results_black &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test) {
  cohort_data &lt;- merged_df_black %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$chborn_num == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_black &lt;- rbind(results_black, data.frame(
      RACE = &quot;Black/African American&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
  }
}

results_black &lt;- results_black %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_black)</code></pre>
<pre class="r"><code># Filter cohorts with more than one census year
cohort_counts2 &lt;- merged_df_white %&gt;%
  group_by(Cohort) %&gt;%
  summarise(Unique_Census_Years = n_distinct(Census_Year)) %&gt;%
  filter(Unique_Census_Years &gt; 1)

# Get the list of cohorts for testing
cohorts_for_test2 &lt;- cohort_counts2$Cohort

# Initialize results data frame
results_white &lt;- data.frame(RACE = character(), Cohort = character(), Chi_Square = numeric(), p_value = numeric(), stringsAsFactors = FALSE)

# Loop through each cohort and run the chi-square test
for (cohort in cohorts_for_test2) {
  cohort_data &lt;- merged_df_white %&gt;% filter(Cohort == cohort)
  
  # Create contingency table
  contingency_table &lt;- table(cohort_data$Census_Year, cohort_data$chborn_num == &quot;0&quot;)
  
  # Perform the chi-square test only if more than one row is in the table
  if (nrow(contingency_table) &gt; 1) {
    test_result &lt;- chisq.test(contingency_table)
    
    # Append results to the results data frame
    results_white &lt;- rbind(results_white, data.frame(
      RACE = &quot;White&quot;,
      Cohort = cohort,
      Chi_Square = test_result$statistic,
      p_value = test_result$p.value
    ))
  }
}
results_white &lt;- results_white %&gt;%
  mutate(Significance = ifelse(p_value &gt; 0.05, &quot;No&quot;, &quot;Yes&quot;))

print(results_white)</code></pre>
<pre class="r"><code>cohort_data &lt;- merged_df_white %&gt;% filter(Cohort == &quot;1901-1910&quot;)</code></pre>
<pre class="r"><code># Combine the two data frames
combined_result &lt;- rbind(results_black, results_white)

# Create the plot
ggplot(combined_result, aes(x = Cohort, y = p_value, color = RACE, shape = Significance)) +
  geom_point(size = 2) +
  geom_line(aes(group = RACE)) +
    annotate(&quot;text&quot;, x = Inf, y = 0.05, label = &quot;p = 0.05&quot;, hjust = 1.1, vjust = -0.5, color = &quot;red&quot;, size = 3) +
  geom_hline(yintercept = 0.05, linetype = &quot;dashed&quot;, color = &quot;red&quot;, size = 0.5) + 
  scale_y_log10() +  # Use log scale for better visualization if p-values vary widely
  labs(
    title = &quot;Change of p-values by Cohort&quot;,
    x = &quot;Cohort&quot;,
    y = &quot;p-value (log scale)&quot;,
    color = &quot;Race&quot;,
    shape = &quot;Significance&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><strong><em>RESULT:</em></strong> The graph shows that there is a
discrepancy in the p-value within the cohorts like 1901-1910, 1911-1920
and 1921-1930 by race. However, in cohort 1931-1941, the p-value of each
race is pretty close to each other. The overall trend of the p-value for
black population is stable across cohort, while the trend for white
population fluctuate a lot.</p>
<pre class="r"><code>ggplot(combined_result, aes(x = Cohort, y = Chi_Square, color = RACE)) +
  geom_point(size = 3) +
  geom_line(aes(group = RACE)) +
  labs(
    title = &quot;Change of Test Statistics by Cohort&quot;,
    x = &quot;Cohort&quot;,
    y = &quot;Chi-Square&quot;,
    color = &quot;Race&quot;
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<p><strong><em>CONCLUSION:</em></strong></p>
</div>
<div id="b.-family-size-analysis" class="section level4">
<h4>b. <strong>Family Size Analysis</strong></h4>
<ul>
<li><p>Use an <strong>ANOVA</strong> or <strong>linear
regression</strong> to test if the mean or variance in family size
changes over census years for the same cohort.</p>
<p><strong>Example Code</strong>:</p></li>
</ul>
<pre class="r"><code>  # Fit linear model to check for changes in family size over time
  #family_size_model &lt;- lm(Mean ~ Census_Year, data = summary_table)
  
  # ANOVA to check for significant differences in mean
  #anova(family_size_model)</code></pre>
<pre class="r"><code>merged_data2 &lt;- left_join(merged_data, summary_table, by = c(&quot;Race&quot;,&quot;Cohort&quot;,&quot;Census_Year&quot;)) %&gt;% dplyr::select(Race, Cohort, Census_Year, Mean, Variance)

merged_black = merged_data2 %&gt;% filter(Race == &quot;Black/African American&quot;)
merged_white = merged_data2 %&gt;% filter(Race == &quot;White&quot;)</code></pre>
<pre class="r"><code>cohorts1 &lt;- unique(merged_black$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts1) {
  
  # Filter data for the specific cohort
  cohort_data_b &lt;- merged_black[merged_black$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_b$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_b)
  
  # Perform ANOVA for Variance
  anova_variance_result &lt;- aov(Variance ~ factor(Census_Year), data = cohort_data_b)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean Family Size:\n&quot;)
  print(summary(anova_mean_result))
  cat(&quot;\nANOVA for Variance in Family Size:\n&quot;)
  print(summary(anova_variance_result))
}</code></pre>
<pre class="r"><code>cohorts2 &lt;- unique(merged_white$Cohort)

# Loop through each cohort and apply ANOVA for Mean and Variance
for (cohort in cohorts2) {
  
  # Filter data for the specific cohort
  cohort_data_w &lt;- merged_white[merged_white$Cohort == cohort, ]
  
  # Check if there are at least two unique Census_Year values
  if (length(unique(cohort_data_w$Census_Year)) &lt; 2) {
    cat(&quot;\nCohort:&quot;, cohort, &quot;has only one Census Year. Skipping ANOVA.\n&quot;)
    next
  }
  
  # Perform ANOVA for Mean
  anova_mean_result &lt;- aov(Mean ~ factor(Census_Year), data = cohort_data_w)
  
  # Perform ANOVA for Variance
  anova_variance_result &lt;- aov(Variance ~ factor(Census_Year), data = cohort_data_w)
  
  # Output the results
  cat(&quot;\nCohort:&quot;, cohort)
  cat(&quot;\nANOVA for Mean Family Size:\n&quot;)
  print(summary(anova_mean_result))
  cat(&quot;\nANOVA for Variance in Family Size:\n&quot;)
  print(summary(anova_variance_result))
}</code></pre>
<p><strong><em>RESULT:</em></strong> 1.In both racial group, the ANOVA
is not applicable for the following cohort since there is only one
census year available in the data for those cohorts:-Inf-1910,
1941-1950, -Inf-1920, -Inf-1890, -Inf-1900, and 1891-1900 2.By looking
at the ANOVA for mean and variance family size in both racial group, the
p-value of the rest cohorts (1901-1910, 1911-1920, 1921-1930, 1931-1940)
are smaller than 0.05, indicating mean and variance family size for
these cohort has significantly changed over different census years in
both population.</p>
</div>
<div id="c.-model-fit-analysis" class="section level4">
<h4>c. <strong>Model Fit Analysis</strong></h4>
<ul>
<li>If the best-fitting model changes for the same cohort over time,
this suggests that the distribution of family sizes has shifted. Use
<strong>multinomial logistic regression</strong> to test if the model
fit differs across census years for the same cohort.</li>
</ul>
<p><strong>Example Code</strong>:</p>
<pre class="r"><code># Test for white population
test_df_w &lt;- merged_data %&gt;%
  mutate(Best_Model_Binary = ifelse(Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)) %&gt;%
  select(Race, Cohort, Census_Year, Best_Model, Best_Model_Binary) %&gt;% 
  filter(Race == &quot;White&quot;)

unique_cohorts &lt;- unique(test_df_w$Cohort)

for (cohort in unique_cohorts) {
  cohort_data &lt;- test_df_w %&gt;% filter(Cohort == cohort)
  
  if (n_distinct(cohort_data$Census_Year) &gt; 1) {
    if (n_distinct(cohort_data$Best_Model_Binary) &gt; 1) {
      logistic_model &lt;- glm(Best_Model_Binary ~ as.factor(Census_Year), data = cohort_data, family = binomial)
      
      print(paste(&quot;Cohort:&quot;, cohort))
      print(summary(logistic_model))
    } else {
      print(paste(&quot;Warning for Cohort&quot;, cohort, &quot;: Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;))
    }
  } else {
    print(paste(&quot;Cohort:&quot;, cohort, &quot;- Not enough data variability across census years for logistic regression.&quot;))
  }
}</code></pre>
<pre class="r"><code># Test for black population
test_df_b &lt;- merged_data %&gt;%
  mutate(Best_Model_Binary = ifelse(Best_Model == &quot;Zero_Inflated_NB&quot;, 1, 0)) %&gt;%
  select(Race, Cohort, Census_Year, Best_Model, Best_Model_Binary) %&gt;% 
  filter(Race == &quot;Black/African American&quot;)

unique_cohorts &lt;- unique(test_df_b$Cohort)

for (cohort in unique_cohorts) {
  cohort_data &lt;- test_df_b %&gt;% filter(Cohort == cohort)
  
  if (n_distinct(cohort_data$Census_Year) &gt; 1) {
    if (n_distinct(cohort_data$Best_Model_Binary) &gt; 1) {
      logistic_model &lt;- glm(Best_Model_Binary ~ as.factor(Census_Year), data = cohort_data, family = binomial)
      
      print(paste(&quot;Cohort:&quot;, cohort))
      print(summary(logistic_model))
    } else {
      print(paste(&quot;Warning for Cohort&quot;, cohort, &quot;: Best_Model_Binary contains only a single category. Model convergence issues likely due to lack of variability.&quot;))
    }
  } else {
    print(paste(&quot;Cohort:&quot;, cohort, &quot;- Not enough data variability across census years for logistic regression.&quot;))
  }
}</code></pre>
<p><strong><em>RESULT:</em></strong> The p-value of all the
“Census_Year” is greater than 0.05, suggesting no statistically
significant effect on choice between best models.</p>
</div>
</div>
<div id="step-4-interpret-the-results" class="section level3">
<h3>Step 4: Interpret the Results</h3>
<p>For each cohort, you will assess whether: -
<strong>Zero-inflation</strong> changes significantly over time (i.e.,
whether the probability of having no children decreases or increases
across census years). - <strong>Family size</strong> (mean, variance,
mode) changes significantly over time. - The <strong>best-fitting
model</strong> changes over time, indicating a shift in family size
distributions.</p>
<p>If significant changes are detected for a cohort (e.g., the same
cohort switches from a zero-inflated model to a non-zero-inflated model,
or family sizes decrease), this indicates a shift in the demographic
pattern for that group.</p>
</div>
<div id="conclusion-1" class="section level3">
<h3>Conclusion</h3>
<p>This analysis will allow you to evaluate <strong>cohort
stability</strong> by testing whether demographic patterns (e.g.,
zero-inflation, family size) are consistent over time for the same
cohort or if there are notable shifts. If the patterns change
significantly, you will be able to identify when and how the demographic
trends for each cohort begin to deviate from their earlier
distribution.</p>
</div>
</div>
<div
id="instructions-for-manqing-question-3-analyzing-and-visualizing-significant-fertility-shifts"
class="section level2">
<h2>[Instructions for Manqing] Question 3: Analyzing and Visualizing
Significant Fertility Shifts</h2>
<p>For Question 3: <strong>Significant Fertility shifts</strong>, the
goal is to summarize the information in the top 2 questions and create a
comprehensive analysis and visualization that illustrates significant
fertility shifts in cohorts, compares fertility patterns of 40-49
year-olds to 50-59 year-olds in the 1990 census so we can pick the set
of fertility distributions we want to use to visualize the sibling
distribution and do the math on the genetic surveillance.</p>
<div id="objective" class="section level3">
<h3>Objective</h3>
<p>Create a comprehensive analysis and visualization that:</p>
<ol style="list-style-type: decimal">
<li><strong>Illustrates significant fertility shifts in cohorts</strong>
based on the stability analysis from Question 2.</li>
<li><strong>Compares fertility patterns of 40-49 year-olds to 50-59
year-olds in the 1990 census</strong>, highlighting any significant
differences.</li>
<li><strong>Synthesizes the findings</strong> to discuss overall trends
and their implications.</li>
</ol>
<p>The steps below are suggestions: use critical thinking and your
judgement to complete this task and answer the question</p>
</div>
<div id="step-1-prepare-the-data" class="section level3">
<h3>Step 1: Prepare the Data</h3>
<div id="use-results-from-stability-analysis-question-2"
class="section level4">
<h4>1.1 Use Results from Stability Analysis (Question 2)</h4>
<ul>
<li><strong>Identify Cohorts with Significant Shifts</strong>:
<ul>
<li>Review the results from your stability analysis in Question 2.</li>
<li>List the cohorts where significant shifts in fertility distributions
were observed for 40-49 year-olds.</li>
<li>Note the nature of these shifts for each cohort, such as changes in
mean number of children, variance, or zero inflation (proportion of
women with zero children).</li>
</ul></li>
</ul>
<p>-change in prob_0 children(black):1901-1910, 1921-1930 -change in
prob_0 children(white): 1901-1910, 1911-1920, 1921-1930 -change in mean
&amp; variance: 1901-1910, 1911-1920, 1921-1930, 1931-1940 -change in
best model fit: none</p>
</div>
<div id="extract-data-for-age-groups-in-1990-census"
class="section level4">
<h4>1.2 Extract Data for Age Groups in 1990 Census</h4>
<ul>
<li><strong>Filter Data for 1990 Census</strong>:
<ul>
<li>Use your existing dataset to extract data specifically from the 1990
census year.</li>
</ul></li>
<li><strong>Select Age Groups</strong>:
<ul>
<li>Focus on women in the age ranges of <strong>40-49</strong> and
<strong>50-59</strong>.</li>
<li>Ensure the data includes necessary variables:
<ul>
<li>Number of children (<code>chborn_num</code>)</li>
<li>Age range (<code>AGE_RANGE</code>)</li>
<li>Race (<code>RACE</code>)</li>
<li>Any other relevant variables used in previous analyses</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="step-2-create-visualizations" class="section level3">
<h3>Step 2: Create Visualizations</h3>
<p>Design visualizations that effectively communicate your findings.</p>
<div id="panel-a-fertility-distribution-shifts-across-cohorts"
class="section level4">
<h4>2.1 Panel A: Fertility Distribution Shifts Across Cohorts</h4>
<ul>
<li><strong>Use Existing Fertility Distribution Plots</strong>:
<ul>
<li>Leverage the fertility distribution plots you created in Question
1.</li>
</ul></li>
<li><strong>Highlight Significant Cohorts</strong>:
<ul>
<li>Emphasize the cohorts identified in Step 1.1 where significant
shifts occurred.
<ul>
<li>This could be done by using distinct colors, markers, or
annotations.</li>
</ul></li>
</ul></li>
<li><strong>Annotate the Plots</strong>:
<ul>
<li>Include text or labels that describe the nature of the significant
shifts for each highlighted cohort.
<ul>
<li>For example, indicate if there was a decrease in mean number of
children or an increase in childlessness.</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>part1&lt;- child_plot +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1960 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1960 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 0.45, ymin = -0.3, ymax = 0.3), 
            fill = &quot;blue&quot;, alpha = 0.03)</code></pre>
<pre class="r"><code>part2&lt;- part1 +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1970 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 0.45, ymin = -0.3, ymax = 0), 
            fill = &quot;blue&quot;, alpha = 0.03) + 
  labs(title = &quot;Fertility Distribution Shifts&quot;,
       subtitle = &quot;Highlighted significant shifts in Number of zero Children&quot;,
       caption = &quot;Annotations indicate key shifts in number of zero children across census years. White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;) +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5), 
    plot.caption = element_text(size = 9, hjust = 0.5),  
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10)
  )
part2</code></pre>
<pre class="r"><code>child_plot +
  geom_rect(data = df_mirror %&gt;% filter((YEAR == 1960 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1960 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1970 &amp; AGE_RANGE == &quot;60-69&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;40-49&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1980 &amp; AGE_RANGE == &quot;60-69&quot;)|
                                        (YEAR == 1990 &amp; AGE_RANGE == &quot;50-59&quot;)|
                                        (YEAR == 1990 &amp; AGE_RANGE == &quot;60-69&quot;)),
            aes(xmin = -0.45, xmax = 13, ymin = -0.3, ymax = 0.3), 
            fill = &quot;blue&quot;, alpha = 0.01) + 
  labs(title = &quot;Fertility Distribution Shifts&quot;,
       subtitle = &quot;Highlighted significant shifts in Mean Family Size&quot;,
       caption = &quot;Annotations indicate key shifts in Mean Family Size across census years. White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;12+&#39; includes families with 12 or more children.&quot;) +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5), 
    plot.caption = element_text(size = 9, hjust = 0.5),  
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 10)
  )</code></pre>
</div>
<div id="panel-b-comparison-of-40-49-and-50-59-age-groups-in-1990"
class="section level4">
<h4>2.2 Panel B: Comparison of 40-49 and 50-59 Age Groups in 1990</h4>
<ul>
<li><strong>Create Comparative Distribution Plots</strong>:
<ul>
<li>Generate side-by-side or overlaid histograms or density plots for
the 40-49 and 50-59 age groups within each racial group.</li>
</ul></li>
<li><strong>Include Summary Statistics</strong>:
<ul>
<li>On each plot or in accompanying tables, provide:
<ul>
<li>Mean number of children</li>
<li>Variance</li>
<li>Proportion of women with zero children (zero inflation)</li>
</ul></li>
</ul></li>
<li><strong>Ensure Clarity in Visuals</strong>:
<ul>
<li>Properly label axes, legends, and titles.</li>
<li>Use consistent color schemes for easy comparison between
groups.</li>
</ul></li>
</ul>
<pre class="r"><code>filter_df &lt;- df_proportions %&gt;% 
  filter(YEAR == &quot;1990&quot;, AGE_RANGE %in% c(&quot;40-49&quot;, &quot;50-59&quot;)) </code></pre>
<pre class="r"><code>ggplot(filter_df, aes(x = chborn_num, y = proportion, fill = AGE_RANGE)) +
  geom_col(position = &quot;identity&quot;, alpha = 0.5) +  
  facet_wrap(~ RACE) +  
  labs(
    title = &quot;Distribution of Number of Children for Women in 40-49 and 50-59 Age Groups in 1990&quot;,
    x = &quot;Number of Children&quot;,
    y = &quot;Proportion&quot;,
    fill = &quot;Age Range&quot;
  ) </code></pre>
<pre class="r"><code>summary_stats &lt;- filter_df %&gt;%
  group_by(AGE_RANGE, RACE) %&gt;%
  summarise(
    mean_children = weighted.mean(chborn_num, count),  # Mean number of children
    variance_children = sum(count * (chborn_num - weighted.mean(chborn_num, count))^2) / sum(count),  # Variance
    zero_inflation = sum(count[chborn_num == 0]) / sum(count)  # Proportion of women with 0 children
  )

# Print summary statistics table
summary_stats</code></pre>
</div>
</div>
<div id="step-3-perform-statistical-comparisons" class="section level3">
<h3>Step 3: Perform Statistical Comparisons</h3>
<p>Conduct statistical tests to determine if observed differences are
significant.</p>
<div id="t-test-for-difference-in-means" class="section level4">
<h4>3.1 T-Test for Difference in Means</h4>
<ul>
<li><strong>Compare Means Between Age Groups</strong>:
<ul>
<li>For each racial group, perform a t-test to compare the mean number
of children between the 40-49 and 50-59 age groups.</li>
</ul></li>
<li><strong>Check Assumptions</strong>:
<ul>
<li>Ensure that the data meets the assumptions of the t-test (normality,
equal variances).</li>
<li>If assumptions are violated, consider using a non-parametric test
like the Mann-Whitney U test.</li>
</ul></li>
</ul>
<pre class="r"><code>## Check the normality assumption for black population
# Subset data for the 40-49 and 50-59 age groups
data_40_49_b &lt;- df %&gt;% filter(AGE_RANGE == &quot;40-49&quot;, RACE == &quot;Black/African American&quot;)
data_50_59_b &lt;- df %&gt;% filter(AGE_RANGE == &quot;50-59&quot;, RACE == &quot;Black/African American&quot;)

qqnorm(data_40_49_b$chborn_num, main = &quot;QQ Plot: 40-49 Age Group (Black/African American)&quot;)
qqline(data_40_49_b$chborn_num)

# QQ plot for the 50-59 age group
qqnorm(data_50_59_b$chborn_num, main = &quot;QQ Plot: 50-59 Age Group (Black/African American)&quot;)
qqline(data_50_59_b$chborn_num)</code></pre>
<pre class="r"><code>## Check equal variance for black population
df_b &lt;- df %&gt;% filter(RACE == &quot;Black/African American&quot;)

# Levene&#39;s test for equal variances
levene_test_result &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_b)

levene_test_result</code></pre>
<pre class="r"><code>## Check the normality assumption for white population
data_40_49_w &lt;- df %&gt;% filter(AGE_RANGE == &quot;40-49&quot;, RACE == &quot;White&quot;)
data_50_59_w &lt;- df %&gt;% filter(AGE_RANGE == &quot;50-59&quot;, RACE == &quot;White&quot;)

qqnorm(data_40_49_w$chborn_num, main = &quot;QQ Plot: 40-49 Age Group (White)&quot;)
qqline(data_40_49_w$chborn_num)

# QQ plot for the 50-59 age group
qqnorm(data_50_59_w$chborn_num, main = &quot;QQ Plot: 50-59 Age Group (White)&quot;)
qqline(data_50_59_w$chborn_num)</code></pre>
<pre class="r"><code>## Check equal variance for white population
df_w &lt;- df %&gt;% filter(RACE == &quot;White&quot;)

# Levene&#39;s test for equal variances
levene_test_result2 &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_w)

levene_test_result2</code></pre>
<p>Since the data violate both assumption, we perform a Mann-Whitney U
test in the follwoing:</p>
<pre class="r"><code>wilcox_test_result &lt;- wilcox.test(data_40_49_b$chborn_num, data_50_59_b$chborn_num)$p.value
wilcox_test_result2 &lt;- wilcox.test(data_40_49_w$chborn_num, data_50_59_w$chborn_num)$p.value
print(c(wilcox_test_result, wilcox_test_result2))</code></pre>
<p><strong><em>RESULT:</em></strong> These p-values are both extremely
small (close to zero), meaning there is a very strong statistical
difference between the two age groups (40-49 and 50-59) in terms of the
number of children within each racial group.</p>
</div>
<div id="f-test-for-difference-in-variances" class="section level4">
<h4>3.2 F-Test for Difference in Variances</h4>
<ul>
<li><strong>Assess Variance Differences</strong>:
<ul>
<li>Perform an F-test or Levene’s test to compare the variances of the
number of children between the two age groups within each racial
group.</li>
</ul></li>
</ul>
<pre class="r"><code>## Apply Levene&#39;s test since non-normality

# Levene&#39;s test for Black group
levene_test_b &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_b)

# Levene&#39;s test for White group
levene_test_w &lt;- leveneTest(chborn_num ~ as.factor(AGE_RANGE), data = df_w)

# Print results
print(levene_test_b)
print(levene_test_w)</code></pre>
<p><strong><em>RESULT:</em></strong> Since the p values are smaller than
0.05 for both racial group, we have enough evidence to reject the null
hypothesis, indicating that the variances of the number of children
between the two age groups within each racial group are significantly
different.</p>
</div>
<div id="chi-square-test-for-difference-in-zero-inflation"
class="section level4">
<h4>3.3 Chi-Square Test for Difference in Zero Inflation</h4>
<ul>
<li><strong>Analyze Zero Inflation</strong>:
<ul>
<li>Create contingency tables showing the counts of women with zero
children and those with one or more children for each age group.</li>
<li>Perform a chi-square test to determine if the proportion of
childlessness differs significantly between the age groups within each
racial group.</li>
</ul></li>
</ul>
<pre class="r"><code>ZI_table &lt;- df %&gt;% 
  mutate(childlessness = ifelse(chborn_num == 0, &quot;0 Children&quot;, &quot;1+ Children&quot;)) %&gt;%       group_by(RACE, AGE_RANGE, childlessness) %&gt;%
  summarise(count = n())

ZI_table</code></pre>
<pre class="r"><code>ZI_table_b &lt;- ZI_table %&gt;%
  filter(RACE == &quot;Black/African American&quot;)

cont_table_b &lt;- xtabs(count ~ AGE_RANGE + childlessness, data = ZI_table_b)
chi_test_b &lt;- chisq.test(cont_table_b)
chi_test_b</code></pre>
<pre class="r"><code>ZI_table_w &lt;- ZI_table %&gt;%
  filter(RACE == &quot;White&quot;)

cont_table_w &lt;- xtabs(count ~ AGE_RANGE + childlessness, data = ZI_table_w)
chi_test_w &lt;- chisq.test(cont_table_w)
chi_test_w</code></pre>
<p><strong><em>RESULT:</em></strong> The p-values for both tests are
extremely low, suggests that there is a significant difference in the
proportion of women with 0 children versus those with 1+ children across
different age ranges for both the Black/African American and White
racial groups. The results imply that childlessness is not uniformly
distributed across age groups(40-49 and 50-59) in 1990.</p>
</div>
</div>
<div id="step-4-summarize-findings" class="section level3">
<h3>Step 4: Summarize Findings</h3>
<p>Write a clear and concise summary addressing the following
points.</p>
<div id="significant-fertility-shifts-across-cohorts"
class="section level4">
<h4>4.1 Significant Fertility Shifts Across Cohorts</h4>
<ul>
<li><strong>Identify Timing of Shifts</strong>:
<ul>
<li>Specify when significant fertility shifts occurred for each racial
group based on your analysis in Question 2.</li>
</ul></li>
<li><strong>Describe Nature of Shifts</strong>:
<ul>
<li>Detail the characteristics of the shifts, such as:
<ul>
<li>Decrease in mean number of children</li>
<li>Increase in childlessness (zero inflation)</li>
<li>Changes in variance or distribution shape</li>
</ul></li>
</ul></li>
<li><strong>Highlight Differences Between Racial Groups</strong>:
<ul>
<li>Compare the timing and nature of shifts between African American and
European American women.</li>
<li>Discuss any patterns or discrepancies observed.</li>
</ul></li>
</ul>
</div>
<div id="comparison-of-40-49-and-50-59-age-groups-in-1990"
class="section level4">
<h4>4.2 Comparison of 40-49 and 50-59 Age Groups in 1990</h4>
<ul>
<li><strong>Summarize Key Differences</strong>:
<ul>
<li>Present the differences in fertility patterns between the two age
groups for each racial group.</li>
<li>Include comparisons of:
<ul>
<li>Distribution shapes</li>
<li>Mean number of children</li>
<li>Variance</li>
<li>Zero inflation</li>
</ul></li>
</ul></li>
<li><strong>Report Statistical Test Results</strong>:
<ul>
<li>Provide the results of the t-tests, F-tests, and chi-square
tests.</li>
<li>Interpret the significance of these results in the context of your
analysis.</li>
</ul></li>
<li><strong>Discuss Implications</strong>:
<ul>
<li>Consider what these differences suggest about fertility trends and
behaviors.</li>
<li>Reflect on whether the older age group represents completed
fertility patterns.</li>
</ul></li>
</ul>
</div>
<div id="synthesis-and-implications" class="section level4">
<h4>4.3 Synthesis and Implications</h4>
<ul>
<li><strong>Integrate Findings</strong>:
<ul>
<li>Connect the insights from the cohort analysis with the age group
comparison.</li>
<li>Discuss how the patterns observed in the 1990 census relate to the
shifts identified across cohorts.</li>
</ul></li>
<li><strong>Consider Contributing Factors</strong>:
<ul>
<li>Explore potential social, economic, or policy factors that may have
contributed to the observed fertility shifts.
<ul>
<li>For example, changes in access to education, employment
opportunities, or family planning resources.</li>
</ul></li>
</ul></li>
<li><strong>Reflect on Broader Implications</strong>:
<ul>
<li>Discuss how these fertility trends might impact your broader
research topic, such as genetic surveillance disparities.</li>
<li>Consider the implications for future demographic research or policy
development.</li>
</ul></li>
</ul>
</div>
</div>
<div id="additional-considerations" class="section level3">
<h3>Additional Considerations</h3>
<ul>
<li><strong>Visual Clarity</strong>:
<ul>
<li>Ensure all visualizations are easy to interpret.</li>
<li>Use clear labels, legends, and annotations.</li>
</ul></li>
<li><strong>Contextualize Statistical Significance</strong>:
<ul>
<li>Explain not just whether results are statistically significant, but
also what they mean in practical terms.</li>
</ul></li>
<li><strong>Acknowledge Data Limitations</strong>:
<ul>
<li>Discuss any limitations or biases in the data that could affect your
findings.
<ul>
<li>For instance, sample size constraints or missing data.</li>
</ul></li>
</ul></li>
<li><strong>Ethical Considerations</strong>:
<ul>
<li>Approach discussions of race and fertility sensitively and
responsibly.</li>
<li>Avoid drawing causal conclusions without robust evidence.</li>
</ul></li>
</ul>
</div>
<div id="integration-with-previous-work" class="section level3">
<h3>Integration with Previous Work</h3>
<ul>
<li><strong>Leverage Previous Analyses</strong>:
<ul>
<li>Use the visualizations and statistical summaries from Questions 1
and 2 as foundations for this analysis.</li>
</ul></li>
<li><strong>Create a Cohesive Narrative</strong>:
<ul>
<li>Ensure that your findings from all questions are connected and build
upon each other.</li>
<li>Tell a comprehensive story about fertility trends across cohorts and
racial groups.</li>
</ul></li>
</ul>
</div>
<div id="final-deliverables" class="section level3">
<h3>Final Deliverables</h3>
<ul>
<li><strong>Multi-Panel Visualization</strong>:
<ul>
<li>Panel A: Fertility distribution shifts across cohorts with
highlighted significant shifts.</li>
<li>Panel B: Comparative distribution plots for 40-49 and 50-59 age
groups in 1990, including summary statistics.</li>
</ul></li>
<li><strong>Written Summary</strong>:
<ul>
<li>A concise report that addresses the points outlined in Step 4.</li>
<li>Include interpretations of statistical analyses and discuss broader
implications.</li>
</ul></li>
<li><strong>Statistical Analysis Documentation</strong>:
<ul>
<li>Provide details of the statistical tests conducted, including test
assumptions, results, and interpretations.</li>
</ul></li>
<li><strong>Annotated Code (if applicable)</strong>:
<ul>
<li>While not the focus, include any new code used for this analysis
with appropriate comments.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="distribution-of-number-of-siblings-across-census-years"
class="section level1">
<h1>Distribution of Number of Siblings Across Census Years</h1>
<p>Having analyzed the distribution of the number of children, we now
turn our attention to the distribution of the number of siblings. We
will explore the trends in the frequency of the number of siblings for
African American and European American mothers across the Census years
by age group.</p>
<p>Frequency of siblings is calculated as follows.</p>
<p><span class="math display">\[
\text{freq}_{n_{\text{sib}}} = \text{freq}_{\text{mother}} \cdot
\text{chborn}_{\text{num}}
\]</span></p>
<p>For example, suppose 10 mothers (generation 0) have 7 children, then
there will be 70 children (generation 1) in total who each have 6
siblings.</p>
<p>We take our original data and calculate the frequency of siblings for
each mother based on the number of children they have. We then aggregate
this data to get the frequency of siblings for each generation along
with details on the birthyears of the relevant children to visualize the
distribution of the number of siblings across generations.</p>
<div id="instructions-for-manqing-plot-across-census-years-for-children"
class="section level2">
<h2>[Instructions for Manqing] Plot Across Census Years for
Children</h2>
<div id="objective-1" class="section level3">
<h3>Objective</h3>
<p>Create a mirror plot for the distribution of siblings across census
years, races, and birth ranges, similar to the one created for the
number of children.</p>
</div>
<div id="step-1-calculate-sibling-frequencies" class="section level3">
<h3>Step 1: Calculate Sibling Frequencies</h3>
<ol style="list-style-type: decimal">
<li>Start with your dataframe that includes the <code>AGE_RANGE</code>
column.</li>
</ol>
<pre class="r"><code>df2 &lt;- df %&gt;% 
  dplyr::select(RACE, YEAR, AGE_RANGE, chborn_num)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Create a new column for the number of siblings:</li>
</ol>
<pre class="r"><code>df2 &lt;- df2 %&gt;%
 mutate(n_siblings = chborn_num - 1)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Calculate the frequency of siblings:</li>
</ol>
<pre class="r"><code>df2 &lt;- df2 %&gt;%
mutate(sibling_freq = ifelse(chborn_num != 1, n_siblings * 1, 1))  # Assuming each mother represents 1 in frequency</code></pre>
</div>
<div id="step-2-aggregate-sibling-data" class="section level3">
<h3>Step 2: Aggregate Sibling Data</h3>
<ol style="list-style-type: decimal">
<li>Group the data and calculate sibling frequencies:</li>
</ol>
<pre class="r"><code>df_siblings &lt;- df2 %&gt;%
 group_by(YEAR, RACE, AGE_RANGE, n_siblings) %&gt;%
 summarise(
   sibling_count = sum(sibling_freq),
   .groups = &quot;drop&quot;
 )</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate proportions within each group:</li>
</ol>
<pre class="r"><code>df_sibling_proportions &lt;- df_siblings %&gt;%
 group_by(YEAR, RACE, AGE_RANGE) %&gt;%
 mutate(proportion = sibling_count / sum(sibling_count)) %&gt;%
 ungroup()</code></pre>
</div>
<div id="step-3-check-normalization" class="section level3">
<h3>Step 3: Check Normalization</h3>
<p>Before creating the plot, verify that the proportions are correctly
normalized:</p>
<pre class="r"><code>normalization_check &lt;- df_sibling_proportions %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  summarise(total_proportion = sum(proportion), .groups = &quot;drop&quot;) %&gt;%
  arrange(YEAR, RACE, AGE_RANGE)

print(normalization_check)</code></pre>
<p>Ensure that the <code>total_proportion</code> for each group is very
close to 1.0. If not, revisit your calculations in Step 2.</p>
</div>
<div id="step-4-prepare-data-for-mirror-plot" class="section level3">
<h3>Step 4: Prepare Data for Mirror Plot</h3>
<p>Reshape data for the mirror plot:</p>
<pre class="r"><code>df_sibling_mirror &lt;- df_sibling_proportions %&gt;%
  mutate(proportion = if_else(RACE == &quot;White&quot;, -proportion, proportion))</code></pre>
</div>
<div id="step-5-create-the-mirror-plot" class="section level3">
<h3>Step 5: Create the Mirror Plot</h3>
<ol style="list-style-type: decimal">
<li>Create the color palette:</li>
</ol>
<pre class="r"><code>my_colors &lt;- colorRampPalette(c(&quot;#FFB000&quot;, &quot;#F77A2E&quot;, &quot;#DE3A8A&quot;, &quot;#7253FF&quot;, &quot;#5E8BFF&quot;))(13)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Create the plot:</li>
</ol>
<pre class="r"><code>ggplot(data = df_sibling_mirror %&gt;% filter(n_siblings != &quot;-1&quot;), aes(x = n_siblings, y = proportion, fill = as.factor(n_siblings))) +
 geom_col(aes(alpha = RACE)) +
 geom_hline(yintercept = 0, color = &quot;black&quot;, size = 0.5) +
 facet_grid(AGE_RANGE ~ YEAR, scales = &quot;free_y&quot;) +
 coord_flip() +
 scale_y_continuous(
   labels = function(x) abs(x),
   limits = function(x) c(-max(abs(x)), max(abs(x)))
 ) +
 scale_x_continuous(breaks = 0:11, labels = c(0:10, &quot;11+&quot;)) +
 scale_fill_manual(values = my_colors) +
 scale_alpha_manual(values = c(&quot;White&quot; = 0.7, &quot;Black/African American&quot; = 1)) +
 labs(
   title = &quot;Distribution of Number of Siblings by Census Year, Race, and Age Range&quot;,
   x = &quot;Number of Siblings&quot;,
   y = &quot;Proportion&quot;,
   fill = &quot;Number of Siblings&quot;,
   caption = &quot;White population shown on left (negative values), Black/African American on right (positive values)\nProportions normalized within each age range, race, and census year\nFootnote: The category &#39;11+&#39; includes individuals with 11 or more siblings.&quot;
 ) +
 theme_minimal() +
 theme(
   plot.title = element_text(size = 14, hjust = 0.5),
   axis.text.y = element_text(size = 8),
   strip.text = element_text(size = 10),
   legend.position = &quot;none&quot;,
   panel.grid.major.y = element_blank(),
   panel.grid.minor.y = element_blank()
 )</code></pre>
</div>
<div id="step-6-interpret-the-plot" class="section level3">
<h3>Step 6: Interpret the Plot</h3>
<p>After creating the plot, examine it carefully:</p>
<ol style="list-style-type: decimal">
<li>Look for patterns in sibling distribution across different census
years and age ranges. <strong><em>RESULT:</em></strong> -By Census Year:
In 1960 and 1970, individuals are more likely to have higher number of
siblings, especially in the 5-10 range. This trend diminishes over
time.</li>
</ol>
<p>By 1980 and 1990, the distribution shifts toward smaller family
sizes, with a growing proportion of individuals having fewer
siblings.</p>
<p>-By age range: 40-49 Age Group: For this group, the number of
individuals with 0-2 siblings increases across census years, especially
in 1980 and 1990, while the proportion of individuals with larger
sibling counts decreases.</p>
<p>50-59 and 60-69 Age Groups: These groups show a similar shift toward
smaller family sizes, but the trend is slightly more gradual compared to
the younger age group.</p>
<p>70+ Age Group: The shift to fewer siblings is noticeable, although
the trend is less pronounced. The distribution remains relatively stable
across the census years, with a significant portion of individuals still
coming from large families in 1960 and 1970.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Compare the distributions between White and Black/African
American populations. <strong><em>RESULT:</em></strong> -Black/African
American Populations (right side of each pair) consistently show a
higher proportion of individuals with larger sibling counts (5-10
siblings) compared to White populations. However, similar to the White
population, the number of individuals with fewer siblings increases over
time.</p></li>
<li><p>Note any significant changes or trends in the number of siblings
over time. <strong><em>RESULT:</em></strong> -White Populations: (left
side of each pair) have a more marked shift toward smaller families by
1990, with a larger proportion of individuals having 0-2 siblings
compared to the Black/African American population. The decline in larger
family sizes (5+ siblings) is more pronounced among Whites, particularly
by 1980 and 1990.</p></li>
<li><p>Consider how these sibling distributions might differ from the
children distributions you analyzed earlier, and think about potential
reasons for these differences. <strong><em>RESULT:</em></strong> While
both distributions show a trend toward smaller families, the sibling
distribution is more spread out across different sibling counts,
suggesting potential difference in the distribution.</p></li>
</ol>
</div>
</div>
<div id="instructions-for-manqing-model-fit-across-census-years-1"
class="section level2">
<h2>[Instructions for Manqing] Model Fit Across Census Years</h2>
<div id="objective-2" class="section level3">
<h3>Objective</h3>
<p>Repeat the model fitting process we performed for the children
distribution, this time using the sibling distribution data.</p>
</div>
<div id="steps" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Prepare the Sibling Data Use the sibling distribution data you
calculated earlier (<code>df_sibling_proportions</code>).</p></li>
<li><p>Fit Models For each combination of RACE, YEAR, and AGE_RANGE, fit
the following distributions:</p>
<ul>
<li>Poisson</li>
<li>Negative Binomial</li>
<li>Zero-Inflated Poisson</li>
<li>Zero-Inflated Negative Binomial</li>
</ul>
<p>Use the same R functions and packages as in the children distribution
analysis.</p></li>
<li><p>Compare Model Fits Use AIC (Akaike Information Criterion) to
compare the fits of different models for each group.</p></li>
</ol>
<pre class="r"><code>combinations2 &lt;- df2 %&gt;%
  filter(n_siblings != -1) %&gt;%
  group_by(YEAR, RACE, AGE_RANGE) %&gt;%
  group_split()

# Initialize the data frame to store results
best_models_sib &lt;- data.frame(
  Race = character(),
  Census_Year = numeric(),
  AGE_RANGE = character(),
  AIC_poisson = numeric(),
  AIC_nb = numeric(),
  AIC_zip = numeric(),
  AIC_zinb = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each subset of data
for (i in seq_along(combinations2)) {
  subset_data &lt;- combinations2[[i]]
  
  # Fit Poisson model
  poisson_model &lt;- glm(n_siblings ~ 1, family = poisson, data = subset_data)
  # Fit Negative Binomial model
  nb_model &lt;- glm.nb(n_siblings ~ 1, data = subset_data)

  # Fit Zero-Inflated Poisson model
  zip_model &lt;- zeroinfl(n_siblings ~ 1 | 1, data = subset_data, dist = &quot;poisson&quot;,control = zeroinfl.control(maxit = 100))
  
  # Fit Zero-Inflated Negative Binomial model with increased max iterations
  zinb_model &lt;- zeroinfl(n_siblings ~ 1 | 1, data = subset_data, dist = &quot;negbin&quot;,control = zeroinfl.control(maxit = 100))
  
  # Append the result to the best_models data frame
  best_models_sib &lt;- rbind(
    best_models_sib,
    data.frame(
      Race = unique(subset_data$RACE),
      Census_Year = unique(subset_data$YEAR),
      AGE_RANGE = unique(subset_data$AGE_RANGE),
      AIC_poisson = AIC(poisson_model),
      AIC_nb = AIC(nb_model),
      AIC_zip = AIC(zip_model),
      AIC_zinb = AIC(zinb_model),
      stringsAsFactors = FALSE
    )
  )
}</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Identify Best-Fitting Models Determine which model fits best for
each combination of RACE, YEAR, and AGE_RANGE.</li>
</ol>
<pre class="r"><code># Add a Best_Model column to store the best model based on minimum AIC
best_models_sib$Best_Model &lt;- apply(best_models_sib, 1, function(row) {
  # Get AIC values for Poisson, NB, ZIP, and ZINB models
  aic_values &lt;- c(Poisson = as.numeric(row[&#39;AIC_poisson&#39;]),
                  Negative_Binomial = as.numeric(row[&#39;AIC_nb&#39;]),
                  Zero_Inflated_Poisson = as.numeric(row[&#39;AIC_zip&#39;]),
                  Zero_Inflated_NB= as.numeric(row[&#39;AIC_zinb&#39;]))
  
  # Find the name of the model with the minimum AIC value
  best_models_sib &lt;- names(which.min(aic_values))
  
  return(best_models_sib)
})

best_models_sib &lt;- best_models_sib %&gt;% dplyr::select(Race, Census_Year, AGE_RANGE, Best_Model)
# View the updated table with the Best_Model column
print(best_models_sib)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Analyze Patterns
<ul>
<li>Examine how the best-fitting model changes across years and birth
ranges for each race.</li>
<li>Compare these patterns to those observed in the children
distribution analysis.</li>
</ul></li>
<li>Visualize Results Create a summary plot showing the best-fitting
models across years and birth ranges for each race, similar to the one
created for the children distribution.</li>
</ol>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = Race, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Race&quot;, x = &quot;Race&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = Census_Year, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Census Year&quot;, x = &quot;Census Year&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code># Bar plot showing the distribution of best models across races
ggplot(best_models_sib, aes(x = AGE_RANGE, fill = Best_Model)) +
  geom_bar(position = &quot;stack&quot;) +
  labs(title = &quot;Best-Fitting Models (siblings) by Birth Range)&quot;, x = &quot;Age Range&quot;, y = &quot;Count&quot;, fill = &quot;Best Model&quot;)</code></pre>
<pre class="r"><code>ggplot(best_models_sib, aes(x = Census_Year, y = AGE_RANGE, fill = Best_Model)) +
  geom_tile(color = &quot;white&quot;, lwd = 0.5, linetype = 1) + # Create the tiles
  facet_wrap(~Race, nrow = 2) + # Facet by Race
  scale_fill_manual(values = c(&quot;Poisson&quot; = &quot;#0072B2&quot;, &quot;Zero_Inflated_NB&quot; = &quot;#F0E442&quot;, &quot;Negative_Binomial&quot; = &quot;grey&quot;)) + 
  labs(
    title = &quot;Best Model(siblings) by Race, Census Year, and Birth Range&quot;,
    x = &quot;Census Year&quot;,
    y = &quot;Age Range&quot;,
    fill = &quot;Best Model&quot;
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels for readability
    plot.title = element_text(size = 14, face = &quot;bold&quot;),
    legend.position = &quot;bottom&quot;
  )</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>Interpret Findings
<ul>
<li><p>Discuss any differences in the best-fitting models between the
sibling and children distributions. <strong><em>RESULT:</em></strong> By
comparing the pattern of best-fitting models between the sibling and
children distributions, we observe that the best model for black
population has the same best model(zero-inlfated NB) across year and age
range except on one subset(age 40-49 in 1990) in siblings distribution.
However, there is a large difference in best model for white population.
A large portion of best model in children distribution for white
population is zero-inlfated NB, while negative-binomial is the best
model fitted for siblings distribution except for one subset(age 40-49
in 1990).</p></li>
<li><p>Consider the implications of these differences for understanding
family structures and fertility patterns.</p></li>
</ul></li>
</ol>
</div>
</div>
<div id="instructions-for-manqing-cohort-stability-analysis-siblings"
class="section level2">
<h2>[Instructions for Manqing] Cohort Stability Analysis Siblings</h2>
<div id="objective-3" class="section level3">
<h3>Objective</h3>
<p>Analyze the stability of sibling distributions across cohorts,
similar to the analysis performed for children.</p>
</div>
<div id="steps-1" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Use the sibling distribution data
(<code>df_sibling_proportions</code>).</p></li>
<li><p>For each combination of RACE and AGE_RANGE:</p>
<ul>
<li>Compare the sibling distributions across different census
years.</li>
<li>Use statistical tests (e.g., Kolmogorov-Smirnov test) to assess if
distributions are significantly different.</li>
</ul></li>
<li><p>Create a summary table showing:</p>
<ul>
<li>RACE</li>
<li>AGE_RANGE</li>
<li>Whether the distribution is stable across census years</li>
<li>Any significant changes observed</li>
</ul></li>
<li><p>Visualize stability:</p>
<ul>
<li>Create a heatmap or similar plot showing stability/changes across
cohorts and races.</li>
</ul></li>
<li><p>Interpret results:</p>
<ul>
<li>Identify which cohorts show stable sibling distributions.</li>
<li>Compare stability patterns to those observed in the children
distribution analysis.</li>
<li>Discuss implications of stability or lack thereof for understanding
family structure changes over time.</li>
</ul></li>
</ol>
</div>
</div>
<div id="instructions-for-manqing-plot-across-census-years-siblings"
class="section level2">
<h2>[Instructions for Manqing] Plot Across Census Years Siblings</h2>
<div id="objective-4" class="section level3">
<h3>Objective</h3>
<p>Create a visualization showing how sibling distributions change
across census years for different races and birth ranges.</p>
</div>
<div id="steps-2" class="section level3">
<h3>Steps</h3>
<ol style="list-style-type: decimal">
<li><p>Use the sibling distribution data
(<code>df_sibling_proportions</code>).</p></li>
<li><p>Create a multi-panel plot:</p>
<ul>
<li>X-axis: Number of siblings (0 to 12+)</li>
<li>Y-axis: Proportion</li>
<li>Color: Census Year</li>
<li>Facet by: RACE and AGE_RANGE</li>
</ul></li>
<li><p>Use <code>ggplot2</code> to create the plot:</p></li>
</ol>
<pre class="r"><code>ggplot(df_sibling_proportions, aes(x = n_siblings, y = proportion, color = factor(YEAR))) +
 geom_line() +
 facet_grid(RACE ~ AGE_RANGE) +
 labs(title = &quot;Sibling Distribution Across Census Years&quot;,
      x = &quot;Number of Siblings&quot;, y = &quot;Proportion&quot;, color = &quot;Census Year&quot;) +
 theme_minimal() +
 theme(axis.text.x = element_text(angle = 45, hjust = 1))</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Analyze the plot:
<ul>
<li>Identify trends in sibling distribution changes over time.</li>
<li>Compare patterns between races and across birth ranges.</li>
<li>Note any significant shifts or stable periods.</li>
</ul></li>
<li>Compare with children distribution plot:
<ul>
<li>Highlight similarities and differences in trends.</li>
<li>Discuss what these comparisons reveal about changing family
structures.</li>
</ul></li>
</ol>
<p>Remember to reference your findings from the children distribution
analysis when discussing the results, highlighting any notable
similarities or differences between the two analyses.</p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
