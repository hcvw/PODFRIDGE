---
title: "Simulation of STR Pairs and Calculation of Likelihood Ratios"
author: "Tina Lasisi"
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE, echo=FALSE}
# Load necessary packages
library(wesanderson) # for color palettes
library(RColorBrewer)
library(tidyverse)
library(patchwork)
library(microbenchmark)
library(kableExtra)
library(future)
library(furrr)
library(dtplyr)
library(data.table)

plan(multisession, workers = parallel::detectCores() - 2)
set.seed(123)  # Set a seed for reproducibility


knitr::opts_knit$set(root.dir = "..")
knitr::opts_chunk$set(
	fig.height = 6,
	fig.width = 8,
	warning = FALSE,
	echo = FALSE
)
# Set path to the data file
path <- file.path(".", "data")
savepath <- file.path(".", "output")

# Set up vector for cousin degree
p <- c(1:8) 

# Set up initial population size
N <- 76e6 # what does this do?

```


## Background

We will simulate pairs of individuals with known relationships (e.g., parent-child, siblings), including unrelated individuals, based on the specified parameters. We will then calculate the likelihood ratio for each pair of individuals based on the simulated genotypes and known relationships.

To do this, we will draw the likelihood ratio caluclations from Balding & Steele's 'Weight-of-evidence for forensic DNA profiles' book. 

### From Weight-of-evidence for forensic DNA profiles book

Likelihood ratio for a single locus is:

$$
R=\kappa_0+\kappa_1 / R_X^p+\kappa_2 / R_X^u
$$
Where $\kappa$ is the probability of having 0, 1 or 2 alleles IBD for a given relationship. 

The $R_X$ terms are quantifying the "surprisingness" of a particular pattern of allele sharing.

The $R_X^p$ terms attached to the $kappa_1$ are defined in the following table:

$$
\begin{aligned}
&\text { Table 7.2 Single-locus LRs for paternity when } \mathcal{C}_M \text { is unavailable. }\\
&\begin{array}{llc}
\hline c & Q & R_X \times\left(1+2 F_{S T}\right) \\
\hline \mathrm{AA} & \mathrm{AA} & 3 F_{S T}+\left(1-F_{S T}\right) p_A \\
\mathrm{AA} & \mathrm{AB} & 2\left(2 F_{S T}+\left(1-F_{S T}\right) p_A\right) \\
\mathrm{AB} & \mathrm{AA} & 2\left(2 F_{S T}+\left(1-F_{S T}\right) p_A\right) \\
\mathrm{AB} & \mathrm{AC} & 4\left(F_{S T}+\left(1-F_{S T}\right) p_A\right) \\
\mathrm{AB} & \mathrm{AB} & 4\left(F_{S T}+\left(1-F_{S T}\right) p_A\right)\left(F_{S T}+\left(1-F_{S T}\right) p_B\right) /\left(2 F_{S T}+\left(1-F_{S T}\right)\left(p_A+p_B\right)\right) \\
\hline
\end{array}
\end{aligned}
$$

For our purposes we will take out the $F_{S T}$ values. So the table will be as follows:

$$
\begin{aligned}
&\begin{array}{llc}
\hline c & Q & R_X \\
\hline \mathrm{AA} & \mathrm{AA} & p_A \\
\mathrm{AA} & \mathrm{AB} & 2 p_A \\
\mathrm{AB} & \mathrm{AA} & 2p_A \\
\mathrm{AB} & \mathrm{AC} & 4p_A \\
\mathrm{AB} & \mathrm{AB} & 4 p_A p_B/(p_A+p_B) \\
\hline
\end{array}
\end{aligned}
$$


If none of the alleles match, then the $\kappa_1 / R_X^p = 0$.

The $R_X^u$ terms attached to the $kappa_2$ are defined as:

If both alleles match and are homozygous the equation is 6.4 (pg 85).
Single locus match probability: $\mathrm{CSP}=\mathcal{G}_Q=\mathrm{AA}$
$$
\frac{\left(2 F_{S T}+\left(1-F_{S T}\right) p_A\right)\left(3 F_{S T}+\left(1-F_{S T}\right) p_A\right)}{\left(1+F_{S T}\right)\left(1+2 F_{S T}\right)}
$$
Simplified to:
$$
p_A{ }^2
$$

If both alleles match and are heterozygous, the equation is 6.5 (pg 85)
Single locus match probability: $\mathrm{CSP}=\mathcal{G}_Q=\mathrm{AB}$
$$
2 \frac{\left(F_{S T}+\left(1-F_{S T}\right) p_A\right)\left(F_{S T}+\left(1-F_{S T}\right) p_B\right)}{\left(1+F_{S T}\right)\left(1+2 F_{S T}\right)}
$$
Simplified to:

$$
2 p_A p_B
$$
If both alleles do not match then $\kappa_2 / R_X^u = 0$. 

## Likelihood ratio calculation

### Flowchart

For our purposes, we can describe the flowchart for the likelihood ratio calculation as follows:

![](assets/STR_LR.png)

### Function

```{r echo=TRUE}
calculate_likelihood_ratio <- function(shared_alleles, genotype_match = NULL, pA = NULL, pB = NULL, k0, k1, k2) {

  # Case 0: No Shared Alleles
  if (shared_alleles == 0) {
    LR <- k0
    return(LR)
  }

  # Case 1: One Shared Allele
  if (shared_alleles == 1) {
    if (genotype_match == "AA-AA") {
      Rxp <- pA
    } else if (genotype_match == "AA-AB" | genotype_match == "AB-AA") {
      Rxp <- 2 * pA
    } else if (genotype_match == "AB-AC") {
      Rxp <- 4 * pA
    } else if (genotype_match == "AB-AB") {
      Rxp <- (4 * (pA * pB) )/ (pA + pB)
    } else {
      stop("Invalid genotype match for 1 shared allele.")
    }
    
    LR <- k0 + (k1 / Rxp)
    return(LR)
  }

  # Case 2: Two Shared Alleles
  if (shared_alleles == 2) {
    if (genotype_match == "AA-AA") {
      Rxp <- pA
      Rxu <- pA^2
    } else if (genotype_match == "AB-AB") {
      Rxp <- (4 * pA * pB) / (pA + pB)
      Rxu <- 2 * pA * pB
    } else {
      stop("Invalid genotype match for 2 shared alleles.")
    }

    LR <- k0 + (k1 / Rxp) + (k2 / Rxu)
    return(LR)
  }
}


```

## Rscript for simulation

Given our likelihood ratio calculation, we will now build a framework around this for simulating pairs of individuals of known relationships and calculating the likelihood ratio for each pair based on the simulated genotypes.

The general flow of our simulation framework will be as follows:

![](assets/simulation-framework.png)

### Step 1: Simulation Setup

The first step is to set up the simulation by defining the parameters and functions required for generating the simulated data. This includes specifying the populations, allele frequencies, and the kinship coefficient matrix for likelihood ratio calculations. 

```{r echo=TRUE}

generate_simulation_setup <- function(kinship_matrix, population_list, num_related, num_unrelated) {
  # Create an empty dataframe to store the simulation setup
  simulation_setup <- data.frame(
    population = character(),
    relationship_type = character(),
    num_simulations = integer(),
    stringsAsFactors = FALSE
  )
  
  # Loop through each population and relationship type to create the setup
  for (population in population_list) {
    for (relationship in kinship_matrix$relationship_type) {
      num_simulations <- ifelse(relationship == "unrelated", num_unrelated, num_related)
      
      # Append to the simulation setup dataframe
      simulation_setup <- rbind(simulation_setup, data.frame(
        population = population,
        relationship_type = relationship,
        num_simulations = num_simulations
      ))
    }
  }
  
  return(simulation_setup)
}


```

#### Create input parameters

The necessary parameters for this are initialized beforehand. 

First, the kinship coefficients are provided in a matrix:

```{r echo=TRUE}
# Create a dataframe with relationship types and their respective kinship coefficients (k0, k1, k2)
kinship_matrix <- tibble(
    relationship_type = factor(
      c("parent_child", "full_siblings", "half_siblings", "cousins", "second_cousins", "unrelated"),
      levels = c("parent_child", "full_siblings", "half_siblings", "cousins", "second_cousins", "unrelated")
    ),
    k0 = c(0, 1/4, 1/2, 7/8, 15/16, 1),
    k1 = c(1, 1/2, 1/2, 1/8, 1/16, 0),
    k2 = c(0, 1/4, 0, 0, 0, 0)
  )

# Print the kinship matrix to check the contents
print(kinship_matrix)


```

Then a list of populations is created:

```{r}
# Create a tibble with populations and their labels
population_labels <- tibble(
  population = factor(
    c("all", "AfAm", "Cauc", "Hispanic", "Asian"),
    levels = c("all", "AfAm", "Cauc", "Hispanic", "Asian")
  ),
  label = c("All", "African American", "Caucasian", "Hispanic", "Asian")
)

# Create a simple list based on the population names
populations_list <- levels(population_labels$population)

# Print the tibble to check the contents
print(population_labels)

# Print the simple list to check the contents
print(populations_list)


```

#### Gather allele frequency information

```{r}

# Read the combined allele frequency data
df_allelefreq <- fread("data/df_allelefreq_combined.csv")

# Ensure the 'allele' column is character
df_allelefreq[, allele := as.character(allele)]

# Verify the structure
str(df_allelefreq)

# Print the first few rows to check the data
print(head(df_allelefreq))


```

We will now extract the unique loci from the allele frequency tables:

```{r}
# Extract unique loci (marker) variables
loci_list <- df_allelefreq |>
  pull(marker) |>
  unique()

# Print loci_list to check
print(loci_list)

# Print the number of unique loci
num_unique_loci <- length(loci_list)
cat("Number of unique loci:", num_unique_loci, "\n")

```

These are the 29 autosomal loci from the 2013 and 2017 FSI paper on US STR allele frequencies for 29 autosomal STR loci [Steffen et al 2017](https://www.fsigenetics.com/article/S1872-4973(17)30180-1/fulltext).

We will use the list of different required loci to calculate likelihood ratios for pairs of individuals. Below is a reference with which loci are used in various sets.

```{r}

core_loci <- read.csv("data/core_CODIS_loci.csv")

core_loci

# Column names for which we need to create lists of loci
columns <- c("core_13", "identifiler_15", "expanded_20", "supplementary")

# Create a named list where each element is a vector of loci for which the column value is 1
loci_lists <- lapply(columns, function(col) {
  core_loci |> 
    filter(get(col) == 1) |> 
    pull(locus)
})

# Set the names of the list elements to the column names
names(loci_lists) <- columns

# Add the loci_list as autosomal_29
loci_lists$autosomal_29 <- loci_list

# Display the result
loci_lists

```

Now we can test the simulation setup function:


```{r}

# Test the simulation setup function
simulation_setup <- generate_simulation_setup(kinship_matrix, populations_list, 10,100)

print(simulation_setup)

```

### Step 2: Initialize Individuals
Once the general simulation setup is done, each pair of individuals must be initialized as its own dataframe. 

Now we can initialize the individuals:


```{r func-initialize}

initialize_individuals_pair <- function(population, relationship_type, sim_id, loci_list) {
  num_loci <- length(loci_list)
  
  # Create a data.table to store the genotype information along with additional columns
  # for the calculation of the likelihood ratio and other necessary metrics
  individuals_genotypes <- data.table(
    population = rep(population, num_loci),
    relationship_type = rep(relationship_type, num_loci),
    sim_id = rep(sim_id, num_loci),
    locus = loci_list,
    ind1_allele1 = character(num_loci),
    ind1_allele2 = character(num_loci),
    ind2_allele1 = character(num_loci),
    ind2_allele2 = character(num_loci),
    shared_alleles = integer(num_loci),  # Initialize shared_alleles with integer default (0)
    genotype_match = character(num_loci),  # Initialize genotype_match with blank characters
    LR = numeric(num_loci)  # Initialize the LR column with numeric defaults (floating point)
  )
  
  return(individuals_genotypes)
}

```


#### Testing the initialization function
Here we test to see what the intialization function creates:

```{r}
# Assuming loci_list is already defined and contains the list of loci
# Example usage:
population <- "all"
relationship_type <- "parent_child"
sim_id <- 1

# Initialize a single pair of individuals
individuals_genotypes <- initialize_individuals_pair(population, relationship_type, sim_id, loci_list)

# Print the initialized individuals
print(individuals_genotypes)

```

```{r}
library(microbenchmark)

# Benchmark the initialization functions
benchmark_results <- microbenchmark(initialize = initialize_individuals_pair(population, relationship_type, sim_id, loci_list),
  times = 100
)

# Print the benchmark results
print(benchmark_results)

```

### Step 3: Simulate Genotypes

Next, we define a function to simulate the genotypes for each pair of individuals based on the allele frequencies and kinship coefficients. 


```{r func-geno-sim}
# simulate_genotypes <- function(row, df_allelefreq, kinship_matrix) {
#   population <- row$population
#   locus <- row$locus
#   relationship <- row$relationship_type
# 
#   # Fetch allele frequencies for the current population and locus
#   allele_freqs <- df_allelefreq[df_allelefreq$population == population & df_allelefreq$marker == locus, ]
# 
#   # Fetch kinship coefficients based on the relationship type
#   kinship_coeffs <- kinship_matrix[kinship_matrix$relationship_type == relationship, ]
# 
#   # Extract alleles and their frequencies
#   alleles <- allele_freqs$allele
#   frequencies <- allele_freqs$frequency
# 
#   # Simulate alleles for individual 1
#   ind1_alleles <- sample(alleles, size = 2, replace = TRUE, prob = frequencies)
# 
#   # Determine the number of shared alleles using kinship coefficients
#   relationship_choice <- sample(c('none', 'one', 'both'), size = 1, prob = c(kinship_coeffs$k0, kinship_coeffs$k1, kinship_coeffs$k2))
# 
#   # Simulate alleles for individual 2 based on the relationship choice
#   if (relationship_choice == 'none') {
#     ind2_alleles <- sample(alleles, size = 2, replace = TRUE, prob = frequencies)
#   } else if (relationship_choice == 'one') {
#     shared_allele <- sample(ind1_alleles, size = 1)
#     non_shared_allele <- sample(alleles, size = 1, prob = frequencies)
#     if (runif(1) > 0.5) {
#       ind2_alleles <- c(shared_allele, non_shared_allele)
#     } else {
#       ind2_alleles <- c(non_shared_allele, shared_allele)
#     }
#   } else if (relationship_choice == 'both') {
#     ind2_alleles <- ind1_alleles
#   }
# 
#   # Return the updated row
#   row$ind1_allele1 <- ind1_alleles[1]
#   row$ind1_allele2 <- ind1_alleles[2]
#   row$ind2_allele1 <- ind2_alleles[1]
#   row$ind2_allele2 <- ind2_alleles[2]
# 
#   return(row)
# }
```


```{r new-func-geno-sim}

simulate_genotypes <- function(row, df_allelefreq, kinship_matrix) {
  population <- row$population
  locus <- row$locus
  relationship <- row$relationship_type

  # Fetch allele frequencies for the current population and locus, filtering out zero frequencies
  allele_freqs <- df_allelefreq %>%
    filter(population == !!population, marker == !!locus, frequency > 0)
  
  # Ensure there are valid alleles to sample from
  if (nrow(allele_freqs) == 0) {
    stop(paste("No valid alleles found for population", population, "and locus", locus))
  }

  # Extract alleles and their frequencies
  alleles <- allele_freqs$allele
  frequencies <- allele_freqs$frequency

  # Debugging information
  # cat("Population:", population, "Locus:", locus, "\n")
  # cat("Alleles and Frequencies before normalization:\n")
  # print(data.frame(Allele = alleles, Frequency = frequencies))

  # Normalize frequencies to sum to 1 and round to 6 decimal places to handle floating point issues
  frequencies <- round(frequencies / sum(frequencies), 6)

  # Filter out zero probabilities after normalization and rounding
  valid_indices <- frequencies > 0
  alleles <- alleles[valid_indices]
  frequencies <- frequencies[valid_indices]

  # Debugging information after normalization and filtering
  # cat("Alleles and Normalized Frequencies:\n")
  # print(data.frame(Allele = alleles, Frequency = frequencies))

  # Simulate alleles for individual 1
  ind1_alleles <- sample(alleles, size = 2, replace = TRUE, prob = frequencies)

  # Debugging information
  # cat("Simulated Alleles for Individual 1:", toString(ind1_alleles), "\n")

  # Determine the number of shared alleles using kinship coefficients
  kinship_coeffs <- kinship_matrix[kinship_matrix$relationship_type == relationship, ]
  relationship_choice <- sample(c('none', 'one', 'both'), size = 1, prob = c(kinship_coeffs$k0, kinship_coeffs$k1, kinship_coeffs$k2))

  # Simulate alleles for individual 2 based on the relationship choice
  if (relationship_choice == 'none') {
    ind2_alleles <- sample(alleles, size = 2, replace = TRUE, prob = frequencies)
  } else if (relationship_choice == 'one') {
    shared_allele <- sample(ind1_alleles, size = 1)
    non_shared_allele <- sample(alleles, size = 1, replace = TRUE, prob = frequencies)
    if (runif(1) > 0.5) {
      ind2_alleles <- c(shared_allele, non_shared_allele)
    } else {
      ind2_alleles <- c(non_shared_allele, shared_allele)
    }
  } else if (relationship_choice == 'both') {
    ind2_alleles <- ind1_alleles
  }

  # Debugging information
  # cat("Simulated Alleles for Individual 2:", toString(ind2_alleles), "\n")

  # Return the updated row
  row$ind1_allele1 <- ind1_alleles[1]
  row$ind1_allele2 <- ind1_alleles[2]
  row$ind2_allele1 <- ind2_alleles[1]
  row$ind2_allele2 <- ind2_alleles[2]

  return(row)
}

```

```{r}

# Perform the microbenchmark
benchmark_result <- microbenchmark(
  geno_sim = simulate_genotypes(individuals_genotypes[1, ], df_allelefreq, kinship_matrix),
  times = 100
)

# Print the benchmark results
print(benchmark_result)

```

### Step 4: Calculate Kinship

Then we define a related function to calculate the kinship and likelihood ratios based on the simulated genotypes.

```{r}
kinship_calculation <- function(row, allele_frequency_data, kinship_matrix) {
  # Step 1: Extract alleles directly from the row
  alleles_ind1 <- c(row$ind1_allele1, row$ind1_allele2)
  alleles_ind2 <- c(row$ind2_allele1, row$ind2_allele2)
  
  alleles_ind1 <- as.character(c(row$ind1_allele1, row$ind1_allele2))
  alleles_ind2 <- as.character(c(row$ind2_allele1, row$ind2_allele2))


  # Step 2: Determine shared and unique alleles
  shared_alleles_vector <- intersect(alleles_ind1, alleles_ind2)
  unique_alleles_ind1 <- setdiff(alleles_ind1, shared_alleles_vector)
  unique_alleles_ind2 <- setdiff(alleles_ind2, shared_alleles_vector)

  # # Debugging prints
  # print(paste("Alleles Ind1:", toString(alleles_ind1)))
  # print(paste("Alleles Ind2:", toString(alleles_ind2)))
  # print(paste("Shared Alleles Vector:", toString(shared_alleles_vector)))
  # print(paste("Unique Alleles Ind1:", toString(unique_alleles_ind1)))
  # print(paste("Unique Alleles Ind2:", toString(unique_alleles_ind2)))

  # Step 3: Map alleles to letters
  allele_map <- list()
  next_label <- 1

  # Map shared alleles first
  for (allele in shared_alleles_vector) {
    allele_map[[LETTERS[next_label]]] <- allele
    next_label <- next_label + 1
  }

  # Map unique alleles from individual 1 next
  for (allele in unique_alleles_ind1) {
    if (!(allele %in% allele_map)) {
      allele_map[[LETTERS[next_label]]] <- allele
      next_label <- next_label + 1
    }
  }

  # Map unique alleles from individual 2 last
  for (allele in unique_alleles_ind2) {
    if (!(allele %in% allele_map)) {
      allele_map[[LETTERS[next_label]]] <- allele
      next_label <- next_label + 1
    }
  }

  # Convert list to named vector for easier access
  allele_map <- unlist(allele_map)

  # Debugging prints
  # print(paste("Allele Map:", paste(names(allele_map), allele_map, sep = "=", collapse = ", ")))

  # Step 4: Apply the map to individual alleles
  labeled_alleles_ind1 <- sapply(as.character(alleles_ind1), function(x) names(allele_map)[which(allele_map == x)])
  labeled_alleles_ind2 <- sapply(as.character(alleles_ind2), function(x) names(allele_map)[which(allele_map == x)])

  # Calculate shared allele count
  shared_alleles <- length(shared_alleles_vector)

  # # Print intermediate values for debugging
  # print(paste("Labeled Alleles Ind1:", toString(labeled_alleles_ind1)))
  # print(paste("Labeled Alleles Ind2:", toString(labeled_alleles_ind2)))
  # print(paste("Shared Alleles Count:", shared_alleles))

  # Step 5: Construct genotype matches
  genotype_ind1 <- paste(sort(labeled_alleles_ind1), collapse = "")
  genotype_ind2 <- paste(sort(labeled_alleles_ind2), collapse = "")
  genotype_match <- paste(genotype_ind1, genotype_ind2, sep = "-")

  # Print genotype match for debugging
  # print(paste("Genotype Match:", genotype_match))

  # Step 6: Fetch allele frequencies
  allele_freqs <- dplyr::filter(allele_frequency_data, population == row$population, marker == row$locus)
  if (nrow(allele_freqs) == 0) {
    stop("No allele frequencies found for the given population and locus.")
  }

  # Determine pA and pB based on the final map
  A_allele <- ifelse("A" %in% names(allele_map), allele_map[["A"]], NA)
  B_allele <- ifelse("B" %in% names(allele_map), allele_map[["B"]], NA)

  # # Debugging prints for allele mapping
  # print(paste("A_allele:", A_allele))
  # print(paste("B_allele:", B_allele))

  pA <- ifelse(any(allele_freqs$allele == A_allele), allele_freqs$frequency[allele_freqs$allele == A_allele], NA)
  pB <- ifelse(any(allele_freqs$allele == B_allele), allele_freqs$frequency[allele_freqs$allele == B_allele], NA)

  # # Debugging prints for allele frequencies
  # print(paste("pA:", pA))
  # print(paste("pB:", pB))

  if (is.na(pA)) {
    stop("Allele frequency for A is missing.")
  }
  if (is.na(pB) && length(shared_alleles_vector) > 1) {
    stop("Allele frequency for B is missing.")
  }

  # Step 7: Fetch kinship coefficients and calculate likelihood ratio
  k_values <- kinship_matrix[kinship_matrix$relationship_type == row$relationship_type, ]
  LR <- calculate_likelihood_ratio(shared_alleles, genotype_match, pA, pB, k_values$k0, k_values$k1, k_values$k2)

  # # Print final calculation values for debugging
  # print(paste("k_values:", toString(k_values)))
  # print(paste("Likelihood Ratio:", LR))

  # Step 8: Update the row with calculated values
  row$shared_alleles <- shared_alleles
  row$genotype_match <- genotype_match
  row$LR <- LR

  return(row)
}


```

Here we test what the simulation will produce for each locus in a pair of individuals.

```{r}
# Select the specific row to be used for the example
example_row <- individuals_genotypes[9, ]

# Simulate genotypes for the example row
simulated_output <- simulate_genotypes(example_row, df_allelefreq, kinship_matrix)

simulated_output

# Calculate kinship and likelihood ratios using the simulated genotypes
final_output <- kinship_calculation(simulated_output, df_allelefreq, kinship_matrix)

# Print the final output to check the updated allele values and computed likelihood ratio
print(final_output)

```


We then need a function to process the loci and calculate the kinship for each row.


```{r}

process_loci <- function(row, allele_frequency_data, kinship_matrix) {
  # Simulate genotypes
  simulated_row <- simulate_genotypes(row, allele_frequency_data, kinship_matrix)
  
  # Calculate kinship
  final_row <- kinship_calculation(simulated_row, allele_frequency_data, kinship_matrix)
  
  return(final_row)
}


```

An example of the final output is shown below for one complete set of loci for a pair of individuals:

```{r}
# Apply the combined function to each row and update the dataframe
for (i in 1:nrow(individuals_genotypes)) {
  individuals_genotypes[i, ] <- process_loci(individuals_genotypes[i, ], df_allelefreq, kinship_matrix)
}

# Print the final output to check the updated allele values and computed likelihood ratio
print(individuals_genotypes)
```

#### Benchmark speed for simulation per individual

Now to benchmark the speed

```{r}

# Function for the list of rows approach
list_of_rows_approach <- function(individuals_genotypes, df_allelefreq, kinship_matrix) {
  rows_list <- split(individuals_genotypes, seq(nrow(individuals_genotypes)))
  final_rows_list <- future_map(rows_list, ~process_loci(.x, df_allelefreq, kinship_matrix), .options = furrr_options(seed = TRUE))
  final_individuals_genotypes <- bind_rows(final_rows_list)
  return(final_individuals_genotypes)
}

# Function for the future_pmap approach
future_pmap_approach <- function(individuals_genotypes, df_allelefreq, kinship_matrix) {
  final_individuals_genotypes <- individuals_genotypes %>%
    future_pmap(~ process_loci(list(...), df_allelefreq, kinship_matrix), .options = furrr_options(seed = TRUE)) %>%
    bind_rows()
  return(final_individuals_genotypes)
}


```

```{r}
# Measure the execution time using system.time() for list_of_rows_approach
list_of_rows_time <- system.time({
  list_of_rows_result <- list_of_rows_approach(individuals_genotypes, df_allelefreq, kinship_matrix)
})

# Print the execution time
cat("Execution time for list_of_rows_approach:\n")
print(list_of_rows_time)

# Measure the execution time using system.time() for future_pmap_approach
future_pmap_time <- system.time({
  future_pmap_result <- future_pmap_approach(individuals_genotypes, df_allelefreq, kinship_matrix)
})

# Print the execution time
cat("Execution time for future_pmap_approach:\n")
print(future_pmap_time)

# Benchmark both approaches using microbenchmark
benchmark_results <- microbenchmark(
  list_of_rows = list_of_rows_approach(individuals_genotypes, df_allelefreq, kinship_matrix),
  future_pmap = future_pmap_approach(individuals_genotypes, df_allelefreq, kinship_matrix),
  times = 10  # Number of iterations
)

# Print the benchmark results
cat("Benchmark results for both approaches:\n")
print(benchmark_results)

```


### Step 5: Process Simulation Setup

Finally, we define a function to process the simulation setup and initialize and process the pairs of individuals for each simulation scenario.

```{r}

# Function to process the individuals' genotypes dataframe
process_individuals_genotypes <- function(individuals_genotypes, df_allelefreq, kinship_matrix) {
  final_individuals_genotypes <- individuals_genotypes %>%
    future_pmap(~ process_loci(list(...), df_allelefreq, kinship_matrix), seed = TRUE) %>%
    bind_rows()
  
  return(final_individuals_genotypes)
}


```




```{r}

calculate_combined_lrs <- function(final_results, loci_lists) {
  combined_lrs <- final_results %>%
    group_by(population, relationship_type, sim_id) %>%
    summarize(
      core_13 = prod(LR[locus %in% loci_lists$core_13], na.rm = TRUE),
      identifiler_15 = prod(LR[locus %in% loci_lists$identifiler_15], na.rm = TRUE),
      expanded_20 = prod(LR[locus %in% loci_lists$expanded_20], na.rm = TRUE),
      supplementary = prod(LR[locus %in% loci_lists$supplementary], na.rm = TRUE),
      autosomal_29 = prod(LR[locus %in% loci_lists$autosomal_29], na.rm = TRUE),
      .groups = "drop"
    ) %>%
    pivot_longer(cols = starts_with("core_13"):starts_with("autosomal_29"),
                 names_to = "loci_set",
                 values_to = "LR")
  
  return(combined_lrs)
}

```


```{r dt-calc-lrs}

calculate_combined_lrs_dt <- function(final_results, loci_lists) {
  final_results <- as.data.table(final_results)
  
  combined_lrs <- final_results[, .(
    core_13 = prod(LR[locus %in% loci_lists$core_13], na.rm = TRUE),
    identifiler_15 = prod(LR[locus %in% loci_lists$identifiler_15], na.rm = TRUE),
    expanded_20 = prod(LR[locus %in% loci_lists$expanded_20], na.rm = TRUE),
    supplementary = prod(LR[locus %in% loci_lists$supplementary], na.rm = TRUE),
    autosomal_29 = prod(LR[locus %in% loci_lists$autosomal_29], na.rm = TRUE)
  ), by = .(population, relationship_type, sim_id)]
  
  combined_lrs <- melt(combined_lrs, 
                       id.vars = c("population", "relationship_type", "sim_id"),
                       measure.vars = c("core_13", "identifiler_15", "expanded_20", "supplementary", "autosomal_29"),
                       variable.name = "loci_set", value.name = "LR")
  
  return(combined_lrs)
}

```


```{r}

# Efficient process_simulation_setup function
process_simulation_setup <- function(simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, output_file, summary_output_file) {
  # Process each simulation setup row
  final_results <- simulation_setup %>%
    future_pmap_dfr(function(population, relationship_type, num_simulations) {
      purrr::map_dfr(1:num_simulations, function(sim_id) {
        # Initialize individuals' genotypes
        individuals_genotypes <- initialize_individuals_pair(population, relationship_type, sim_id, loci_list)
        
        # Process individuals' genotypes
        processed_genotypes <- process_individuals_genotypes(individuals_genotypes, df_allelefreq, kinship_matrix)
        
        return(processed_genotypes)
      })
    }, .progress = TRUE)
  
  # # Remove the `seed` column if it exists
  if ("seed" %in% colnames(final_results)) {
    final_results <- final_results %>% select(-seed)
  }

  # Save the final results to a CSV file
  write.csv(final_results, output_file, row.names = FALSE)
  
  # Calculate combined LRs for each loci set and create a summary dataframe
  combined_lrs <- calculate_combined_lrs(final_results, loci_lists)
  
  # Save the summary dataframe to a CSV file
  write.csv(combined_lrs, summary_output_file, row.names = FALSE)
  
  return(list(final_results = final_results, combined_lrs = combined_lrs))
}
```

```{r dt-process-sim}

# Efficient process_simulation_setup function using data.table
process_simulation_setup_dt <- function(simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, output_file, summary_output_file) {
  # Process each simulation setup row
  final_results <- simulation_setup %>%
    future_pmap_dfr(function(population, relationship_type, num_simulations) {
      purrr::map_dfr(1:num_simulations, function(sim_id) {
        # Initialize individuals' genotypes
        individuals_genotypes <- initialize_individuals_pair(population, relationship_type, sim_id, loci_list)
        
        # Process individuals' genotypes
        processed_genotypes <- process_individuals_genotypes(individuals_genotypes, df_allelefreq, kinship_matrix)
        
        return(processed_genotypes)
      })
    }, .progress = TRUE)
  
  # Remove the `seed` column if it exists
  if ("seed" %in% colnames(final_results)) {
    final_results <- final_results %>% select(-seed)
  }

  # Save the final results to a CSV file
  write.csv(final_results, output_file, row.names = FALSE)
  
  # Calculate combined LRs for each loci set and create a summary dataframe
  combined_lrs <- calculate_combined_lrs_dt(final_results, loci_lists)
  
  # Save the summary dataframe to a CSV file
  write.csv(combined_lrs, summary_output_file, row.names = FALSE)
  
  return(list(final_results = final_results, combined_lrs = combined_lrs))
}


```

```{r}

# Assuming simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, output_file, and summary_output_file are already defined

benchmark <- microbenchmark(
  dplyr_version = process_simulation_setup(simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, "data/processed_genotypes_dplyr.csv", "data/summary_genotypes_dplyr.csv"),
  datatable_version = process_simulation_setup_dt(simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, "data/processed_genotypes_dt.csv", "data/summary_genotypes_dt.csv"),
  times = 10
)

print(benchmark)

```

```{r}
estimate_simulation_time_from_benchmark <- function(benchmark_results, total_simulations) {
  # Extract median times for dplyr and data.table versions
  dplyr_median_time <- median(benchmark_results$time[benchmark_results$expr == "dplyr_version"]) / 1e9
  datatable_median_time <- median(benchmark_results$time[benchmark_results$expr == "datatable_version"]) / 1e9
  
  # Calculate total estimated time in seconds
  dplyr_total_time_estimate <- dplyr_median_time * total_simulations
  datatable_total_time_estimate <- datatable_median_time * total_simulations
  
  # Convert total estimated time to minutes and hours
  dplyr_total_time_estimate_min <- dplyr_total_time_estimate / 60
  datatable_total_time_estimate_min <- datatable_total_time_estimate / 60
  
  dplyr_total_time_estimate_hr <- dplyr_total_time_estimate_min / 60
  datatable_total_time_estimate_hr <- datatable_total_time_estimate_min / 60
  
  # Create a data frame for the results
  results <- data.frame(
    Method = c("dplyr_version", "datatable_version"),
    Median_Time_Seconds = c(dplyr_median_time, datatable_median_time),
    Estimated_Time_Minutes = c(dplyr_total_time_estimate_min, datatable_total_time_estimate_min),
    Estimated_Time_Hours = c(dplyr_total_time_estimate_hr, datatable_total_time_estimate_hr)
  )
  
  # Print the table using kable
  kable(results, format = "html", digits = 2, caption = "Estimated Total Simulation Time") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
}

total_simulations <- 1000  # Total number of simulations to estimate

# Estimate simulation time
estimate_simulation_time_from_benchmark(benchmark, total_simulations)

```


```{r}
# Example usage:
final_df <- process_simulation_setup(simulation_setup, df_allelefreq, kinship_matrix, loci_list, loci_lists, "data/processed_genotypes.csv", "data/summary_genotypes.csv")

```

```{r}
df_geno <- final_df$final_results |> 
  filter(is.infinite(LR) | is.na(LR)) |> 
  print()

df_pairs <- final_df$combined_lrs |> 
  filter(is.infinite(LR) | is.na(LR)) |> 
  print()
```

```{r}

# Ensure df_geno is not empty
if (nrow(df_geno) > 0) {
  # Create a copy of the dataframe to store the results
  df_geno_results <- df_geno

  # Loop through each row and apply the kinship_calculation function
  for (i in 1:nrow(df_geno)) {
    cat("\nProcessing row:", i, "\n")
    
    # Apply the kinship_calculation function
    df_geno_results[i, ] <- kinship_calculation(df_geno[i, ], df_allelefreq, kinship_matrix)
  }

  # Print the dataframe to check the results
  print(df_geno_results)
} else {
  stop("df_geno is empty. No data to process.")
}

```

```{r}
# Extract unique locus, alleles, and population from df_geno_results
unique_locus_alleles <- df_geno_results %>%
  select(population, locus, ind1_allele1, ind1_allele2, ind2_allele1, ind2_allele2) %>%
  gather(key = "allele_type", value = "allele", -population, -locus) %>%
  distinct(population, locus, allele)

# Print unique locus, alleles, and population
print(unique_locus_alleles)

# Filter df_allelefreq for the extracted unique combinations
filtered_allele_freqs <- df_allelefreq %>%
  semi_join(unique_locus_alleles, by = c("population", "marker" = "locus", "allele"))

# Print the filtered allele frequencies
print(filtered_allele_freqs)
```




### Plotting


```{r}
# Define the order of relationship types based on the kinship coefficients (most to least related)
relationship_order <- c("parent_child", "full_siblings", "half_siblings", "cousins", "second_cousins", "unrelated")

# Define the order of populations
population_order <- c("all", "AfAm", "Cauc", "Hispanic", "Asian")

# Define the order of loci sets
loci_set_order <- c("core_13", "identifiler_15", "expanded_20", "supplementary", "autosomal_29")

# Convert relationship_type, population, and loci_set to factors with the specified orders
combined_lrs <- final_df$combined_lrs %>%
  mutate(
    relationship_type = factor(relationship_type, levels = relationship_order),
    population = factor(population, levels = population_order),
    loci_set = factor(loci_set, levels = loci_set_order)
  )

# Plot the combined LR data with logarithmic scale on y-axis
ggplot(combined_lrs, aes(x = relationship_type, y = LR, fill = population, color = population)) +
  geom_boxplot() +
  facet_wrap(~ loci_set, scales = "fixed") +
  labs(
    title = "LR Distributions Across Populations and Relationship Types",
    x = "Relationship Type",
    y = "LR",
    fill = "Population",
    color = "Population"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_y_log10() +
  scale_fill_manual(values = c("all" = "yellow", "AfAm" = "red", "Cauc" = "blue", "Hispanic" = "green", "Asian" = "purple")) +
  coord_flip()+
  scale_x_discrete(limits = rev(levels(combined_lrs$relationship_type)))

# Save the plot to a file
ggsave("output/log_lr_panel_plot.png", width = 12, height = 8)
```

```{r}
# Calculate summary statistics
summary_stats <- combined_lrs %>%
  group_by(relationship_type, population, loci_set) %>%
  summarize(
    mean_LR = mean(LR),
    lower_95 = quantile(LR, 0.025),
    upper_95 = quantile(LR, 0.975)
  ) %>%
  ungroup()
```


```{r}
# Plot the mean line
ggplot(summary_stats, aes(x = loci_set, y = mean_LR, group = population, color = population)) +
  geom_line(size = 1) +
  facet_wrap(~ relationship_type, scales = "free_y", ncol = 2) +
  scale_y_log10() +
  labs(
    title = "Mean LR Across Populations and Relationship Types",
    x = "Loci Set",
    y = "Combined LR",
    color = "Population"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  ) +
  scale_color_manual(values = c("all" = "yellow", "AfAm" = "red", "Cauc" = "blue", "Hispanic" = "green", "Asian" = "purple"))

# Save the plot to a file
ggsave("output/line_chart_lr.png", width = 14, height = 10)
```

```{r}
# Function to calculate cut-off values for 1%, 0.1%, and 0.01% FPR
calculate_cutoffs <- function(input_df, fp_rates) {
  cutoffs <- input_df %>%
    filter(relationship_type == "unrelated") %>%
    group_by(loci_set) %>%
    summarize(
      fixed_cutoff = 1.00,
      cutoff_1 = quantile(LR, probs = 1 - fp_rates[1] / 100, na.rm = TRUE),
      cutoff_0_1 = quantile(LR, probs = 1 - fp_rates[2] / 100, na.rm = TRUE),
      cutoff_0_01 = quantile(LR, probs = 1 - fp_rates[3] / 100, na.rm = TRUE)
    ) %>%
    ungroup()
  
  return(cutoffs)
}

# Define false positive rates as percentages
fp_rates <- c(1, 0.1, 0.01)

# Calculate cutoffs for each loci set
cutoffs <- calculate_cutoffs(combined_lrs, fp_rates)

print(cutoffs)


```

```{r}
# Function to calculate proportions exceeding the cut-offs
calculate_proportions_exceeding_cutoffs <- function(input_df, cutoffs) {
  # Join the cut-offs with the original data frame
  df_with_cutoffs <- left_join(input_df, cutoffs, by = "loci_set")
  
  # Calculate a flag indicating whether the LR exceeds each cut-off
  df_with_cutoffs <- df_with_cutoffs %>%
    mutate(
      exceeds_fixed_cutoff = LR > fixed_cutoff,
      exceeds_cutoff_1 = LR > cutoff_1,
      exceeds_cutoff_0_1 = LR > cutoff_0_1,
      exceeds_cutoff_0_01 = LR > cutoff_0_01
    )
  
  # Aggregate to calculate the proportion of pairs exceeding the cut-offs by relationship type and loci set
  proportions_exceeding <- df_with_cutoffs %>%
    group_by(population, relationship_type, loci_set) %>%
    summarize(
      proportion_exceeding_fixed = mean(exceeds_fixed_cutoff, na.rm = TRUE),
      proportion_exceeding_1 = mean(exceeds_cutoff_1, na.rm = TRUE),
      proportion_exceeding_0_1 = mean(exceeds_cutoff_0_1, na.rm = TRUE),
      proportion_exceeding_0_01 = mean(exceeds_cutoff_0_01, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    filter(relationship_type != "unrelated")  # Exclude unrelated relationship type
  
  return(proportions_exceeding)
}

# Calculate the proportions exceeding the cut-offs
proportions_exceeding_cutoffs <- calculate_proportions_exceeding_cutoffs(combined_lrs, cutoffs)

print(proportions_exceeding_cutoffs)

```

```{r}

# Convert population to factor for plotting
proportions_exceeding_cutoffs$population <- factor(proportions_exceeding_cutoffs$population, levels = population_order)

# Pivot the data to long format for easier plotting
proportions_long <- proportions_exceeding_cutoffs %>%
  pivot_longer(cols = starts_with("proportion_exceeding"), 
               names_to = "Cutoff_Type", values_to = "Proportion", 
               names_prefix = "proportion_exceeding_")

# Map Cutoff_Type to human-readable labels
proportions_long$Cutoff_Type <- factor(proportions_long$Cutoff_Type, levels = c("fixed", "1", "0_1", "0_01"),
                                       labels = c("Fixed Cutoff (1.00)", "1% FPR", "0.1% FPR", "0.01% FPR"))

# Plot the proportions exceeding the cut-offs
ggplot(proportions_long, aes(x = relationship_type, y = Proportion, fill = population, color = population)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Cutoff_Type + loci_set, scales = "fixed") +
  labs(
    title = "Proportions Exceeding Likelihood Cut-offs Across Relationship Types and Loci Sets",
    x = "Relationship Type",
    y = "Proportion Exceeding Cut-off",
    fill = "Population",
    color = "Population"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  scale_fill_manual(values = c("all" = "yellow", "AfAm" = "red", "Cauc" = "blue", "Hispanic" = "green", "Asian" = "purple")) +
  coord_flip()

# Save the plot to a file
ggsave("output/proportions_exceeding_cutoffs_combined.png", width = 12, height = 8)


```


## Simulation results

```{r}
input_df <- read_csv("data/dl_known_vs_tested_simulation_results.csv") %>% 
  mutate(log_R_sum = ifelse(is.infinite(log_R_sum) & log_R_sum < 0,
                            log(1.4e-11),
                            log_R_sum))

```


```{r include=FALSE}
# Check if there are any -Inf values in the log_R_sum column
inf_values_log_R_sum <- sapply(input_df$log_R_sum, function(x) is.infinite(x) & x < 0)

# Count the number of rows containing -Inf values
num_rows_with_inf <- sum(inf_values_log_R_sum)

# Print the count of rows containing -Inf values in log_R_sum
print(paste("Number of rows with -Inf values in log_R_sum column:", num_rows_with_inf))


```



```{r}
# Filter the input dataframe for unrelated values only
input_df_unrelated <- input_df %>% filter(known_relationship_type == "unrelated")
```

## Proportion of individuals of known relationship type exceeding likelihood cut-off

```{r func-exceeding-cut-off}
# Function to calculate proportion exceeding cutoff
calculate_proportion_exceeding_cutoff <- function(input_population, relationship_type, fp_rate, input_df) {

  unrelated_tested <- input_df %>%
    filter(population == input_population,
           known_relationship_type == "unrelated",
           tested_relationship_type == relationship_type)
  
  m_value = fp_rate / 100
  cut_value <- quantile(unrelated_tested$log_R_sum, 1 - m_value)
  
  actual_relationship <- input_df %>%
    filter(population == input_population,
           known_relationship_type == relationship_type,
           tested_relationship_type == relationship_type)
  
  proportion_exceeding_cutoff <- mean(actual_relationship$log_R_sum > cut_value)
  
  return(data.frame(population = input_population,
                    relationship_type = relationship_type,
                    fp_rate = fp_rate,
                    prop_exceeding = proportion_exceeding_cutoff))
}
```


```{r pars}
# Define a vector of false positive rates as percentages
fp_rates <- c(0.1, 0.01, 0.001)

population_groups = unique(input_df$population)
relationship_types = unique(input_df$known_relationship_type)
```


```{r pars2}
# Exclude "unrelated" from relationship types for calculation purposes
relationship_types = relationship_types[relationship_types != "unrelated"]

# Apply function to calculate proportions for each combination of population group, relationship type and false positive rate
proportion_args <- expand.grid(input_population = population_groups, 
                               relationship_type = relationship_types,
                               fp_rate = fp_rates)

# add input_df for each row
exceeding_proportions <- purrr::pmap_df(proportion_args, 
                                        calculate_proportion_exceeding_cutoff, 
                                        input_df = input_df)


# Look at the results
head(exceeding_proportions)

```

```{r fig.width=10}

# Convert population to factor so it can be used in fill aesthetic
exceeding_proportions$population <- as.factor(exceeding_proportions$population)

# Calculate the total number of unrelated pairs and full sibling pairs
num_pairs <- input_df %>% 
  group_by(population, known_relationship_type) %>%
  summarise(n_pairs = n()) %>% 
  spread(known_relationship_type, n_pairs, fill = 0)

# Take the values from the first population
first_population <- num_pairs$population[1]
num_unrelated_pairs <- num_pairs$unrelated[1]
num_related_pairs <- num_pairs$full_siblings[1] 

# format numbers with comma as thousands separator
num_unrelated_pairs <- format(num_unrelated_pairs, big.mark = ",")
num_related_pairs <- format(num_related_pairs, big.mark = ",")

# Create the caption
caption_text <- paste("Number of unrelated pairs per population: ", num_unrelated_pairs,
                      ". Number of related pairs: ", num_related_pairs, ".")

# Create the facetted bar plot
ggplot(exceeding_proportions, aes(x = relationship_type, y = prop_exceeding, fill = population)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  facet_wrap(~fp_rate, scales="free") +
  scale_fill_manual(values = wes_palette("Darjeeling1", n = length(unique(exceeding_proportions$population)), type = "continuous")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Proportion exceeding cut-off") +
  xlab("Relationship type") +
  ggtitle("Proportions exceeding likelihood cut-off for different relationship types") +
  labs(fill = "Population") +
  labs(caption = caption_text)
```

## Cut-offs for each FPR

```{r}
# Function to calculate and return cutoff values
calculate_cutoffs <- function(input_population, relationship_type, fp_rates, input_df) {
  cutoffs <- data.frame()
  for (fp_rate in fp_rates) {
    unrelated_tested <- input_df %>%
      filter(population == input_population,
             known_relationship_type == "unrelated",
             tested_relationship_type == relationship_type)
    
    m_value = fp_rate / 100
    cut_value <- quantile(unrelated_tested$log_R_sum, 1 - m_value, na.rm = TRUE)
    
    cutoffs <- rbind(cutoffs, data.frame(population = input_population,
                                         relationship_type = relationship_type,
                                         fp_rate = fp_rate,
                                         cutoff = cut_value))
  }
  return(cutoffs)
}

# Example usage:
fp_rates <- c(1, 0.1, 0.01)
population_groups <- unique(input_df$population)
relationship_types <- c("parent_child", "full_siblings", "half_siblings", "unrelated") # Ensure this matches your data structure

cutoff_results <- lapply(population_groups, function(pop) {
  lapply(relationship_types, function(rel) {
    calculate_cutoffs(pop, rel, fp_rates, input_df)
  })
})
cutoff_results <- do.call(rbind, do.call(rbind, cutoff_results))

write_csv(cutoff_results, "output/cutoff_results.csv")

```

```{r}

```

```{r}
library(dplyr)

# Assuming 'input_df' is your DataFrame with the necessary columns

# Aggregate LLR results by population and known relationship type
aggregated_llr_results_by_population <- input_df %>%
  group_by(population, known_relationship_type) %>%
  summarize(mean_log_R_sum = mean(log_R_sum, na.rm = TRUE),
            median_log_R_sum = median(log_R_sum, na.rm = TRUE),
            min_log_R_sum = min(log_R_sum, na.rm = TRUE),
            max_log_R_sum = max(log_R_sum, na.rm = TRUE),
            count = n()) %>%
  ungroup()  # Remove grouping

# View the aggregated results
print(aggregated_llr_results_by_population)

write_csv(aggregated_llr_results_by_population, "output/aggregated_llr_results_by_population.csv")

```

```{r}

```

#### Calculate LLR cutoffs for unrelated pairs at each FPR by population
This table presents aggregated log_R_sum values by relationship type for each population, alongside LLR cutoffs calculated for unrelated pairs to maintain false positive rates (FPRs) of 1%, 0.1%, and 0.01%. The cutoffs indicate the LLR threshold above which a pair is less likely to be unrelated at the given FPR, thereby serving as a critical benchmark for assessing relationship evidence. The mean log_R_sum values further elucidate the average strength of genetic evidence supporting each relationship type within populations, highlighting variations and consistencies in genetic relatedness indicators across demographic groups.

```{r}
calculate_llr_cutoffs <- function(df, fpr_vector) {
  df %>%
    filter(known_relationship_type == "unrelated") %>%
    group_by(population) %>%
    summarize(cutoff_1 = quantile(log_R_sum, probs = 1 - fpr_vector[1], na.rm = TRUE),
              cutoff_0_1 = quantile(log_R_sum, probs = 1 - fpr_vector[2], na.rm = TRUE),
              cutoff_0_01 = quantile(log_R_sum, probs = 1 - fpr_vector[3], na.rm = TRUE),
              .groups = 'drop')
}

fpr_vector <- c(0.01, 0.001, 0.0001) # FPRs: 1%, 0.1%, and 0.01%
llr_cutoffs <- calculate_llr_cutoffs(input_df, fpr_vector)


```

```{r}
aggregated_llr_results <- input_df %>%
  group_by(population, known_relationship_type) %>%
  summarize(mean_log_R_sum = mean(log_R_sum, na.rm = TRUE),
            .groups = 'drop')

```

```{r}


# Transforming the data to a wide format
wide_format_results <- aggregated_llr_results %>%
  pivot_wider(names_from = known_relationship_type, values_from = mean_log_R_sum) %>%
  arrange(population)

# Using kable and kableExtra to create and style the table
kable_styled <- kable(wide_format_results, format = "html", booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = T)  # Assuming the first column is 'population'

# Display the table in an R Markdown document or R Notebook
kable_styled

```

```{r}
visualize_llr_distribution <- function(df, cutoffs) {
  ggplot(df, aes(x = log_R_sum, fill = known_relationship_type)) +
    geom_histogram(alpha = 0.6, bins = 30, position = "identity") +
    geom_vline(data = cutoffs, aes(xintercept = cutoff_1, color = "1% FPR"), linetype = "dashed") +
    geom_vline(data = cutoffs, aes(xintercept = cutoff_0_1, color = "0.1% FPR"), linetype = "dashed") +
    geom_vline(data = cutoffs, aes(xintercept = cutoff_0_01, color = "0.01% FPR"), linetype = "dashed") +
    scale_color_manual(values = c("1% FPR" = "red", "0.1% FPR" = "blue", "0.01% FPR" = "green")) +
    facet_wrap(~population) +
    labs(title = "Distribution of log_R_sum Values and LLR Cutoffs by Population",
         x = "Log Likelihood Ratio (LLR)", y = "Frequency") +
    theme_minimal()
}

visualize_llr_distribution(input_df, llr_cutoffs)
```

```{r}
calculate_proportions_exceeding_cutoffs <- function(df, cutoffs) {
  # Join the cutoffs with the original data frame to have cutoffs accessible for each row
  df_with_cutoffs <- left_join(df, cutoffs, by = "population")
  
  # Calculate a flag indicating whether the log_R_sum exceeds the cutoff for each FPR
  df_with_cutoffs <- df_with_cutoffs %>%
    mutate(exceeds_cutoff_1 = log_R_sum > cutoff_1,
           exceeds_cutoff_0_1 = log_R_sum > cutoff_0_1,
           exceeds_cutoff_0_01 = log_R_sum > cutoff_0_01)
  
  # Aggregate to calculate the proportion of pairs exceeding the cutoffs by relationship type and population
  proportions_exceeding <- df_with_cutoffs %>%
    group_by(population, known_relationship_type) %>%
    summarize(proportion_exceeding_1 = mean(exceeds_cutoff_1, na.rm = TRUE),
              proportion_exceeding_0_1 = mean(exceeds_cutoff_0_1, na.rm = TRUE),
              proportion_exceeding_0_01 = mean(exceeds_cutoff_0_01, na.rm = TRUE),
              .groups = 'drop')
  
  return(proportions_exceeding)
}

proportions_exceeding_cutoffs <- calculate_proportions_exceeding_cutoffs(input_df, llr_cutoffs)

```

```{r}
visualize_proportions_exceeding_cutoffs <- function(proportions_df) {
  proportions_df$known_relationship_type <- factor(proportions_df$known_relationship_type,
                                                   levels = c("parent_child", "full_siblings", "half_siblings", 
                                                              "cousins", "second_cousins", "unrelated"))
  proportions_long <- pivot_longer(proportions_df, cols = starts_with("proportion_exceeding"), 
                                   names_to = "FPR", values_to = "Proportion",
                                   names_prefix = "proportion_exceeding_")
  
  proportions_long$FPR <- factor(proportions_long$FPR, levels = c("1", "0_1", "0_01"),
                                 labels = c("1% FPR", "0.1% FPR", "0.01% FPR"))
  
  ggplot(proportions_long, aes(x = known_relationship_type, y = Proportion, fill = population)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    facet_grid(FPR ~ .) +
      scale_fill_manual(values = wes_palette("Darjeeling1", n = length(unique(exceeding_proportions$population)), type = "continuous")) +
    labs(title = "Proportion of Individuals Exceeding Cutoffs by Relationship Type",
         x = "Relationship Type", y = "Proportion Exceeding Cutoff",
         fill = "Population") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

visualize_proportions_exceeding_cutoffs(proportions_exceeding_cutoffs)
```

